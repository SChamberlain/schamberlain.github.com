<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  <link href="http://gmpg.org/xfn/11" rel="profile">

  <title>
    
    Recology, R/etc.
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Open+Sans:300,400italic,400,600,700|Abril+Fatface">

  <link rel="stylesheet" href="/public/css/bootstrap/css/bootstrap.css">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/favicon.ico">
  <link rel="shortcut icon" href="/public/favicon.ico">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.css" rel="stylesheet">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body class="theme-base-0f layout-reverse">

    <header class="masthead">
      <div class="masthead-inner">
        <h1>Recology</h1>
        <!-- <h1> <a href="http://recology.info/">Recology</a></h1> -->
        <p class="lead">R/etc.</p>

        <div class="colophon">
          <ul class="colophon-links">
            <li>
              <a href="/"><i class="fa fa-home fa-lg"></i></a>&nbsp;
              <a href="/about"><i class="fa fa-info-circle fa-lg"></i></a>&nbsp;
              <a href="/archives"><i class="fa fa-archive fa-lg"></i></a>&nbsp;
              <a href="/rresources"><i class="fa fa-book fa-lg"></i></a>&nbsp;
              <a href="http://rforcats.net/" rel><i class="fa fa-graduation-cap fa-lg"></i></a>&nbsp;
              <a href="/feed.xml"><i class="fa fa-rss fa-lg"></i></a>&nbsp;
              <a href="https://twitter.com/sckottie"><i class="fa fa-twitter fa-lg"></i></a>&nbsp;
              <a href="/fork"><i class="fa fa-spinner fa-lg"></i></a>
            </li>
          </ul>
          <!-- <small><a href="https://github.com/mdo/hyde">Hyde</a> from <a href="https://twitter.com/mdo" target="_blank">@mdo</a>.</small> -->
        </div>
      </div>
    </header>

    <div class="content container">
      <div class="posts">
  <a style="float:right;" href="/archives" data-toggle="tooltip" data-placement="bottom" title="Archives"><i class="fa fa-archive fa-lg"></i></a>
  <a style="float:right;" href="/tags"><i class="fa fa-tags fa-lg"></i></a>&nbsp;
  
  <div class="post">
    <h1>
      <a href="/2013/03/r-metadata/">
        Scholarly metadata in R
      </a>
    </h1>

    <span class="post-date">16 Mar 2013</span>

    Scholarly metadata - the meta-information surrounding articles - can be super useful.  Although metadata does not contain the full content of articles, it contains a lot of useful information, including title, authors, abstract, URL to the article, etc. 

One of the largest sources of metadata is provided via the Open Archives Initiative Protocol for Metadata Harvesting or [OAI-PMH](http://www.openarchives.org/OAI/openarchivesprotocol.html). Many publishers, provide their metadata through their own endpoint, and implement the standard OAI-PMH methods: [GetRecord](http://www.openarchives.org/OAI/openarchivesprotocol.html#GetRecord), [Identify](http://www.openarchives.org/OAI/openarchivesprotocol.html#Identify), [ListIdentifiers](http://www.openarchives.org/OAI/openarchivesprotocol.html#ListIdentifiers), [ListMetadataFormats](http://www.openarchives.org/OAI/openarchivesprotocol.html#ListMetadataFormats), [ListRecords](http://www.openarchives.org/OAI/openarchivesprotocol.html#ListRecords), and [ListSets](http://www.openarchives.org/OAI/openarchivesprotocol.html#ListSets). Many providers use OAI-PMH, including [DataCite](http://oai.datacite.org/), [Dryad](http://wiki.datadryad.org/Data_Access#OAI-PMH), and [PubMed](http://www.ncbi.nlm.nih.gov/pmc/tools/oai/).

Some data-/article-providers provide their metadata via their own APIs. For example, Nature Publishing Group provides their own metadata API [here](http://developers.nature.com/docs) in non OAI-PMH format; you can get PLoS metadata through their [search API](http://api.plos.org/), and the BHL (see below) provides their own custom metadata service.

In addition, CrossRef provides a number of metadata search services: [metadata search](http://search.labs.crossref.org/help/api) and [openurl](http://labs.crossref.org/openurl/). 

What about the other publishers? (please tell me if I'm wrong about these three) 

+ Springer has [a metadata API](http://dev.springer.com/docs), but it is terrible, soooo...
+ Elsevier, are you kidding? Well, they do have some sort of API service, but its a pain in the ass. 
+ Wiley, no better than Elsevier.

Note that metadata can live in other places:

+ Another package being developed by David Springate, [rpubmed](https://github.com/ropensci/rpubmed) can get PubMed metadata. 
+ Our wrapper to the Mendeley API, [RMendeley](https://github.com/ropensci/rmendeley), gets article metadata via Mendeley's database. 
+ Our wrapper to the Biodiversity Heritage Library API [here](http://www.biodiversitylibrary.org/api2/docs/docs.html) gets their metadata. 

No, you can't get metadata via Google Scholar - the don't allow scraping, and don't have expose their data via an API.

I have discussed this package [in a previous blog post](http://sckott.github.io/2012/09/rmetadata/), but have since worked on the code a bit, and thought it deserved a new post. 

You can see a tutorial for this package [here](http://ropensci.github.com/rmetadata/), and contribute to the code [here](https://github.com/ropensci/rmetadata).

***************

### Install rmetadata

{% highlight r %}
# install_github('rmetadata', 'ropensci') # uncomment to install
library(rmetadata)
{% endhighlight %}


***************

### Count OAI-PMH identifiers for a data provider.
	

{% highlight r %}
# For DataCite.
count_identifiers("datacite")

  provider   count
1 datacite 1216193
{% endhighlight %}


*********
	
### Lookup article info via CrossRef with DOI and get a citation.

#### As Bibtex
	

{% highlight r %}
print(crossref_citation("10.3998/3336451.0009.101"), style = "Bibtex")

@Article{,
  title = {In Google We Trust?},
  author = {Geoffrey Bilder},
  journal = {The Journal of Electronic Publishing},
  year = {2006},
  month = {01},
  volume = {9},
  doi = {10.3998/3336451.0009.101},
}
{% endhighlight %}

	
#### As regular text
	

{% highlight r %}
print(crossref_citation("10.3998/3336451.0009.101"), style = "text")

Bilder G (2006). "In Google We Trust?" _The Journal of Electronic
Publishing_, *9*. <URL:
http://dx.doi.org/10.3998/3336451.0009.101>.
{% endhighlight %}

	
*********
	
### Search the CrossRef Metatdata for DOIs using free form references.
	
#### Search with title, author, year, and journal
	

{% highlight r %}
crossref_search_free(query = "Piwowar Sharing Detailed Research Data Is Associated with Increased Citation Rate PLOS one 2007")

                                                                                             text
1 Piwowar Sharing Detailed Research Data Is Associated with Increased Citation Rate PLOS one 2007
  match                   doi score
1  TRUE 10.1038/npre.2007.361 4.905
{% endhighlight %}

	
#### Get a DOI and get the citation using \code{crossref_search}
	

{% highlight r %}
# Get a DOI for a paper
doi <- crossref_search_free(query = "Piwowar sharing data PLOS one")$doi

# Get the metadata
crossref_search(doi = doi)[, 1:3]

                           doi score normalizedScore
1 10.1371/journal.pone.0000308 18.19             100
{% endhighlight %}


*********
	
### Get a random set of DOI's through CrossRef.
	

{% highlight r %}
# Default search gets 20 random DOIs
crossref_r()

 [1] "10.4028/www.scientific.net/MSF.126-128.467"
 [2] "10.2139/ssrn.548523"                       
 [3] "10.1016/S0012-821X(02)00562-9"             
 [4] "10.1093/rsq/13.2-3.167"                    
 [5] "10.5772/55055"                             
 [6] "10.1515/BC.1999.050"                       
 [7] "10.1016/S0020-7292(98)90160-6"             
 [8] "10.1111/j.1439-0418.1985.tb02788.x"        
 [9] "10.1089/aid.2012.0115"                     
[10] "10.1016/0002-9378(95)90155-8"              
[11] "10.1001/jama.1949.02900490055028"          
[12] "10.1051/jphyscol:1989172"                  
[13] "10.1016/s0301-2115(03)00298-7"             
[14] "10.1007/BF02735292"                        
[15] "10.1016/0003-4916(65)90026-6"              
[16] "10.4156/jdcta.vol5.issue5.12"              
[17] "10.1007/s10904-009-9316-2"                 
[18] "10.1023/A:1021690001832"                   
[19] "10.1007/s12262-012-0724-0"                 
[20] "10.1007/bf02192860"
{% endhighlight %}



{% highlight r %}

# Specify you want journal articles only
crossref_r(type = "journal_article")

 [1] "10.1016/j.jacc.2011.09.055"                                 
 [2] "10.1002/dev.420170603"                                      
 [3] "10.4315/0362-028X.JFP-10-403"                               
 [4] "10.1016/S0925-4927(98)00016-X"                              
 [5] "10.1111/j.1933-1592.2002.tb00141.x"                         
 [6] "10.1541/ieejfms.127.629"                                    
 [7] "10.5539/enrr.v3n1p62"                                       
 [8] "10.1016/S0960-9776(96)90038-7"                              
 [9] "10.1016/0925-9635(94)05240-9"                               
[10] "10.1016/s0929-693x(97)86846-7"                              
[11] "10.1002/(SICI)1096-9071(199601)48:1<53::AID-JMV9>3.0.CO;2-K"
[12] "10.1016/s0267-7261(01)00016-1"                              
[13] "10.1111/j.1748-0361.2003.tb00575.x"                         
[14] "10.1097/00005721-197701000-00011"                           
[15] "10.1007/s00894-009-0593-z"                                  
[16] "10.1071/AR9830063"                                          
[17] "10.1186/gb-2009-10-4-r39"                                   
[18] "10.2165/00128415-201113540-00038"                           
[19] "10.1007/BF00522986"                                         
[20] "10.1080/19407963.2011.539385"
{% endhighlight %}

	
*********
	
### Search the CrossRef Metatdata API. 
	

{% highlight r %}
# Search for two different query terms
crossref_search(query = c("renear", "palmer"), rows = 4)[, 1:3]

                            doi score normalizedScore
1       10.1126/science.1157784 3.253             100
2  10.1002/meet.2009.1450460141 2.169              66
3 10.4242/BalisageVol3.Renear01 2.102              64
4 10.4242/BalisageVol5.Renear01 2.102              64
{% endhighlight %}



{% highlight r %}

# Get results for a certain year
crossref_search(query = c("renear", "palmer"), year = 2010)[, 1:3]

                                  doi  score normalizedScore
1            10.1002/meet.14504701218 1.0509             100
2            10.1002/meet.14504701240 1.0509             100
3           10.5270/OceanObs09.cwp.68 1.0442              99
4               10.1353/mpq.2010.0003 0.6890              65
5                  10.1353/mpq.0.0041 0.6890              65
6                  10.1353/mpq.0.0044 0.6890              65
7                  10.1353/mpq.0.0057 0.6890              65
8                    10.1386/fm.1.1.2 0.6890              65
9                    10.1386/fm.1.2.2 0.6890              65
10                   10.1386/fm.1.3.2 0.6890              65
11       10.1097/ALN.0b013e3181f09404 0.6090              57
12      10.1016/j.urology.2010.02.033 0.6090              57
13              10.1353/ect.2010.0025 0.6090              57
14               10.1117/2.4201001.04 0.6090              57
15 10.1111/j.1835-9310.1977.tb01159.x 0.6090              57
16    10.4067/S0717-69962010000100001 0.6090              57
17    10.4067/S0717-69962010000200001 0.6090              57
18           10.2105/AJPH.2009.191098 0.6029              57
19              10.1353/mpq.2010.0004 0.5167              49
20                 10.1353/mpq.0.0048 0.5167              49
{% endhighlight %}

	
*********
	
### Get a short DOI from shortdoi.org.
	

{% highlight r %}
# Geta a short DOI, just the short DOI returned
short_doi(doi = "10.1371/journal.pone.0042793")

[1] "10/f2bfz9"
{% endhighlight %}



{% highlight r %}

# Geta a short DOI, all data returned
short_doi(doi = "10.1371/journal.pone.0042793", justshort = FALSE)

$DOI
[1] "10.1371/journal.pone.0042793"

$ShortDOI
[1] "10/f2bfz9"

$IsNew
[1] FALSE
{% endhighlight %}

	
*********
	
### Get a record from a OAI-PMH data provider.
	

{% highlight r %}
# Single provider, one identifier
md_getrecord(provider = "pensoft", identifier = "10.3897/zookeys.1.10")

                                                                                                title
1 A new candidate for a Gondwanaland distribution in the Zodariidae (Araneae): Australutica in Africa
      creator date             type
1 Jocqué,Rudy 2008 Research Article
{% endhighlight %}



{% highlight r %}

# Single provider, multiple identifiers
md_getrecord(provider = "pensoft", identifier = c("10.3897/zookeys.1.10", "10.3897/zookeys.4.57"))

                                                                                                   title
1    A new candidate for a Gondwanaland distribution in the Zodariidae (Araneae): Australutica in Africa
2 Studies of Tiger Beetles. CLXXVIII. A new Lophyra (Lophyra) from Somaliland (Coleoptera, Cicindelidae)
        creator date             type
1   Jocqué,Rudy 2008 Research Article
2 Cassola,Fabio 2008 Research Article
{% endhighlight %}

	
*********

### List available metadata formats from various providers. 
	

{% highlight r %}
# List metadata formats for a provider
md_listmetadataformats(provider = "dryad")

  metadataPrefix
1         oai_dc
2            rdf
3            ore
4           mets
                                                       schema
1              http://www.openarchives.org/OAI/2.0/oai_dc.xsd
2                 http://www.openarchives.org/OAI/2.0/rdf.xsd
3 http://tweety.lanl.gov/public/schemas/2008-06/atom-tron.sch
4                  http://www.loc.gov/standards/mets/mets.xsd
                            metadataNamespace
1 http://www.openarchives.org/OAI/2.0/oai_dc/
2    http://www.openarchives.org/OAI/2.0/rdf/
3                 http://www.w3.org/2005/Atom
4                    http://www.loc.gov/METS/
{% endhighlight %}



{% highlight r %}

# List metadata formats for a specific identifier for a provider
md_listmetadataformats(provider = "pensoft", identifier = "10.3897/zookeys.1.10")

            identifier metadataPrefix
1 10.3897/zookeys.1.10         oai_dc
2 10.3897/zookeys.1.10           mods
                                             schema
1    http://www.openarchives.org/OAI/2.0/oai_dc.xsd
2 http://www.loc.gov/standards/mods/v3/mods-3-1.xsd
                            metadataNamespace
1 http://www.openarchives.org/OAI/2.0/oai_dc/
2                  http://www.loc.gov/mods/v3
{% endhighlight %}


*********

### Some plotting - mean number of authors per paper

Okay, so this isn't a super useful visualization, but you can surely think of something better. 


{% highlight r %}
library(ggplot2)
library(ggthemes)
library(reshape)


temp <- md_listrecords(provider = "pensoft", from = "2011-10-01", until = "2012-01-01")
temp2 <- ldply(temp)[, -1]
auths <- sapply(temp2$creator, function(x) length(strsplit(as.character(x), 
    ";")[[1]]))
toplot <- data.frame(authors = auths, articletype = temp2$type)
toplot_ <- ddply(toplot, .(articletype), summarise, authors = mean(authors))
toplot_$articletype <- reorder(toplot_$articletype, toplot_$authors)

ggplot(toplot_, aes(articletype, authors)) + theme_tufte(base_size = 16) + geom_bar(stat = "identity") + 
    coord_flip()
{% endhighlight %}

![center](/public/img/someplotting.png)

***************

#### Get the .Rmd file used to create this post [at my github account](https://github.com/sckott/sckott.github.com/tree/master/_drafts/2013-03-16-r-metadata.Rmd) - or [.md file](https://github.com/sckott/sckott.github.com/tree/master/_posts/2013-03-16-r-metadata.md).

#### Written in [Markdown](http://daringfireball.net/projects/markdown/), with help from [knitr](http://yihui.name/knitr/), and [knitcitations](https://github.com/cboettig/knitcitations).

  </div>
  
  <div class="post">
    <h1>
      <a href="/2013/03/ropensci-collaboration/">
        Visualizing rOpenSci collaboration
      </a>
    </h1>

    <span class="post-date">08 Mar 2013</span>

    We ([rOpenSci](http://ropensci.org/)) have been writing code for R packages for a couple years, so it is time to take a look back at the data. What data you ask? The commits data from GitHub ~ data that records who did what and when. 

Using the [Github commits API](http://developer.github.com/v3/repos/commits/) we can gather data on who commited code to a Github repository, and when they did it. Then we can visualize this hitorical record. 

***************

### Install some functions for interacting with the Github API via R

{% highlight r %}

install_github('sandbox', 'ropensci') 

library(sandbox)
library(httr)
library(ggplot2)
library(scales)
library(reshape2)
library(bipartite)
library(doMC)
library(plyr)
library(ggthemes)
library(picante)

# And authenticate - pops open a page in your default browser, then tells 
# you authentication was successful
github_auth()
{% endhighlight %}


***************

### Get all repos for an organization, here ropensci of course

{% highlight r %}
ropensci_repos <- github_allrepos(userorg = "ropensci")
{% endhighlight %}


***************

### Get commits broken down in to additions and deletions, though below we just collapse them to all commits

{% highlight r %}
registerDoMC(cores = 4)
github_commits_safe <- plyr::failwith(NULL, github_commits)
out <- llply(ropensci_repos, function(x) github_commits_safe("ropensci", x, 
    since = "2009-01-01T", limit = 500), .parallel = TRUE)
names(out) <- ropensci_repos
out2 <- compact(out)
outdf <- ldply(out2)
{% endhighlight %}


***************

### Plot commits by date and repo

{% highlight r %}
outdf_subset <- outdf[!outdf$.id %in% c("citeulike", "challenge", "docs", "ropensci-book", 
    "usecases", "textmine", "usgs", "ropenscitoolkit", "neotoma", "rEWDB", "rgauges", 
    "rodash", "ropensci.github.com", "ROAuth"), ]
outdf_subset$.id <- tolower(outdf_subset$.id)
outdf_subset <- ddply(outdf_subset, .(.id, date), summarise, value = sum(value))

mindates <- llply(unique(outdf_subset$.id), function(x) min(outdf_subset[outdf_subset$.id == 
    x, "date"]))
names(mindates) <- unique(outdf_subset$.id)
mindates <- sort(do.call(c, mindates))
outdf_subset$.id <- factor(outdf_subset$.id, levels = names(mindates))

ggplot(outdf_subset, aes(date, value, fill = .id)) + 
    geom_bar(stat = "identity", width = 0.5) + 
    geom_rangeframe(sides = "b", colour = "grey") + 
    theme_bw(base_size = 9) + 
    scale_x_date(labels = date_format("%Y"), breaks = date_breaks("year")) + 
    scale_y_log10() + 
    facet_grid(.id ~ .) + 
    labs(x = "", y = "") + 
    theme(axis.text.y = element_blank(), 
        axis.text.x = element_text(colour = "black"), 
        axis.ticks.y = element_blank(), 
        strip.text.y = element_text(angle = 0, size = 8, ), 
        strip.background = element_rect(size = 0), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), 
        legend.text = element_text(size = 8), 
        legend.position = "none", 
        panel.border = element_blank())
{% endhighlight %}


![center](/public/img/commitsbydate.png) 


The plot above plots the sum of additions+deletions, and is sorted by the first commit date of reach repo, with the first being [treebase](https://github.com/ropensci/treeBASE), which wraps the [Treebase API](http://treebase.org/treebase-web/urlAPI.html), and the most recent being [rwbclimate](https://github.com/ropensci/rWBclimate), which wraps the [World Blank climate data API](http://data.worldbank.org/developers/climate-data-api). 

You can see that some repos have recieved commits more or less consistently over their life time, while others have seen a little development here and there. 

***************
w
### In addition, there are quite a few people that have committed code now to rOpenSci repos, calling for a network vizualization of course.

{% highlight r %}
outdf_network <- droplevels(outdf[!outdf$.id %in% c("citeulike", "challenge", 
    "docs", "ropensci-book", "usecases", "textmine", "usgs", "ropenscitoolkit", 
    "retriever", "rodash", "ropensci.github.com", "ROAuth", "rgauges", "sandbox", 
    "rfna", "rmetadata", "rhindawi", "rpmc", "rpensoft", "ritis"), ])
casted <- dcast(outdf_network, .id + date + name ~ variable, fun.aggregate = length, 
    value.var = "value")
names(casted)[1] <- "repo"
casted2 <- ddply(casted, .(repo, name), summarise, commits = sum(additions))
casted2 <- data.frame(repo = casted2$repo, weight = casted2$commits, name = casted2$name)
mat <- sample2matrix(casted2)
plotweb(sortweb(mat, sort.order = "dec"), method = "normal", text.rot = 90, 
    adj.high = c(-0.3, 0), adj.low = c(1, -0.3), y.width.low = 0.05, y.width.high = 0.05, 
    ybig = 0.09, labsize = 0.7)
{% endhighlight %}

![center](/public/img/collabnetwork.png) 


The plot above shows repos on one side and contributors on the other. Some folks (the core rOpenSci team: cboettig, karthikram, emhart, and schamberlain) have committed quite a lot to many packages. We also have amny awesome contributors to our packages (some contributors and repos have been removed for clarity). 

rOpenSci is truly a collaborative effort to develop tools for open science, so thanks to all our contributors - keep on forking, pull requesting, and commiting. 

  </div>
  
  <div class="post">
    <h1>
      <a href="/2013/02/academia-reboot/">
        Academia reboot
      </a>
    </h1>

    <span class="post-date">22 Feb 2013</span>

    ## Reboot

We need to reboot academia, at least for graduate training. I am speaking from the point of view of ecology/evolution (EEB). Why you ask? Because of the following line of reasoning:

+ First, the most important factor for me comes down to supply and demand. We have too much supply (=graduate students) and not enough demand (=faculty positions, etc.) - see [this comic at PhDComics](http://www.phdcomics.com/comics/archive.php?comicid=911) for proof. This seems especially apparent when you hear from your fellow postdoc friends that there were hundreds of other people with Ph.D.'s applying for the same position. 

+ Second, funding is getting thin. I have never received funding from a competitive grant, despite having 12 published papers to my name. Recent cuts to the NSF, NIH, and other federal agencies mean that getting a grant will be harder and harder. Furthermore, the mean age of a first time NIH grant recipient in 2008 was 51 according to a recent study in PLoS One (Matthews _et. al._ 2011). 

+ Third, we don't learn the skills we really need. This is many fold. First, we don't learn the appropriate mathematical and statistical techniques in undergraduate and grad school - a forthcoming paper found that in a survey of nearly 1000 ecology and evolution graduate students, most thought they were unprepared wrt to math and stats (interview with author in Soundcloud widget below). Second, we don't learn enough computational skills. Digital data (not on your physical clipboard, but your digital one) is more and more important, requiring knowing how to leverage and keep track of data. Yet, we aren't taught these skills, at least in my experience. The need for training in computation/coding is evident from the sold out [Software Carpentry workshops](http://software-carpentry.org/). Third, reproducibility is not something we are taught. Well, we are taught to check over everything in detail (read: proof your data), but there is often no way to reproduce analyses when we use 10 different expensive software programs to do an analysis (read: MS Word, JMP, SAS, SigmaPlot, etc.). And isn't reproduciblity important?

***************

<iframe width="30%" height="140" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=http%3A%2F%2Fapi.soundcloud.com%2Ftracks%2F78215101&amp;color=ff6600&amp;auto_play=false&amp;show_artwork=false"></iframe>

***************

## What do we do?

To address the supply/demand issue, I think we need fewer graduate students, period. I think this will work for a few reasons. If there are fewer graduate students, those that get in will be of higher quality because profs can be more selective, they may get payed more (hopefully) since there are few students, and they should in theory get more attention from their advisers (if they want it). In addition, there would be less competition for the very few grants out there for grad students.  This would then lead to fewer postdocs, and less competition for faculty positions. I think the supply/demand issue in EEB is particularly problematic. That is, in EEB there doesn't seem to be the large quantity of private sector jobs as there is for Ph.D. graduates in engineering, physics, etc. 

The funding situation is beyond me, but definitely makes me want to leave academia. Crowdfunding, especially [#SciFund](http://scifundchallenge.org/), is an option for scientists, but mostly only on a small financial scale. Any thoughts?

The skills issue will likely be addressed in time, and vary among schools for sure. Some schools will focus on natural history, which is good (that's where I did my undergrad and it was great), and some schools will incorporate more of these science 2.0 skills (advanced stats, better math training, and computer science).

***************

## _Thoughts?_

***************

#### Get the .Rmd file used to create this post [at my github account](https://github.com/sckott/sckott.github.com/tree/master/_drafts/2013-02-22-academia-reboot.Rmd) - or [.md file](https://github.com/sckott/sckott.github.com/tree/master/_posts/2013-02-22-academia-reboot.md).

#### Written in [Markdown](http://daringfireball.net/projects/markdown/), with help from [knitr](http://yihui.name/knitr/), and [knitcitations](https://github.com/cboettig/knitcitations).

***************

#### References
<p>Matthews KRW, Calhoun KM, lo N, ho V and Germano G (2011).
&ldquo;The Aging of Biomedical Research in The United States.&rdquo;
<EM>Plos One</EM>, <B>6</B>.
<a href="http://dx.doi.org/10.1371/journal.pone.0029738">http://dx.doi.org/10.1371/journal.pone.0029738</a>.


  </div>
  
</div>

<!-- Pagination links -->
<div class="pagination">
  
    <a href="/page26" class="older">Older</a>
  
  
    
      <a href="/page24" class="newer">Newer</a>
    
  
</div>

    </div>

    <!-- for bootstrap tooltips -->
    <script type="text/javascript">
      $("[data-toggle=\"tooltip\"]").tooltip();
    </script>

  </body>

  <footer>
  <!-- Disqus code -->
  <script type="text/javascript">
      /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
      var disqus_shortname = 'recology'; // required: replace example with your forum shortname

      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function () {
          var s = document.createElement('script'); s.async = true;
          s.type = 'text/javascript';
          s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
          (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
      }());
  </script>

  <!-- google analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-63197374-1', 'auto');
    ga('send', 'pageview');
  </script>
</footer>

</html>
