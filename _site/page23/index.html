<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  <link href="http://gmpg.org/xfn/11" rel="profile">

  <title>
    
    Recology, R/etc.
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Open+Sans:300,400italic,400,600,700|Abril+Fatface">

  <link rel="stylesheet" href="/public/css/bootstrap/css/bootstrap.css">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/favicon.ico">
  <link rel="shortcut icon" href="/public/favicon.ico">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.css" rel="stylesheet">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body class="theme-base-0f layout-reverse">

    <header class="masthead">
      <div class="masthead-inner">
        <h1>Recology</h1>
        <!-- <h1> <a href="http://recology.info/">Recology</a></h1> -->
        <p class="lead">R/etc.</p>

        <div class="colophon">
          <ul class="colophon-links">
            <li>
              <a href="/"><i class="fa fa-home fa-lg"></i></a>&nbsp;
              <a href="/about"><i class="fa fa-info-circle fa-lg"></i></a>&nbsp;
              <a href="/archives"><i class="fa fa-archive fa-lg"></i></a>&nbsp;
              <a href="/rresources"><i class="fa fa-book fa-lg"></i></a>&nbsp;
              <a href="http://rforcats.net/" rel><i class="fa fa-graduation-cap fa-lg"></i></a>&nbsp;
              <a href="/feed.xml"><i class="fa fa-rss fa-lg"></i></a>&nbsp;
              <a href="https://twitter.com/sckottie"><i class="fa fa-twitter fa-lg"></i></a>&nbsp;
              <a href="/fork"><i class="fa fa-spinner fa-lg"></i></a>
            </li>
          </ul>
          <!-- <small><a href="https://github.com/mdo/hyde">Hyde</a> from <a href="https://twitter.com/mdo" target="_blank">@mdo</a>.</small> -->
        </div>
      </div>
    </header>

    <div class="content container">
      <div class="posts">
  <a style="float:right;" href="/archives" data-toggle="tooltip" data-placement="bottom" title="Archives"><i class="fa fa-archive fa-lg"></i></a>
  <a style="float:right;" href="/tags"><i class="fa fa-tags fa-lg"></i></a>&nbsp;
  
  <div class="post">
    <h1>
      <a href="/2013/06/fylopic/">
        Fylopic, an R wrapper to Phylopic
      </a>
    </h1>

    <span class="post-date">01 Jun 2013</span>

    ## What is PhyloPic?

PhyloPic is an awesome new service - I'll let the creator, [Mike Keesey](http://tmkeesey.net/), explain what it is (paraphrasing here): 

> PhyloPic stores silhouette images of organisms, and each image is associated with taxonomic names, and stores the taxonomy of all taxa, allowing searching by taxonomic names. Anyone can submit silhouettes to PhyloPic. 

What is a silhouette?  It's like this:

![A silhouette](http://phylopic.org/assets/images/submissions/bedd622a-4de2-4067-8c70-4aa44326d229.128.png)

*by Gareth Monger*


What makes PhyloPic not just awesome, but super awesome? All or most images are licensed under [Creative Commons licenses](http://creativecommons.org/). This means you can use the silhouettes without having to ask or pay - just attribute. 

***************

## What is fylopic?

The idea behind Fylopic is to create modular bits and pieces (i.e., functions) to allow you to add silhouettes to not only ggplot2 plots, but base plots as well. That is, you can simply load fylopic in your R session, and add some silhouettes to your phylogeny, or your barchart, etc. - that is, `fylopic` is meant to be a helper in your workflow to add in silhouettes to visualizations. 

Some people prefer base plots while others prefer ggplot2 plots (me!), so it would be nice to have both options. Phylogenies at the moment render faster in base plots. I don't yet have implementations for base plots, but will come soon, or you can send a pull request to add it. 

One interesting use case could be to be able to get a set of silhouettes, then get a phylogeny for taxa associatd with the silhouettess using the NCBI taxonomy, but it's not easily available yet (though I may be able to use [Ben Morris' phylocommons](https://github.com/bendmorris/phylocommons) soon. This isn't doable yet, so in the example below the function `make_phylo` creates a phylogeny using `ape::rcoal`.

You could also do the reverse -> you have a phylogeny and then you could search Phylopic for silhouettes. 

***************

## Info

Check out the Phylopic website [here](http://phylopic.org/), and Phylopic API developer documentation [here](http://phylopic.org/api/). 

Also check out Ben Morris' Python wrapper to Phylopic [here](https://github.com/bendmorris/python-phylopic). 

***************

## What can you do with fylopic?

***************

#### Install fylopic

{% highlight r %}
install.packages("devtools")
library(devtools)
install_github("fylopic", "sckott")
{% endhighlight %}



{% highlight r %}
library(fylopic, quietly = TRUE)
{% endhighlight %}


***************

#### Plot a phylogeny with silhouettes at the tips

Here, I search for names based on keyword *Homo sapiens* - which returns many matche codes. With those results we search for any silhouettes associated with those codes. Then we download images. Finally, make a phylogeny with the silhouettes at the tips. Note that in this eample the phylogeny is just a random coalescent tree made using `ape::rcoal` - obviously, in the real world you'd want to do something more useful. 


{% highlight r %}
## search on Homo sapiens
searchres <- search_text(text = "Homo sapiens", options = "names")

### which returns UUIDs
searchres[1:3]
{% endhighlight %}



{% highlight text %}
[1] "74aea16b-666b-497a-b2cb-72201ad75a8e"
[2] "1ee65cf3-53db-4a52-9960-a9f7093d845d"
[3] "cc9ad8ee-3a82-4add-8d50-bc78f4ff6956"
{% endhighlight %}



{% highlight r %}

## search for images based on the UUIds
output <- search_images(uuid = searchres, options = c("pngFiles", "credit", 
    "canonicalName"))

### we got eight matches
output
{% endhighlight %}



{% highlight text %}
$`15444b9c-f17f-4d6e-89b5-5990096bcfb0`
$`15444b9c-f17f-4d6e-89b5-5990096bcfb0`$supertaxa
[1] "e547cd01-7dd1-495b-8239-52cf9971a609"
[2] "bd88f674-6976-4cb2-a46e-e6a12a8ba463"


$`fedf0e5f-f20a-442c-accf-eb84a3af8c6b`
$`fedf0e5f-f20a-442c-accf-eb84a3af8c6b`$supertaxa
[1] "e547cd01-7dd1-495b-8239-52cf9971a609"
[2] "bd88f674-6976-4cb2-a46e-e6a12a8ba463"


$`a88d3a4c-44d3-409e-87b6-516bd188c709`
$`a88d3a4c-44d3-409e-87b6-516bd188c709`$supertaxa
[1] "e547cd01-7dd1-495b-8239-52cf9971a609"
[2] "bd88f674-6976-4cb2-a46e-e6a12a8ba463"


$`d88164ec-3152-444b-b41c-4757a344a764`
$`d88164ec-3152-444b-b41c-4757a344a764`$supertaxa
[1] "9c6af553-390c-4bdd-baeb-6992cbc540b1"


$`da5eaeb7-1ed2-4b2e-ad4a-49993881d706`
$`da5eaeb7-1ed2-4b2e-ad4a-49993881d706`$supertaxa
[1] "9c6af553-390c-4bdd-baeb-6992cbc540b1"
{% endhighlight %}



{% highlight r %}

## download images
myobjs <- get_image(uuids = output, size = "128")

## make the phylogeny
make_phylo(pngobj = myobjs)
{% endhighlight %}

![center](/public/img/2013-06-01-fylopic/unnamed-chunk-1.png) 


***************

#### Plot a silhouette behind a plot

Notice in the below example that you can use normal `ggplot2` syntax, and simply add another layer (`add_phylopic` from `fylopic`) to the plot.


{% highlight r %}
library(ggplot2)
img <- get_image("27356f15-3cf8-47e8-ab41-71c6260b2724", size = "512")[[1]]
qplot(x = Sepal.Length, y = Sepal.Width, data = iris, geom = "point") + add_phylopic(img)
{% endhighlight %}

![center](/public/img/2013-06-01-fylopic/unnamed-chunk-2.png) 


***************

## What's next?

This is a side project, so if anyone has interest in helping please do contribute code, report bugs, request features, etc. 

  </div>
  
  <div class="post">
    <h1>
      <a href="/2013/05/rbison/">
        BISON USGS species occurrence data
      </a>
    </h1>

    <span class="post-date">27 May 2013</span>

    The USGS recently released a way to search for and get species occurrence records for the USA. The service is called [BISON](http://bison.usgs.ornl.gov/) (Biodiversity Information Serving Our Nation). The service has [a web interface](http://bison.usgs.ornl.gov/) for human interaction in a browser, and [two APIs](http://bison.usgs.ornl.gov/services.html) (application programming interface) to allow machines to interact with their database. One of the APIs allows you to search and retrieve data, and the other gives back maps as either a heatmap or a species occurrence map. The latter is more appropriate for working in a browser, so I'll leave that to the web app folks. 

The Core Science Analytics and Synthesis (CSAS) program of the US Geological Survey are responsible for BISON, and are the US node of the Global Biodiversity Information Facility (GBIF). BISON data is nested within that of GBIF, but has (or wil have?) additional data not in GBIF, as described on their *About* page:

> BISON has been initiated with the 110 million records GBIF makes available from the U.S. and is integrating millions more records from other sources each year

Have a look at their *Data providers* and *Statistics* tabs on the BISON website, which list where data comes from and how many searches and downloads have been done on each data provider.

We (rOpenSci) started an R package to interact with the BISON search API >> `rbison`. You may be thinking, but if the data in BISON is also in GBIF, why both making another R package for BISON? Good question. As I just said, BISON will have some data GBIF won't have. Also, the services (search API and map service) are different than those of GBIF. 

Check out the package on GitHub here [https://github.com/ropensci/rbison](https://github.com/ropensci/rbison). 

Here is a quick run through of some things you can do with `rbison`. 

***************

### Install ribson

{% highlight r %}
# Install rbison from GitHub using devtools, uncomment to install
# install.packages('devtools') library(devtools) install_github('rbison',
# 'ropensci')
library(rbison)
{% endhighlight %}


***************

### Search the BISON database for, of course, bison 
	

{% highlight r %}
# Do the search
out <- bison(species = "Bison bison", type = "scientific_name", start = 0, count = 10)

# Check that the returned object is the right class ('bison')
class(out)
{% endhighlight %}



{% highlight text %}
[1] "bison"
{% endhighlight %}


#### Get a summary of the data


{% highlight r %}
bison_data(out)
{% endhighlight %}



{% highlight text %}
  total observation fossil specimen unknown
1   761          30      4      709      18
{% endhighlight %}


#### Summary by counties (just the first 6 rows)


{% highlight r %}
head(bison_data(input = out, datatype = "counties"))
{% endhighlight %}



{% highlight text %}
  record_id total county_name      state
1     48295     7    Lipscomb      Texas
2     41025    15      Harney     Oregon
3     49017     8    Garfield       Utah
4     35031     2    McKinley New Mexico
5     56013     1     Fremont    Wyoming
6     40045     2       Ellis   Oklahoma
{% endhighlight %}


#### Summary of states


{% highlight r %}
bison_data(input = out, datatype = "states")
{% endhighlight %}



{% highlight text %}
      record_id total county_fips
1    Washington     1          53
2         Texas     8          48
3    New Mexico     8          35
4          Iowa     1          19
5       Montana     9          30
6       Wyoming   155          56
7        Oregon    15          41
8      Oklahoma    14          40
9        Kansas    10          20
10      Arizona     1          04
11       Alaska    29          02
12         Utah    16          49
13     Colorado    17          08
14     Nebraska     1          31
15 South Dakota    61          46
{% endhighlight %}


***************

### Map the results


{% highlight r %}
# Search for Ursus americanus (american black bear)
out <- bison(species = "Ursus americanus", type = "scientific_name", start = 0, 
    count = 200)

# Sweet, got some data
bison_data(out)
{% endhighlight %}



{% highlight text %}
  total observation fossil specimen literature unknown centroid
1  3792          59    125     3522         47      39       78
{% endhighlight %}


### Make some maps! Note that right now the county and state maps just plot the conterminous lower 48. The map of individual occurrences shows the lower 48 + Alaska


{% highlight r %}
# By county
bisonmap(out, tomap = "county")
{% endhighlight %}

![center](/public/img/2013-05-25-rbison/map11.png) 

{% highlight r %}

# By state
bisonmap(out, tomap = "state")
{% endhighlight %}

![center](/public/img/2013-05-25-rbison/map12.png) 

{% highlight r %}

# Individual locations
bisonmap(out)
{% endhighlight %}



{% highlight text %}
## Rendering map...plotting 199 points
{% endhighlight %}

![center](/public/img/2013-05-25-rbison/map13.png) 


*********
	
### When plotting occurrences, you can pass additional arguments into the `bisonmap` function.

#### For example, you can jitter the points


{% highlight r %}
bisonmap(input = out, geom = geom_jitter)
{% endhighlight %}



{% highlight text %}
## Rendering map...plotting 199 points
{% endhighlight %}

![center](/public/img/2013-05-25-rbison/map2.png) 


#### And you can specify by how much you want the points to jitter (here an extreme example to make it obvious)


{% highlight r %}
library(ggplot2)
bisonmap(input = out, geom = geom_jitter, jitter = position_jitter(width = 5))
{% endhighlight %}



{% highlight text %}
## Rendering map...plotting 199 points
{% endhighlight %}

![center](/public/img/2013-05-25-rbison/map3.png) 


*********

#### Let us know if you have any feature requests or find bugs at [our GitHub Issues page](https://github.com/ropensci/rbison/issues).

  </div>
  
  <div class="post">
    <h1>
      <a href="/2013/03/r-metadata/">
        Scholarly metadata in R
      </a>
    </h1>

    <span class="post-date">16 Mar 2013</span>

    Scholarly metadata - the meta-information surrounding articles - can be super useful.  Although metadata does not contain the full content of articles, it contains a lot of useful information, including title, authors, abstract, URL to the article, etc. 

One of the largest sources of metadata is provided via the Open Archives Initiative Protocol for Metadata Harvesting or [OAI-PMH](http://www.openarchives.org/OAI/openarchivesprotocol.html). Many publishers, provide their metadata through their own endpoint, and implement the standard OAI-PMH methods: [GetRecord](http://www.openarchives.org/OAI/openarchivesprotocol.html#GetRecord), [Identify](http://www.openarchives.org/OAI/openarchivesprotocol.html#Identify), [ListIdentifiers](http://www.openarchives.org/OAI/openarchivesprotocol.html#ListIdentifiers), [ListMetadataFormats](http://www.openarchives.org/OAI/openarchivesprotocol.html#ListMetadataFormats), [ListRecords](http://www.openarchives.org/OAI/openarchivesprotocol.html#ListRecords), and [ListSets](http://www.openarchives.org/OAI/openarchivesprotocol.html#ListSets). Many providers use OAI-PMH, including [DataCite](http://oai.datacite.org/), [Dryad](http://wiki.datadryad.org/Data_Access#OAI-PMH), and [PubMed](http://www.ncbi.nlm.nih.gov/pmc/tools/oai/).

Some data-/article-providers provide their metadata via their own APIs. For example, Nature Publishing Group provides their own metadata API [here](http://developers.nature.com/docs) in non OAI-PMH format; you can get PLoS metadata through their [search API](http://api.plos.org/), and the BHL (see below) provides their own custom metadata service.

In addition, CrossRef provides a number of metadata search services: [metadata search](http://search.labs.crossref.org/help/api) and [openurl](http://labs.crossref.org/openurl/). 

What about the other publishers? (please tell me if I'm wrong about these three) 

+ Springer has [a metadata API](http://dev.springer.com/docs), but it is terrible, soooo...
+ Elsevier, are you kidding? Well, they do have some sort of API service, but its a pain in the ass. 
+ Wiley, no better than Elsevier.

Note that metadata can live in other places:

+ Another package being developed by David Springate, [rpubmed](https://github.com/ropensci/rpubmed) can get PubMed metadata. 
+ Our wrapper to the Mendeley API, [RMendeley](https://github.com/ropensci/rmendeley), gets article metadata via Mendeley's database. 
+ Our wrapper to the Biodiversity Heritage Library API [here](http://www.biodiversitylibrary.org/api2/docs/docs.html) gets their metadata. 

No, you can't get metadata via Google Scholar - the don't allow scraping, and don't have expose their data via an API.

I have discussed this package [in a previous blog post](http://sckott.github.io/2012/09/rmetadata/), but have since worked on the code a bit, and thought it deserved a new post. 

You can see a tutorial for this package [here](http://ropensci.github.com/rmetadata/), and contribute to the code [here](https://github.com/ropensci/rmetadata).

***************

### Install rmetadata

{% highlight r %}
# install_github('rmetadata', 'ropensci') # uncomment to install
library(rmetadata)
{% endhighlight %}


***************

### Count OAI-PMH identifiers for a data provider.
	

{% highlight r %}
# For DataCite.
count_identifiers("datacite")

  provider   count
1 datacite 1216193
{% endhighlight %}


*********
	
### Lookup article info via CrossRef with DOI and get a citation.

#### As Bibtex
	

{% highlight r %}
print(crossref_citation("10.3998/3336451.0009.101"), style = "Bibtex")

@Article{,
  title = {In Google We Trust?},
  author = {Geoffrey Bilder},
  journal = {The Journal of Electronic Publishing},
  year = {2006},
  month = {01},
  volume = {9},
  doi = {10.3998/3336451.0009.101},
}
{% endhighlight %}

	
#### As regular text
	

{% highlight r %}
print(crossref_citation("10.3998/3336451.0009.101"), style = "text")

Bilder G (2006). "In Google We Trust?" _The Journal of Electronic
Publishing_, *9*. <URL:
http://dx.doi.org/10.3998/3336451.0009.101>.
{% endhighlight %}

	
*********
	
### Search the CrossRef Metatdata for DOIs using free form references.
	
#### Search with title, author, year, and journal
	

{% highlight r %}
crossref_search_free(query = "Piwowar Sharing Detailed Research Data Is Associated with Increased Citation Rate PLOS one 2007")

                                                                                             text
1 Piwowar Sharing Detailed Research Data Is Associated with Increased Citation Rate PLOS one 2007
  match                   doi score
1  TRUE 10.1038/npre.2007.361 4.905
{% endhighlight %}

	
#### Get a DOI and get the citation using \code{crossref_search}
	

{% highlight r %}
# Get a DOI for a paper
doi <- crossref_search_free(query = "Piwowar sharing data PLOS one")$doi

# Get the metadata
crossref_search(doi = doi)[, 1:3]

                           doi score normalizedScore
1 10.1371/journal.pone.0000308 18.19             100
{% endhighlight %}


*********
	
### Get a random set of DOI's through CrossRef.
	

{% highlight r %}
# Default search gets 20 random DOIs
crossref_r()

 [1] "10.4028/www.scientific.net/MSF.126-128.467"
 [2] "10.2139/ssrn.548523"                       
 [3] "10.1016/S0012-821X(02)00562-9"             
 [4] "10.1093/rsq/13.2-3.167"                    
 [5] "10.5772/55055"                             
 [6] "10.1515/BC.1999.050"                       
 [7] "10.1016/S0020-7292(98)90160-6"             
 [8] "10.1111/j.1439-0418.1985.tb02788.x"        
 [9] "10.1089/aid.2012.0115"                     
[10] "10.1016/0002-9378(95)90155-8"              
[11] "10.1001/jama.1949.02900490055028"          
[12] "10.1051/jphyscol:1989172"                  
[13] "10.1016/s0301-2115(03)00298-7"             
[14] "10.1007/BF02735292"                        
[15] "10.1016/0003-4916(65)90026-6"              
[16] "10.4156/jdcta.vol5.issue5.12"              
[17] "10.1007/s10904-009-9316-2"                 
[18] "10.1023/A:1021690001832"                   
[19] "10.1007/s12262-012-0724-0"                 
[20] "10.1007/bf02192860"
{% endhighlight %}



{% highlight r %}

# Specify you want journal articles only
crossref_r(type = "journal_article")

 [1] "10.1016/j.jacc.2011.09.055"                                 
 [2] "10.1002/dev.420170603"                                      
 [3] "10.4315/0362-028X.JFP-10-403"                               
 [4] "10.1016/S0925-4927(98)00016-X"                              
 [5] "10.1111/j.1933-1592.2002.tb00141.x"                         
 [6] "10.1541/ieejfms.127.629"                                    
 [7] "10.5539/enrr.v3n1p62"                                       
 [8] "10.1016/S0960-9776(96)90038-7"                              
 [9] "10.1016/0925-9635(94)05240-9"                               
[10] "10.1016/s0929-693x(97)86846-7"                              
[11] "10.1002/(SICI)1096-9071(199601)48:1<53::AID-JMV9>3.0.CO;2-K"
[12] "10.1016/s0267-7261(01)00016-1"                              
[13] "10.1111/j.1748-0361.2003.tb00575.x"                         
[14] "10.1097/00005721-197701000-00011"                           
[15] "10.1007/s00894-009-0593-z"                                  
[16] "10.1071/AR9830063"                                          
[17] "10.1186/gb-2009-10-4-r39"                                   
[18] "10.2165/00128415-201113540-00038"                           
[19] "10.1007/BF00522986"                                         
[20] "10.1080/19407963.2011.539385"
{% endhighlight %}

	
*********
	
### Search the CrossRef Metatdata API. 
	

{% highlight r %}
# Search for two different query terms
crossref_search(query = c("renear", "palmer"), rows = 4)[, 1:3]

                            doi score normalizedScore
1       10.1126/science.1157784 3.253             100
2  10.1002/meet.2009.1450460141 2.169              66
3 10.4242/BalisageVol3.Renear01 2.102              64
4 10.4242/BalisageVol5.Renear01 2.102              64
{% endhighlight %}



{% highlight r %}

# Get results for a certain year
crossref_search(query = c("renear", "palmer"), year = 2010)[, 1:3]

                                  doi  score normalizedScore
1            10.1002/meet.14504701218 1.0509             100
2            10.1002/meet.14504701240 1.0509             100
3           10.5270/OceanObs09.cwp.68 1.0442              99
4               10.1353/mpq.2010.0003 0.6890              65
5                  10.1353/mpq.0.0041 0.6890              65
6                  10.1353/mpq.0.0044 0.6890              65
7                  10.1353/mpq.0.0057 0.6890              65
8                    10.1386/fm.1.1.2 0.6890              65
9                    10.1386/fm.1.2.2 0.6890              65
10                   10.1386/fm.1.3.2 0.6890              65
11       10.1097/ALN.0b013e3181f09404 0.6090              57
12      10.1016/j.urology.2010.02.033 0.6090              57
13              10.1353/ect.2010.0025 0.6090              57
14               10.1117/2.4201001.04 0.6090              57
15 10.1111/j.1835-9310.1977.tb01159.x 0.6090              57
16    10.4067/S0717-69962010000100001 0.6090              57
17    10.4067/S0717-69962010000200001 0.6090              57
18           10.2105/AJPH.2009.191098 0.6029              57
19              10.1353/mpq.2010.0004 0.5167              49
20                 10.1353/mpq.0.0048 0.5167              49
{% endhighlight %}

	
*********
	
### Get a short DOI from shortdoi.org.
	

{% highlight r %}
# Geta a short DOI, just the short DOI returned
short_doi(doi = "10.1371/journal.pone.0042793")

[1] "10/f2bfz9"
{% endhighlight %}



{% highlight r %}

# Geta a short DOI, all data returned
short_doi(doi = "10.1371/journal.pone.0042793", justshort = FALSE)

$DOI
[1] "10.1371/journal.pone.0042793"

$ShortDOI
[1] "10/f2bfz9"

$IsNew
[1] FALSE
{% endhighlight %}

	
*********
	
### Get a record from a OAI-PMH data provider.
	

{% highlight r %}
# Single provider, one identifier
md_getrecord(provider = "pensoft", identifier = "10.3897/zookeys.1.10")

                                                                                                title
1 A new candidate for a Gondwanaland distribution in the Zodariidae (Araneae): Australutica in Africa
      creator date             type
1 Jocqué,Rudy 2008 Research Article
{% endhighlight %}



{% highlight r %}

# Single provider, multiple identifiers
md_getrecord(provider = "pensoft", identifier = c("10.3897/zookeys.1.10", "10.3897/zookeys.4.57"))

                                                                                                   title
1    A new candidate for a Gondwanaland distribution in the Zodariidae (Araneae): Australutica in Africa
2 Studies of Tiger Beetles. CLXXVIII. A new Lophyra (Lophyra) from Somaliland (Coleoptera, Cicindelidae)
        creator date             type
1   Jocqué,Rudy 2008 Research Article
2 Cassola,Fabio 2008 Research Article
{% endhighlight %}

	
*********

### List available metadata formats from various providers. 
	

{% highlight r %}
# List metadata formats for a provider
md_listmetadataformats(provider = "dryad")

  metadataPrefix
1         oai_dc
2            rdf
3            ore
4           mets
                                                       schema
1              http://www.openarchives.org/OAI/2.0/oai_dc.xsd
2                 http://www.openarchives.org/OAI/2.0/rdf.xsd
3 http://tweety.lanl.gov/public/schemas/2008-06/atom-tron.sch
4                  http://www.loc.gov/standards/mets/mets.xsd
                            metadataNamespace
1 http://www.openarchives.org/OAI/2.0/oai_dc/
2    http://www.openarchives.org/OAI/2.0/rdf/
3                 http://www.w3.org/2005/Atom
4                    http://www.loc.gov/METS/
{% endhighlight %}



{% highlight r %}

# List metadata formats for a specific identifier for a provider
md_listmetadataformats(provider = "pensoft", identifier = "10.3897/zookeys.1.10")

            identifier metadataPrefix
1 10.3897/zookeys.1.10         oai_dc
2 10.3897/zookeys.1.10           mods
                                             schema
1    http://www.openarchives.org/OAI/2.0/oai_dc.xsd
2 http://www.loc.gov/standards/mods/v3/mods-3-1.xsd
                            metadataNamespace
1 http://www.openarchives.org/OAI/2.0/oai_dc/
2                  http://www.loc.gov/mods/v3
{% endhighlight %}


*********

### Some plotting - mean number of authors per paper

Okay, so this isn't a super useful visualization, but you can surely think of something better. 


{% highlight r %}
library(ggplot2)
library(ggthemes)
library(reshape)


temp <- md_listrecords(provider = "pensoft", from = "2011-10-01", until = "2012-01-01")
temp2 <- ldply(temp)[, -1]
auths <- sapply(temp2$creator, function(x) length(strsplit(as.character(x), 
    ";")[[1]]))
toplot <- data.frame(authors = auths, articletype = temp2$type)
toplot_ <- ddply(toplot, .(articletype), summarise, authors = mean(authors))
toplot_$articletype <- reorder(toplot_$articletype, toplot_$authors)

ggplot(toplot_, aes(articletype, authors)) + theme_tufte(base_size = 16) + geom_bar(stat = "identity") + 
    coord_flip()
{% endhighlight %}

![center](/public/img/someplotting.png)

***************

#### Get the .Rmd file used to create this post [at my github account](https://github.com/sckott/sckott.github.com/tree/master/_drafts/2013-03-16-r-metadata.Rmd) - or [.md file](https://github.com/sckott/sckott.github.com/tree/master/_posts/2013-03-16-r-metadata.md).

#### Written in [Markdown](http://daringfireball.net/projects/markdown/), with help from [knitr](http://yihui.name/knitr/), and [knitcitations](https://github.com/cboettig/knitcitations).

  </div>
  
</div>

<!-- Pagination links -->
<div class="pagination">
  
    <a href="/page24" class="older">Older</a>
  
  
    
      <a href="/page22" class="newer">Newer</a>
    
  
</div>

    </div>

    <!-- for bootstrap tooltips -->
    <script type="text/javascript">
      $("[data-toggle=\"tooltip\"]").tooltip();
    </script>

  </body>

  <footer>
  <!-- Disqus code -->
  <script type="text/javascript">
      /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
      var disqus_shortname = 'recology'; // required: replace example with your forum shortname

      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function () {
          var s = document.createElement('script'); s.async = true;
          s.type = 'text/javascript';
          s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
          (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
      }());
  </script>

  <!-- google analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-63197374-1', 'auto');
    ga('send', 'pageview');
  </script>
</footer>

</html>
