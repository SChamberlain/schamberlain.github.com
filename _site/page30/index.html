<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  <link href="http://gmpg.org/xfn/11" rel="profile">

  <title>
    
    Recology, R/etc.
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Open+Sans:300,400italic,400,600,700|Abril+Fatface">

  <link rel="stylesheet" href="/public/css/bootstrap/css/bootstrap.css">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/favicon.ico">
  <link rel="shortcut icon" href="/public/favicon.ico">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.css" rel="stylesheet">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body class="theme-base-0f layout-reverse">

    <header class="masthead">
      <div class="masthead-inner">
        <h1>Recology</h1>
        <!-- <h1> <a href="http://recology.info/">Recology</a></h1> -->
        <p class="lead">R/etc.</p>

        <div class="colophon">
          <ul class="colophon-links">
            <li>
              <a href="/"><i class="fa fa-home fa-lg"></i></a>&nbsp;
              <a href="/about"><i class="fa fa-info-circle fa-lg"></i></a>&nbsp;
              <a href="/archives"><i class="fa fa-archive fa-lg"></i></a>&nbsp;
              <a href="/rresources"><i class="fa fa-book fa-lg"></i></a>&nbsp;
              <a href="http://rforcats.net/" rel><i class="fa fa-graduation-cap fa-lg"></i></a>&nbsp;
              <a href="/feed.xml"><i class="fa fa-rss fa-lg"></i></a>&nbsp;
              <a href="https://twitter.com/sckottie"><i class="fa fa-twitter fa-lg"></i></a>&nbsp;
              <a href="/fork"><i class="fa fa-spinner fa-lg"></i></a>
            </li>
          </ul>
          <!-- <small><a href="https://github.com/mdo/hyde">Hyde</a> from <a href="https://twitter.com/mdo" target="_blank">@mdo</a>.</small> -->
        </div>
      </div>
    </header>

    <div class="content container">
      <div class="posts">
  <a style="float:right;" href="/archives" data-toggle="tooltip" data-placement="bottom" title="Archives"><i class="fa fa-archive fa-lg"></i></a>
  <a style="float:right;" href="/tags"><i class="fa fa-tags fa-lg"></i></a>&nbsp;
  
  <div class="post">
    <h1>
      <a href="/2012/10/rgbif-newfxns/">
        GBIF biodiversity data from R - more functions
      </a>
    </h1>

    <span class="post-date">08 Oct 2012</span>

    #### UPDATE: In response to Jarrett's query I laid out a separate use case in which you may want to query by higher taxonomic rankings than species. See below.  In addition, added examples of querying by location in reply to comments by seminym. 

*****

We have been working on an R package to get GBIF data from R, with the stable version available through CRAN [here](URL), and the development version available on GitHub [here](http://github.com/rgbif). 

We had a Google Summer of code stuent work on the package this summer - you can see his work on the package over at his GitHub page [here]().  We have added some new functionality since his work, and would like to show it off. 

### Lets install rgbif first.

{% highlight r linenos %}
# install_github('rgbif', 'ropensci') # uncomment if not already installed
library(rgbif)
library(plyr)
library(XML)
library(httr)
library(maps)
library(ggplot2)
{% endhighlight %}


### Get taxonomic information on a specific taxon or taxa in GBIF by their taxon concept keys.

{% highlight r linenos %}
(keys <- taxonsearch(scientificname = "Puma concolor"))  # many matches to this search
{% endhighlight %}



{% highlight text %}
 [1] "51780668" "51758018" "50010499" "51773067" "51078815" "51798065"
 [7] "51088007" "50410780" "50305290" "51791438"
{% endhighlight %}



{% highlight r linenos %}
taxonget(keys[[1]])  # let's get the first one - the first row in the data.frame is the one we searched for (51780668)
{% endhighlight %}



{% highlight text %}
[[1]]
                    sciname taxonconceptkeys       rank
1             Puma concolor         51780668    species
2                      Puma         51780667      genus
3                   Felidae         51780651     family
4                 Carnivora         51780613      order
5                  Mammalia         51780547      class
6                  Chordata         51775774     phylum
7                  Animalia         51775773    kingdom
8 Puma concolor californica         51780669 subspecies
9   Puma concolor improcera         51780670 subspecies

{% endhighlight %}


### The `occurrencedensity` function was renamed to `densitylist` because it is in the `density` API service, not the `occurrence` API service.  You can use `densitylist` to get a data.frame of total occurrence counts by one-degree cell for a single taxon, country, dataset, data publisher or data network.  Just a quick reminder of what the function can do:

{% highlight r linenos %}
head(densitylist(originisocountrycode = "CA"))
{% endhighlight %}



{% highlight text %}
  cellid minLatitude maxLatitude minLongitude maxLongitude count
1  46913          40          41          -67          -66    44
2  46914          40          41          -66          -65   907
3  46915          40          41          -65          -64   510
4  46916          40          41          -64          -63   645
5  46917          40          41          -63          -62    56
6  46918          40          41          -62          -61   143
{% endhighlight %}


### Using a related function, `density_spplist`, you can get a species list by one-degree cell as well.

{% highlight r linenos %}
# Get a species list by cell, choosing one at random
density_spplist(originisocountrycode = "CO", spplist = "random")[1:10]
{% endhighlight %}



{% highlight text %}
 [1] "Abarema laeta (Benth.) Barneby & J.W.Grimes"
 [2] "Abuta grandifolia (Mart.) Sandwith"         
 [3] "Acalypha cuneata Poepp."                    
 [4] "Acalypha diversifolia Jacq."                
 [5] "Acalypha macrostachya Jacq."                
 [6] "Acalypha stachyura Pax"                     
 [7] "Acanthoscelio acutus"                       
 [8] "Accipiter collaris"                         
 [9] "Actitis macularia"                          
[10] "Adelobotrys klugii Wurdack"                 
{% endhighlight %}



{% highlight r linenos %}
# density_spplist(originisocountrycode = 'CO', spplist = 'r') # can
# abbreviate the `spplist` argument

# Get a species list by cell, choosing the one with the greatest no. of
# records
density_spplist(originisocountrycode = "CO", spplist = "great")[1:10]  # great is abbreviated from `greatest`
{% endhighlight %}



{% highlight text %}
 [1] "Acanthaceae Juss."                
 [2] "Accipitridae sp."                 
 [3] "Accipitriformes/Falconiformes sp."
 [4] "Apodidae sp."                     
 [5] "Apodidae sp. (large swift sp.)"   
 [6] "Apodidae sp. (small swift sp.)"   
 [7] "Arctiinae"                        
 [8] "Asteraceae Bercht. & J. Presl"    
 [9] "Asteraceae sp. 1"                 
[10] "Asteraceae sp. 6"                 
{% endhighlight %}



{% highlight r linenos %}

# Can also get a data.frame with counts instead of the species list
density_spplist(originisocountrycode = "CO", spplist = "great", listcount = "counts")[1:10, 
    ]
{% endhighlight %}



{% highlight text %}
                              names_ count
1                  Acanthaceae Juss.     2
2                   Accipitridae sp.     6
3  Accipitriformes/Falconiformes sp.     2
4                       Apodidae sp.     5
5     Apodidae sp. (large swift sp.)     8
6     Apodidae sp. (small swift sp.)     5
7                          Arctiinae     7
8      Asteraceae Bercht. & J. Presl     2
9                   Asteraceae sp. 1     6
10                  Asteraceae sp. 6    10
{% endhighlight %}


### You can now map point results, from fxns `occurrencelist` and those from `densitylist`, which plots them as points or as tiles, respectively.  Point map, using output from occurrencelist.

{% highlight r linenos %}
out <- occurrencelist(scientificname = "Puma concolor", coordinatestatus = TRUE, 
    maxresults = 100, latlongdf = T)
gbifmap(input = out)  # make a map, plotting on world map
{% endhighlight %}

![center](/public/img/gbifmap1.png) 


### Point map, using output from occurrencelist, with many species plotted as different colors

{% highlight r linenos %}
splist <- c("Accipiter erythronemius", "Junco hyemalis", "Aix sponsa", "Buteo regalis")
out <- lapply(splist, function(x) occurrencelist(x, coordinatestatus = T, maxresults = 100, 
    latlongdf = T))
gbifmap(out)
{% endhighlight %}

![center](/public/img/gbifmap2.png) 


### Tile map, using output from densitylist, using results in Canada only.

{% highlight r linenos %}
out2 <- densitylist(originisocountrycode = "CA")  # data for Canada
gbifmap(out2)  # on world map
{% endhighlight %}

![center](/public/img/gbifmap31.png) 

{% highlight r linenos %}
gbifmap(out2, region = "Canada")  # on Canada map
{% endhighlight %}

![NA](/public/img/gbifmap32.png) 


*****

### We can also query by higher taxonomic rankings, and map all lower species within that ranking. Above we queried by scientificname, but we can also query by higher taxonomy. 7071443 is the taxonconceptkey for 'Bacillariophyceae', a Class which includes many lower species. 

{% highlight r linenos %}
out <- densitylist(taxonconceptKey = 7071443)
gbifmap(out)
{% endhighlight %}

![center](/public/img/algae.png) 


### seminym asked about querying by area. You can query by area, though slightly differently for occurrencelist and densitylist functions. For occurrencelist you can search using min and max lat and long values (and min an max altitude, pretty cool, eh).  

{% highlight r linenos %}
# Get occurrences or density by area, using min/max lat/long coordinates
out <- occurrencelist(minlatitude = 30, maxlatitude = 35, minlongitude = -100, 
    maxlongitude = -95, coordinatestatus = T, maxresults = 5000, latlongdf = T)

# Using `geom_point`
gbifmap(out, "state", "texas", geom_point)
{% endhighlight %}

![center](/public/img/byarea_occurr1.png) 

{% highlight r linenos %}

# Using geom_jitter to move the points apart from one another
gbifmap(out, "state", "texas", geom_jitter, position_jitter(width = 0.3, height = 0.3))
{% endhighlight %}

![NA](/public/img/byarea_occurr2.png) 

{% highlight r linenos %}

# And move points a lot
gbifmap(out, "state", "texas", geom_jitter, position_jitter(width = 1, height = 1))
{% endhighlight %}

![NA](/public/img/byarea_occurr3.png) 


### And you can query by area in `densitylist` by specifying a place using the `originisocountrycode` argument (as done in an above example).  Just showing the head of the data.frame here.  

{% highlight r linenos %}
# Get density by place, note that you can't use the lat and long arguments
# in densitylist
head(densitylist(originisocountrycode = "CA"))
{% endhighlight %}



{% highlight text %}
  cellid minLatitude maxLatitude minLongitude maxLongitude count
1  46913          40          41          -67          -66    44
2  46914          40          41          -66          -65   907
3  46915          40          41          -65          -64   510
4  46916          40          41          -64          -63   645
5  46917          40          41          -63          -62    56
6  46918          40          41          -62          -61   143
{% endhighlight %}


*********
#### Get the .Rmd file used to create this post [at my github account](https://github.com/sckott/sckott.github.com/tree/master/_drafts/2012-10-08-rgbif-newfxns.Rmd) - or [.md file](https://github.com/sckott/sckott.github.com/tree/master/_posts/2012-10-08-rgbif-newfxns.md).

#### Written in [Markdown](http://daringfireball.net/projects/markdown/), with help from [knitr](http://yihui.name/knitr/).

  </div>
  
  <div class="post">
    <h1>
      <a href="/2012/09/rvertnet/">
        Vertnet - getting vertebrate museum record data and a quick map
      </a>
    </h1>

    <span class="post-date">19 Sep 2012</span>

    We ([rOpenSci](http://ropensci.org/)) started a repo to wrap the API for [VertNet](http://vertnet.org/index.php), an open access online database of vertebrate specimen records across many collection holders. Find the open source code [here](https://github.com/ropensci/rvertnet) - please contribute if you are so inclined.  We had a great Google Summer of Code student, [Vijay Barve](http://vijaybarve.wordpress.com/) contributing to the repo this summer, so it is getting close to being CRAN-able. 

Most of the functions in the repo get you the raw data, but there were no functions to visualize the data.  Since much of the data records of latitude and longitude data, maps are a natural visualization to use.  

What follows is a quick example of using the basic `vertmap` function.

### First, let's install `rvertnet`

{% highlight r linenos %}
# install_github('rvertnet', 'ropensci') # uncomment if not installed
# already
library(rvertnet)
{% endhighlight %}


### First, let's get some data using `vertoccurrence`

{% highlight r linenos %}
out <- vertoccurrence(q = "larva", num = 100)  # get records on keyword 'larva', limit to 100
nrow(out)  # how many rows?
{% endhighlight %}



{% highlight text %}
[1] 100
{% endhighlight %}


### Now map it using `vertmap`.  This is a very basic function: it simply cleans up the input data.frame, removing rows without lat/long data, and providing warnings when the input data.frame is not in the correct format.  `vertmap` uses the `ggplot2` framework for the map.  If you want to make you own map please do so -  this is just a simple fxn to get you started if you want to take a quick look at the data. 

{% highlight r linenos %}
vertmap(input = out)  # make a map using vertmap
{% endhighlight %}

![center](/public/img/vertmap.png) 


*********
#### Get the .Rmd file used to create this post [at my github account](https://github.com/sckott/sckott.github.com/tree/master/_drafts/2012-09-19-rvertnet.Rmd) - or [.md file](https://github.com/sckott/sckott.github.com/tree/master/_posts/2012-09-19-rvertnet.md).

#### Written in [Markdown](http://daringfireball.net/projects/markdown/), with help from [knitr](http://yihui.name/knitr/), and nice knitr highlighting/etc. in in [RStudio](http://rstudio.org/).

  </div>
  
  <div class="post">
    <h1>
      <a href="/2012/09/getting-data/">
        Getting data from figures in published papers
      </a>
    </h1>

    <span class="post-date">18 Sep 2012</span>

    ## The problem:
There are a lot of figures in published papers in the scholarly literature, like the below, from (Attwood _et. al._ 2012)):  

![alt text](/public/img/getfig2.png)

At some point, a scientist wants to ask a question for which they can synthesize the knowledge on that question by collecting data from the published literature.  This often requires something like the following workflow:

1. Search for relevant papers (e.g., via Google Scholar).
2. Collect the papers.
3. Decide which are appropriate for inclusion.
4. Collect data from the figures using software on a native application.  Examples include [GraphClick](http://www.arizona-software.ch/graphclick/) and [ImageJ](http://rsbweb.nih.gov/ij/).
5. Proof data. 
6. Analyze data & publish paper. 

This workflow needs revamping, particularly in step number 3 - collecting the data.  This data remains private, moving from one closed source (original publication) to another (personal computer).  We can surely do better.

## A solution
The data collection process (Step 3 above) can make use of modern technology, and be based in the browser. Some benefits of a browser based data collection approach:

+ Cross-platform: a data digitization program that lives in the browser can be more easily cross-platform (Linux/Mac/Windows) than a native app. 
+ Linked data: with the increasing abundance of APIs (application programming interfaces), we can link the data going into this app to anything of interest.  This is not so easy in a native app. 
+ Automatic updates: a web based browser can be updated easily without requiring a user to go get updates. 
+ User-based: a web based browser can easily integrate secure user login so that users can be associated with data collected, allowing for quantification of user-based error, and eventually user based scores/badges/etc. if so desired.

For those concerned about a browser based approach to data collection from figures, it will likely be possible to make it work offline as well, then send data up to servers when connected to the web again. 

What would be great about having data be public by default is that the work would be reproducible easily, at least on the data side of things. Hopefully the researchers would make all their code available publicly to recreate their analyses. 

## Question: Why would this idea work?
Better question: Why wouldn’t it work!

I think this idea could be awesome.  The reason I think it could be is based on two observations: 

1. There is a seemingly endless supply of academic papers with figures in them from which data can be extracted.**
2. There is increasing use of meta-analysis in science, which is fed by just this kind of data. 

** p.s. in the future, perhaps we will move to all SVG format figures or something even better, in which case data can be extracted from the underlying XML

## Okay, maybe it's a good idea, but who owns the data in figures in published papers?
As far as I know, and I've checked with a few knowledgeable people, no one owns this data. So it's ripe for the digitizing!

## Open access
I want this project to be totally open access (and I hope you do too).  I love models like GitHub where everything is public by default (unless you are an enterprise user, exceptions, exceptions), and I think that is what this requires.  You may be thinking though: "But I am collecting data for my meta-analysis and I don't want to share the data with anyone else".  My answer: "I understand where you are coming from, but it doesn't seem very likely that someone will be asking the exact same question as you and be looking for the data from the exact same papers".  There will just be a huge database of data from figures, and all the appropriate metadata of course.  Anyone should be able to use this.

## APIs
It would be great to build this from the start having an API in mind.  That is, how do we need to structure the data to be easily served up in an API to other websites, or pulled down to someone's local machine within Python or R to do data manipulation, analysis, and visualization?  We are going to need a key-value store database, such as MongoDB/CouchDB because ideally at least we would store the data collected, the figure itself, use information, etc. 

## What is being done about this?
I was fortunate enough to tag along with [Ted Hart](http://emhart.github.com/), a postdoc at [UBC](PUTINLINKHERE), on a recently submitted NCEAS working group proposal. Who knows if we'll get it, but we are already working on a prototype, so we will hit the ground running if we get funded, and just hit the ground, but walk a bit slower if we don't get the funding. 

## What could this be in the future?
At least in my mind, I think of this idea going the direction of gamification, including points, badges, etc., sort of like [FoldIt](http://fold.it/portal/) or [GalaxyZoo](http://www.galaxyzoo.org/).  At first we need alpha-, then beta-testers, which I imagine will most likely be academics exracting data for a meta-analysis for example.  But in the future, it would be great to make the interface enjoyable enough to attract non-academics, which could greatly increase the speed of data collection. 

Once there are a lot of people collecting data we can get many data points for every single data point in a graph.  Whereas right now, someone clicks on each data point in a graph one, maybe two times if they are lucky.  In the future, we could have ten different users clicking on each mean and each error bar in each graph.  So exciting!  The following figure illustrates this. 

![center](/public/img/clicks.png) 


## What do you think?
Is this idea totally insane?  Is it do-able?  Is it worth doing?

*********
#### Get the .Rmd file used to create this post [at my github account](https://github.com/sckott/sckott.github.com/tree/master/_drafts/2012-09-18-getting-data.Rmd) - or [.md file](https://github.com/sckott/sckott.github.com/tree/master/_posts/2012-09-18-getting-data.md).

#### Written in [Markdown](http://daringfireball.net/projects/markdown/), with help from [knitr](http://yihui.name/knitr/), and nice knitr highlighting/etc. in in [RStudio](http://rstudio.org/).

*********
#### References
<p>Attwood AS, Scott-Samuel NE, Stothart G, Munafò MR and Laks J (2012).
&ldquo;Glass Shape Influences Consumption Rate For Alcoholic Beverages.&rdquo;
<EM>Plos One</EM>, <B>7</B>.
<a href="http://dx.doi.org/10.1371/journal.pone.0043007">http://dx.doi.org/10.1371/journal.pone.0043007</a>.


  </div>
  
</div>

<!-- Pagination links -->
<div class="pagination">
  
    <a href="/page31" class="older">Older</a>
  
  
    
      <a href="/page29" class="newer">Newer</a>
    
  
</div>

    </div>

    <!-- for bootstrap tooltips -->
    <script type="text/javascript">
      $("[data-toggle=\"tooltip\"]").tooltip();
    </script>

  </body>

  <footer>
  <!-- Disqus code -->
  <script type="text/javascript">
      /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
      var disqus_shortname = 'recology'; // required: replace example with your forum shortname

      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function () {
          var s = document.createElement('script'); s.async = true;
          s.type = 'text/javascript';
          s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
          (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
      }());
  </script>

  <!-- google analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-63197374-1', 'auto');
    ga('send', 'pageview');
  </script>
</footer>

</html>
