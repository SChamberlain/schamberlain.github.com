<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  <link href="http://gmpg.org/xfn/11" rel="profile">

  <title>
    
    Recology, R/etc.
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Open+Sans:300,400italic,400,600,700|Abril+Fatface">

  <link rel="stylesheet" href="/public/css/bootstrap/css/bootstrap.css">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/favicon.ico">
  <link rel="shortcut icon" href="/public/favicon.ico">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.css" rel="stylesheet">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body class="theme-base-0f layout-reverse">

    <header class="masthead">
      <div class="masthead-inner">
        <h1>Recology</h1>
        <!-- <h1> <a href="http://recology.info/">Recology</a></h1> -->
        <p class="lead">R/etc.</p>

        <div class="colophon">
          <ul class="colophon-links">
            <li>
              <a href="/"><i class="fa fa-home fa-lg"></i></a>&nbsp;
              <a href="/about"><i class="fa fa-info-circle fa-lg"></i></a>&nbsp;
              <a href="/archives"><i class="fa fa-archive fa-lg"></i></a>&nbsp;
              <a href="/rresources"><i class="fa fa-book fa-lg"></i></a>&nbsp;
              <a href="http://rforcats.net/" rel><i class="fa fa-graduation-cap fa-lg"></i></a>&nbsp;
              <a href="/feed.xml"><i class="fa fa-rss fa-lg"></i></a>&nbsp;
              <a href="https://twitter.com/sckottie"><i class="fa fa-twitter fa-lg"></i></a>&nbsp;
              <a href="/fork"><i class="fa fa-spinner fa-lg"></i></a>
            </li>
          </ul>
          <!-- <small><a href="https://github.com/mdo/hyde">Hyde</a> from <a href="https://twitter.com/mdo" target="_blank">@mdo</a>.</small> -->
        </div>
      </div>
    </header>

    <div class="content container">
      <div class="posts">
  <a style="float:right;" href="/archives" data-toggle="tooltip" data-placement="bottom" title="Archives"><i class="fa fa-archive fa-lg"></i></a>
  <a style="float:right;" href="/tags"><i class="fa fa-tags fa-lg"></i></a>&nbsp;
  
  <div class="post">
    <h1>
      <a href="/2012/09/gov-dat/">
        Getting data on your government
      </a>
    </h1>

    <span class="post-date">01 Sep 2012</span>

    *********

I created an R package a while back to interact with some APIs that serve up data on what our elected represenatives are up to, including the [New York Times Congress API](http://developer.nytimes.com/), and the [Sunlight Labs API](http://services.sunlightlabs.com/).

What kinds of things can you do with `govdat`?  Here are a few examples. 

*********

### How do the two major parties differ in the use of certain words (searches the congressional record using the Sunlight Labs Capitol Words API)?

{% highlight r linenos %}
# install_github('govdat', 'sckott')
library(govdat)
library(reshape2)
library(ggplot2)

dems <- sll_cw_dates(phrase = "science", start_date = "1996-01-20", end_date = "2012-09-01", 
    granularity = "year", party = "D", printdf = TRUE)
repubs <- sll_cw_dates(phrase = "science", start_date = "1996-01-20", end_date = "2012-09-01", 
    granularity = "year", party = "R", printdf = TRUE)
df <- melt(rbind(data.frame(party = rep("D", nrow(dems)), dems), data.frame(party = rep("R", 
    nrow(repubs)), repubs)))
df$count <- as.numeric(df$count)

ggplot(df, aes(yearmonth, count, colour = party, group = party)) + geom_line() + 
    scale_colour_manual(values = c("blue", "red")) + labs(y = "use of the word 'Science'") + 
    theme_bw(base_size = 18) + opts(axis.text.x = theme_text(size = 10), panel.grid.major = theme_blank(), 
    panel.grid.minor = theme_blank(), legend.position = c(0.2, 0.8))
{% endhighlight %}

![center](/public/img/unnamed-chunk-1.png) 


*********

### Let's get some data on donations to individual elected representatives.

{% highlight r linenos %}
library(plyr)

# Let's get Nancy Pelosi's entity ID
sll_ts_aggregatesearch("Nancy Pelosi")[[1]]
{% endhighlight %}



{% highlight text %}
$name
[1] "Nancy Pelosi (D)"

$count_given
[1] 0

$firm_income
[1] 0

$count_lobbied
[1] 0

$seat
[1] "federal:house"

$total_received
[1] 13769274

$state
[1] "CA"

$lobbying_firm
NULL

$count_received
[1] 9852

$party
[1] "D"

$total_given
[1] 0

$type
[1] "politician"

$id
[1] "85ab2e74589a414495d18cc7a9233981"

$non_firm_spending
[1] 0

$is_superpac
NULL

{% endhighlight %}



{% highlight r linenos %}

# Her entity ID
sll_ts_aggregatesearch("Nancy Pelosi")[[1]]$id
{% endhighlight %}



{% highlight text %}
[1] "85ab2e74589a414495d18cc7a9233981"
{% endhighlight %}



{% highlight r linenos %}

# And search for her top donors by sector
nancy <- ldply(sll_ts_aggregatetopsectors(sll_ts_aggregatesearch("Nancy Pelosi")[[1]]$id))
nancy  # but just abbreviations for sectors
{% endhighlight %}



{% highlight text %}
   sector count     amount
1       F  1847 2698672.00
2       P   981 2243050.00
3       H   829 1412700.00
4       K  1345 1409836.00
5       Q  1223 1393154.00
6       N   829 1166187.00
7       B   537  932044.00
8       W   724  760800.00
9       Y   820  664926.00
10      E   201  283575.00
{% endhighlight %}



{% highlight r linenos %}
data(sll_ts_sectors)  # load sectors abbrevations data
nancy2 <- merge(nancy, sll_ts_sectors, by = "sector")  # attach full sector names
nancy2_melt <- melt(nancy2[, -1], id.vars = 3)
nancy2_melt$value <- as.numeric(nancy2_melt$value)

# and lets plot some results
ggplot(nancy2_melt, aes(sector_name, value)) + geom_bar() + coord_flip() + facet_wrap(~variable, 
    scales = "free", ncol = 1)
{% endhighlight %}

![center](/public/img/unnamed-chunk-2.png) 

{% highlight r linenos %}

## It looks like a lot of individual donations (the count facet) by
## finance/insurance/realestate, but by amount, the most (by slim margin)
## is from labor organizations.
{% endhighlight %}


*********

### Or we may want to get a bio of a congressperson. Here we get Todd Akin of MO. And some twitter searching too? Indeed.

{% highlight r linenos %}
out <- nyt_cg_memberbioroles("A000358")  # cool, lots of info, output cutoff for brevity
out[[3]][[1]][1:2]
{% endhighlight %}



{% highlight text %}
$member_id
[1] "A000358"

$first_name
[1] "Todd"

{% endhighlight %}



{% highlight r linenos %}

# we can get her twitter id from this bio, and search twitter using
# twitteR package
akintwitter <- out[[3]][[1]]$twitter_id

# install.packages('twitteR')
library(twitteR)
tweets <- userTimeline(akintwitter, n = 100)
tweets[1:5]  # there's some gems in there no doubt
{% endhighlight %}



{% highlight text %}
[[1]]
[1] "RepToddAkin: Do you receive my Akin Alert e-newsletter?  Pick the issues youâ€™d like to get updates on and sign up here!\nhttp://t.co/nZfiRjTF"

[[2]]
[1] "RepToddAkin: If the 2001 &amp; 2003 tax policies expire, taxes will increase over $4 trillion in the next 10 years. America can't afford it. #stopthetaxhike"

[[3]]
[1] "RepToddAkin: A govt agency's order shouldn't defy constitutional rights. I'm still working for #religiousfreedom and repealing the HHS mandate. #prolife"

[[4]]
[1] "RepToddAkin: I am a cosponsor of the bill being considered today to limit abortions in DC. RT if you agree! #prolife http://t.co/Mesrjl0w"

[[5]]
[1] "RepToddAkin: We need to #StopTheTaxHike. Raising taxes like the President wants would destroy more than 700,000 jobs. #4jobs http://t.co/KUTd0M7U"

{% endhighlight %}


*********

### Get the .Rmd file used to create this post [at my github account](https://github.com/sckott/sckott.github.com/tree/master/_drafts/2012-09-01-gov-dat.Rmd) - or [.md file](https://github.com/sckott/sckott.github.com/tree/master/_posts/2012-09-01-gov-dat.md).

*********

### Written in [Markdown](http://daringfireball.net/projects/markdown/), with help from [knitr](http://yihui.name/knitr/), and nice knitr highlighting/etc. in in [RStudio](http://rstudio.org/).

  </div>
  
  <div class="post">
    <h1>
      <a href="/2012/08/get-ecoevo-journal-titles/">
        Getting ecology and evolution journal titles from R
      </a>
    </h1>

    <span class="post-date">31 Aug 2012</span>

    *********

So I want to mine some #altmetrics data for some research I'm thinking about doing.  The steps would be: 

+ Get journal titles for ecology and evolution journals. 
+ Get DOI's for all papers in all the above journal titles. 
+ Get altmetrics data on each DOI. 
+ Do some fancy analyses. 
+ Make som pretty figs. 
+ Write up results. 

It's early days, so jus working on the first step.  However, getting a list of journals in ecology and evolution is frustratingly hard.  This turns out to not be that easy if you are (1) trying to avoid [Thomson Reuters](http://thomsonreuters.com/), and (2) want a machine interface way to do it (read: API). 

Unfortunately, Mendeley's API does not have methods for getting a list of journals by field, or at least I don't know how to do it using [their API](http://apidocs.mendeley.com/).  No worries though - [Crossref](http://crossref.org/) comes to save the day.   Here's my attempt at this using the [Crossref OAI-PMH](http://help.crossref.org/#using_oai_pmh).

*********

### I wrote a little while loop to get journal titles from the Crossref OAI-PMH. This takes a while to run, but at least it works on my machine - hopefully yours too!

{% highlight r linenos %}
library(XML)
library(RCurl)

token <- "characters"  # define a iterator, also used for gettingn the resumptionToken
nameslist <- list()  # define empty list to put joural titles in to
while (is.character(token) == TRUE) {
    baseurl <- "http://oai.crossref.org/OAIHandler?verb=ListSets"
    if (token == "characters") {
        tok2 <- NULL
    } else {
        tok2 <- paste("&resumptionToken=", token, sep = "")
    }
    query <- paste(baseurl, tok2, sep = "")
    crsets <- xmlToList(xmlParse(getURL(query)))
    names <- as.character(sapply(crsets[[4]], function(x) x[["setName"]]))
    nameslist[[token]] <- names
    if (class(try(crsets[[2]]$.attrs[["resumptionToken"]])) == "try-error") {
        stop("no more data")
    } else token <- crsets[[2]]$.attrs[["resumptionToken"]]
}
{% endhighlight %}


*********

### Yay!  Hopefully it worked if you tried it.  Let's see how long the list of journal titles is. 

{% highlight r linenos %}
sapply(nameslist, length)  # length of each list
{% endhighlight %}



{% highlight text %}
                          characters c65ebc3f-b540-4672-9c00-f3135bf849e3 
                               10001                                10001 
6f61b343-a8f4-48f1-8297-c6f6909ca7f7 
                                6864 
{% endhighlight %}



{% highlight r linenos %}
allnames <- do.call(c, nameslist)  # combine to list
length(allnames)
{% endhighlight %}



{% highlight text %}
[1] 26866
{% endhighlight %}


*********


### Now, let's use some `regex` to pull out the journal titles that are likely ecology and evolutionary biology journals.  The `^` symbol says "the string must start here". The `\\s` means whitespace.  The `[]` lets you specify a set of letters you are looking for, e.g., `[Ee]` means capital `E` *OR* lowercase `e`.  I threw in titles that had the words systematic and natrualist too.  Tried to trim any whitespace as well using the `stringr` package. 

{% highlight r linenos %}
library(stringr)

ecotitles <- as.character(allnames[str_detect(allnames, "^[Ee]cology|\\s[Ee]cology")])
evotitles <- as.character(allnames[str_detect(allnames, "^[Ee]volution|\\s[Ee]volution")])
systtitles <- as.character(allnames[str_detect(allnames, "^[Ss]ystematic|\\s[Ss]systematic")])
naturalist <- as.character(allnames[str_detect(allnames, "[Nn]aturalist")])

ecoevotitles <- unique(c(ecotitles, evotitles, systtitles, naturalist))  # combine to list
ecoevotitles <- str_trim(ecoevotitles, side = "both")  # trim whitespace, if any
length(ecoevotitles)
{% endhighlight %}



{% highlight text %}
[1] 188
{% endhighlight %}



{% highlight r linenos %}

# Just the first ten titles
ecoevotitles[1:10]
{% endhighlight %}



{% highlight text %}
 [1] "Microbial Ecology in Health and Disease"           
 [2] "Population Ecology"                                
 [3] "Researches on Population Ecology"                  
 [4] "Behavioral Ecology and Sociobiology"               
 [5] "Microbial Ecology"                                 
 [6] "Biochemical Systematics and Ecology"               
 [7] "FEMS Microbiology Ecology"                         
 [8] "Journal of Experimental Marine Biology and Ecology"
 [9] "Applied Soil Ecology"                              
[10] "Forest Ecology and Management"                     
{% endhighlight %}

*********

### Get the .Rmd file used to create this post [at my github account](https://github.com/sckott/sckott.github.com/tree/master/_drafts/2012-08-30-get-ecoevo-journal-titles.Rmd).

*********

### Written in [Markdown](http://daringfireball.net/projects/markdown/), with help from [knitr](http://yihui.name/knitr/), and nice knitr highlighting/etc. in in [RStudio](http://rstudio.org/).

  </div>
  
  <div class="post">
    <h1>
      <a href="/2012/08/ecology-unconference/">
        Ecology unconference at ESA 2013
      </a>
    </h1>

    <span class="post-date">30 Aug 2012</span>

    *********

So I heard many people say after or during the recent ESA conference in Portland that they really enjoyed the converstations more than listening to talks or looking at posters. 

There was some chatter about doing an unconference associated with next year's ESA conference in Minneapolis. And Sandra Chung (@sandramchung) got on it and started a wiki that we can all conribute ideas to. The wiki is here: [http://ecologyunconference.wikispaces.com/](http://ecologyunconference.wikispaces.com/)

What is an unconference? The idea of an unconference is to have a community organized meetup in which interactions among people are emphasized over the traditional lecture and poster format. For example, many sessions may just be organized a single idea, and people attending have a discussion around the topic. The format can be decided by the community. 

What will we do there? The broadest restriction is that topics should be about science that happens online. You may say, "Well, real ecology happens in the field!". Yes, but a lot of the products of ecology are put online, and increasingly the discussion of the practice of ecology happens online. Check out the [Science Online 2012 website](http://scienceonline2012.com/) for a little taste of what we hope to achieve next year.

How do I get involved? Go to the wiki and start contributing: [http://ecologyunconference.wikispaces.com/](http://ecologyunconference.wikispaces.com/). There are already some suggestions for topics...Here's a screenshot of the ideas for Session Proposals page:

![ecologyunconf](/public/img/ecologyunconf.png)

*********

### Important!  Use the #esaun13 hashtag to talk about this unconference on Twitter, G+, and app.net.

*********

### Get the .Rmd file used to create this post [at my github account](https://github.com/sckott/sckott.github.com/tree/master/_drafts/2012-08-30-making-matrices.Rmd).

*********

### Written in [Markdown](http://daringfireball.net/projects/markdown/), with help from [knitr](http://yihui.name/knitr/).

  </div>
  
</div>

<!-- Pagination links -->
<div class="pagination">
  
    <a href="/page31" class="older">Older</a>
  
  
    
      <a href="/page29" class="newer">Newer</a>
    
  
</div>

    </div>

    <!-- for bootstrap tooltips -->
    <script type="text/javascript">
      $("[data-toggle=\"tooltip\"]").tooltip();
    </script>

  </body>

  <footer>
  <!-- Disqus code -->
  <script type="text/javascript">
      /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
      var disqus_shortname = 'recology'; // required: replace example with your forum shortname

      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function () {
          var s = document.createElement('script'); s.async = true;
          s.type = 'text/javascript';
          s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
          (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
      }());
  </script>

  <!-- google analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-63197374-1', 'auto');
    ga('send', 'pageview');
  </script>
</footer>

</html>
