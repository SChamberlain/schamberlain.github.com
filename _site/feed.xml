<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
	<channel>
		<title>Recology</title>
		<description></description>
		<link>http://schamberlain.github.com</link>
		
			<item>
				<title>Hitting the Global Names Resolver API</title>
				<description>&lt;h2&gt;Example of using the Global Names Resolver API to check species names&lt;/h2&gt;

&lt;hr /&gt;

&lt;p&gt;There are a number of options for resolution of taxonomic names. The &lt;a href=&quot;http://tnrs.iplantcollaborative.org/&quot;&gt;Taxonomic Name Resolution Service (TNRS)&lt;/a&gt; comes to mind. There is a new service for taxonomic name resoultion called the &lt;a href=&quot;http://resolver.globalnames.org/&quot;&gt;Global Names Resolver&lt;/a&gt;. They describe the service thusly &quot;&lt;em&gt;Resolve lists of scientific names against known sources. This service parses incoming names, executes exact or fuzzy matching as required, and displays a confidence score for each match along with its identifier.&lt;/em&gt;&quot;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2&gt;Load required packages&lt;/h2&gt;

&lt;h3&gt;Just uncomment the code to use.&lt;/h3&gt;

&lt;h2&gt;Get the data sources available&lt;/h2&gt;

&lt;h3&gt;Get just id's and names of sources in a data.frame&lt;/h3&gt;

&lt;hr /&gt;

&lt;h3&gt;Give me the id for EOL (Encyclopedia of Life)&lt;/h3&gt;

&lt;hr /&gt;

&lt;h3&gt;Fuzzy search for sources with the word &quot;zoo&quot;&lt;/h3&gt;

&lt;h2&gt;Resolve some names&lt;/h2&gt;

&lt;h3&gt;Search for &lt;em&gt;Helianthus annuus&lt;/em&gt; and &lt;em&gt;Homo sapiens&lt;/em&gt;, return a data.frame&lt;/h3&gt;

&lt;hr /&gt;

&lt;h3&gt;Search for the same species, with only using data source 12 (i.e., EOL)&lt;/h3&gt;

&lt;h3&gt;That's it. Have fun! And put bugs/comments/etc. &lt;a href=&quot;https://github.com/ropensci/taxize_/issues&quot;&gt;here&lt;/a&gt;.&lt;/h3&gt;

&lt;hr /&gt;

&lt;h3&gt;Written in &lt;a href=&quot;http://daringfireball.net/projects/markdown/&quot;&gt;Markdown&lt;/a&gt;, with help from &lt;a href=&quot;http://yihui.name/knitr/&quot;&gt;knitr&lt;/a&gt;, and nice knitr highlighting/etc. in in &lt;a href=&quot;http://rstudio.org/&quot;&gt;RStudio&lt;/a&gt;.&lt;/h3&gt;

&lt;hr /&gt;

&lt;h3&gt;I prepared the markdown for this post by:&lt;/h3&gt;

&lt;p&gt;from &lt;a href=&quot;http://jfisher-usgs.github.com/r/2012/07/03/knitr-jekyll/&quot;&gt;jfisher&lt;/a&gt;.&lt;/p&gt;
</description>
				<published>2012-07-20 00:00:00 -0700</published>
				<link>http://schamberlain.github.com/2012/07/global-names-resolver/</link>
			</item>
		
			<item>
				<title>Recent R packages for ecology and evolution</title>
				<description>&lt;p&gt;Many R packages/tools have come out recently for doing ecology and evolution. All of the below were described in Methods in Ecology and Evolution, except for spider, which came out in &lt;a href=&quot;http://onlinelibrary.wiley.com/journal/10.1111/(ISSN)1755-0998&quot;&gt;Molecular Ecology Resources&lt;/a&gt;. Here are some highlights.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;mvabund &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2012.00190.x/abstract&quot;&gt;paper&lt;/a&gt; - &lt;a href=&quot;http://cran.r-project.org/web/packages/mvabund/index.html&quot;&gt;get R pkg&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Model-based analysis of multivariate abundance data. Visualising data, fitting predictive models, checking assumptions, hypothesis testing.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;popdemo &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2012.00222.x/abstract&quot;&gt;paper&lt;/a&gt; - &lt;a href=&quot;http://cran.r-project.org/web/packages/popdemo/index.html&quot;&gt;get R pkg&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Population demography using projection matrix analysis.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;motmot &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2011.00132.x/abstract&quot;&gt;paper&lt;/a&gt; - &lt;a href=&quot;http://cran.r-project.org/web/packages/motmot/index.html&quot;&gt;get R pkg&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Models of trait macroevolution on trees&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;spider &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/j.1755-0998.2011.03108.x/abstract?deniedAccessCustomisedMessage=&amp;amp;userIsAuthenticated=false&quot;&gt;paper&lt;/a&gt; - &lt;a href=&quot;http://cran.r-project.org/web/packages/spider/index.html&quot;&gt;get R pkg&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Analysis of species identity and evolution, with particular reference to DNA barcoding&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;BaSTA &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2012.00186.x/abstract&quot;&gt;paper&lt;/a&gt; - &lt;a href=&quot;http://cran.r-project.org/web/packages/BaSTA/index.html&quot;&gt;get R pkg&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Bayesian estimation of age-specific survival from incomplete markâ€“recapture/recovery data with covariates&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;abc &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2011.00179.x/abstract&quot;&gt;paper&lt;/a&gt; - &lt;a href=&quot;http://cran.r-project.org/web/packages/abc/index.html&quot;&gt;get R pkg&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Approximate Bayesian Computation (ABC)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RNetLogo &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2011.00180.x/abstract&quot;&gt;paper&lt;/a&gt; - &lt;a href=&quot;http://cran.r-project.org/web/packages/RNetLogo/index.html&quot;&gt;get R pkg&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Running and exploring individual-based models implemented in NetLogo&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;phytools &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2011.00169.x/abstract&quot;&gt;paper&lt;/a&gt; - &lt;a href=&quot;http://cran.r-project.org/web/packages/phytools/index.html&quot;&gt;get R pkg&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Tools for phylogenetic comparative biology&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;smatr &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2011.00153.x/abstract&quot;&gt;paper&lt;/a&gt; - &lt;a href=&quot;http://cran.r-project.org/web/packages/smatr/index.html&quot;&gt;get R pkg&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Estimation and inference about allometric lines&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RBrownie &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2011.00112.x/abstract&quot;&gt;paper&lt;/a&gt; - &lt;a href=&quot;http://www.brianomeara.info/tutorials/brownie&quot;&gt;get R pkg ?&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Testing hypotheses about rates of evolutionary change&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;polytomy resolver &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2011.00103.x/abstract&quot;&gt;paper&lt;/a&gt; - &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2011.00103.x/suppinfo&quot;&gt;get R pkg&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Resolve polytomies on dated phylogenies with their R scripts [here][].&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;And a cool tool came out for the Python programming language.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;NichePy &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2011.00184.x/abstract&quot;&gt;paper&lt;/a&gt; - &lt;a href=&quot;https://github.com/bastodian/NichePy&quot;&gt;get python&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Modular tools for estimating the similarity of ecological niche and species distribution models&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;

</description>
				<published>2012-06-14 00:00:00 -0700</published>
				<link>http://schamberlain.github.com/2012/06/recent-r-eeb-packages/</link>
			</item>
		
			<item>
				<title>Visualize your Github stats (forks and watchers) in a browser with R!</title>
				<description>&lt;p&gt;So &lt;a href=&quot;http://opencpu.org/&quot;&gt;OpenCPU&lt;/a&gt; is pretty awesome.  You can run R in a browser using URL calls with an alphanumeric code (e.g., x3e50ee0780) defining a stored function, and any arguments you pass to it.&lt;/p&gt;

&lt;p&gt;Go &lt;a href=&quot;http://beta.opencpu.org/apps/opencpu.demo/storefunction/&quot;&gt;here&lt;/a&gt; to store a function.  And you can output lots of different types of things: png, pdf, json, etc - see &lt;a href=&quot;http://opencpu.org/documentation/outputs/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here's a function I created:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/2602432.js?file=getgithubstats.r&quot;&gt;&lt;/script&gt;


&lt;p&gt;It makes a &lt;a href=&quot;http://had.co.nz/ggplot2/&quot;&gt;ggplot2&lt;/a&gt; graphic of your watchers and forks on each repo (up to 100 repos), sorted by descending number of forks/watchers.&lt;/p&gt;

&lt;p&gt;Here's an example from the function.  Paste the following in to your browser and you should get the below figure.&lt;/p&gt;

&lt;p&gt;http://beta.opencpu.org/R/call/opencpu.demo/gitstats/png&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/hadley.png&quot; alt=&quot;had&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And you can specify user or organization name using arguments in the URL&lt;/p&gt;

&lt;p&gt;http://beta.opencpu.org/R/call/opencpu.demo/gitstats/png?type='org'&amp;amp;id='ropensci'&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/ropensci.png&quot; alt=&quot;ropensci&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Sweet. Have fun.&lt;/p&gt;
</description>
				<published>2012-05-05 00:00:00 -0700</published>
				<link>http://schamberlain.github.com/2012/05/opencpu-github-stats/</link>
			</item>
		
			<item>
				<title>mvabund - new R pkg for multivariate abundance data</title>
				<description>&lt;p&gt;There is a new R package in town, mvabund, which does, as they say &quot;statistical methods for analysing multivariate abundance data&quot;.  The authors introduced the paper in an online early paper in Methods in Ecology and Evolution &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2012.00190.x/full&quot;&gt;here&lt;/a&gt;, R package &lt;a href=&quot;http://cran.r-project.org/web/packages/mvabund/index.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The package is meant to visualize data, fit predictive models, check model assumptions, and test hypotheses about community-environment associations.&lt;/p&gt;

&lt;p&gt;Here is a quick example.&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/2112141.js?file=mvabund.r&quot;&gt;&lt;/script&gt;


&lt;p&gt;&lt;img src=&quot;/img/mvabund1.png&quot; alt=&quot;mvabund1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/mvabund2.png&quot; alt=&quot;mvabund2&quot; /&gt;&lt;/p&gt;
</description>
				<published>2012-03-19 00:00:00 -0700</published>
				<link>http://schamberlain.github.com/2012/03/mvabund/</link>
			</item>
		
			<item>
				<title>Journal Articles Need Interactive Graphics</title>
				<description>&lt;p&gt;I should have thought of it earlier: In a day and age when we are increasingly reading scientific literature on computer screens, why is it that we limit our peer-reviewed data representation to static, unchanging graphs and plots? Why do we not try to create dynamic visualizations of our rich and varied data sets? Would we not derive benefits in the quality and clarity of scientific discourse from publishing these visualizations?&lt;/p&gt;

&lt;p&gt;An article in the very good (and under-appreciated, in my opinion) &lt;em&gt;&lt;a href=&quot;http://www.americanscientist.org/&quot;&gt;American Scientist&lt;/a&gt;&lt;/em&gt; magazine written by Brian Hayes started me thinking about these questions.  &lt;a href=&quot;http://www.americanscientist.org/issues/pub/pixels-or-perish&quot;&gt;&quot;Pixels or Perish&quot;&lt;/a&gt; begins by recapping the evolution of graphics in scientific publications and notes that before people were good at making plots digitally, they were good at making figures from using photographic techniques; and before that, from elaborate engravings.  Clearly, the state-of-the-art in scientific publishing is a moving target.&lt;/p&gt;

&lt;p&gt;Hayes points out that one of the primary advantages of static images is that everyone knows how to use them and that almost no one lacks the tools to view them.  That is, printed images in a magazine or static digital images in the portable document format (pdf) are easily viewed on paper or on a screen and can be readily interpreted by a wide audience.  While I agree that this feature is very important, why have we not, as scientists, moved to the next level?  We do not lack the ability to interpret data--it is our job to do so--not to mention that we are some of the heaviest generators of data in the first place.&lt;/p&gt;

&lt;p&gt;The obstacles to progress towards interactive data are two-fold.  First, generating dynamic data visualizations is not as easy as generating static plots.  The data visualization tools simply are not as well developed and they do not show up as frequently in the programming environments in which scientists work.  One example Hayes cites is that the ideas from programs such as &lt;a href=&quot;http://vis.stanford.edu/files/2011-D3-InfoVis.pdf&quot;&gt;D&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; have not yet made an appearance in software, like &lt;a href=&quot;http://www.r-project.org/&quot;&gt;R&lt;/a&gt; and &lt;a href=&quot;http://www.mathworks.com/products/matlab/&quot;&gt;Matlab&lt;/a&gt;, that more scientists use. This is one reason why I am so excited by the work that our very own &lt;a href=&quot;http://schamberlain.github.com/recologyabout.html&quot;&gt;Scott&lt;/a&gt; has been doing with this &lt;a href=&quot;http://schamberlain.github.com/&quot;&gt;Recology&lt;/a&gt; blog, in trying to promote awareness of tools in &lt;a href=&quot;http://www.r-project.org/&quot;&gt;R&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The second is that neither of our currently dominant publishing formats (physical paper and digital pdf files) support dynamic graphics. Hayes says it better than I could: &quot;â€¦the Web is not where scientists publishâ€¦[publications are]â€¦available &lt;em&gt;through&lt;/em&gt; the Web, not &lt;em&gt;on&lt;/em&gt; the Web.&quot;  So, not many current publications really take advantage of the new capabilities that the Web has offered us to showcase dynamic data sets.  In fact, while &lt;a href=&quot;http://www.sciencemag.org/&quot;&gt;Science&lt;/a&gt; and &lt;a href=&quot;http://wwww.nature.com&quot;&gt;Nature&lt;/a&gt;--just to name two prominent examples of scientific journals--make available HTML versions of their articles, it seems like most of the interactivity is limited to looking at larger versions of figures in the articles*.  I myself usually just download the pdf version of articles rather than viewing the HTML version.  This obstacle, however, is not a fundamental one; it is only the current situation.&lt;/p&gt;

&lt;p&gt;The more serious obstacle that Hayes foresees in transitioning to dynamic graphics is one of archiving. Figures in journal articles printed in 1900 are still readable today, but there is no guarantee that a particular file format will survive in usable form to 2100, or even 2020.  I do not know the answer to this conundrum.  A balance might need to be struck between generating static and dynamic data.  At least in the medium term, papers should probably also contain static versions of figures representing dynamic data sets. It is inelegant, but it could avoid the situation where we lose access to information that was once there.&lt;/p&gt;

&lt;p&gt;That said, if the &lt;a href=&quot;http://www.nytimes.com&quot;&gt;New York Times&lt;/a&gt; can do it, so can we.  We should not wait to make our data presentation more dynamic and interactive.  At first, it will be difficult to incorporate these kinds of figures into the articles themselves, and they will likely be relegated to the &quot;supplemental material&quot; dead zone that is infrequently viewed.  But the more dynamic material that journals receive from authors, the more incentive they will have to expand upon their current offerings.  Ultimately, doing so will greatly improve the quality of scientific discourse.&lt;/p&gt;

&lt;p&gt;&lt;small&gt;* Whether the lack of dynamic data visualization on these journals' websites is due to the authors not submitting such material or due to restrictions from the journals themselves, I do not know. I suspect the burden falls more on the authors' shoulders at this point than the journals'.&lt;/small&gt;&lt;/p&gt;
</description>
				<published>2012-02-25 00:00:00 -0800</published>
				<link>http://schamberlain.github.com/2012/02/science-publications-need-interactive-graphics/</link>
			</item>
		
			<item>
				<title>Take the INNGE survey on math and ecology</title>
				<description>&lt;p&gt;Many ecologists are R users, but we vary in our understanding of the math and statistical theory behind models we use. There is no clear consensus on what should be the basic mathematical training of ecologists.&lt;/p&gt;

&lt;p&gt;To learn what the community thinks, we invite you to fill out a short and anonymous questionnaire on this topic &lt;a href=&quot;https://sites.google.com/site/mathematicsandecologysurvey/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The questionnaire was designed by &lt;a href=&quot;http://www.cebc.cnrs.fr/Fidentite/barraquand/barraquand.htm&quot;&gt;FrÃ©dÃ©ric Barraquand&lt;/a&gt;, a graduate student at UniversitÃ© Pierre et Marie Curie, in collaboration with the International Network of Next-Generation Ecologists (&lt;a href=&quot;http://www.innge.net&quot;&gt;INNGE&lt;/a&gt;).&lt;/p&gt;
</description>
				<published>2012-02-17 00:00:00 -0800</published>
				<link>http://schamberlain.github.com/2012/02/math-ecology-survey/</link>
			</item>
		
			<item>
				<title>Scraping Flora of North America</title>
				<description>&lt;p&gt;So &lt;a href=&quot;http://fna.huh.harvard.edu/&quot;&gt;Flora of North America&lt;/a&gt; is an awesome collection of taxonomic information for plants across the continent.  However, the information within is not easily machine readable.&lt;/p&gt;

&lt;p&gt;So, a little web scraping is called for.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/ropensci/rfna&quot;&gt;rfna&lt;/a&gt; is an R package to collect information from the Flora of North America.&lt;/p&gt;

&lt;p&gt;So far, you can:
1. Get taxonomic names from web pages that index the names.
2. Then get daughter URLs for those taxa, which then have their own 2nd order daughter URLs you can scrape, or scrape the 1st order daughter page.
3. Query Asteraceae taxa for whether they have paleate or epaleate receptacles.  This function is something I needed, but more functions will be made like this to get specific traits.&lt;/p&gt;

&lt;p&gt;Further functions will do search, etc.&lt;/p&gt;

&lt;p&gt;You can install by:&lt;/p&gt;

&lt;p&gt;Here is an example where a set of URLs is acquired using function &lt;code&gt;getdaughterURLs&lt;/code&gt;, then the function &lt;code&gt;receptacle&lt;/code&gt; is used to ask whether of each the taxa at those URLs have paleate or epaleate receptacles.&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/1690353.js?file=rfna_demo.r&quot;&gt;&lt;/script&gt;



</description>
				<published>2012-01-27 00:00:00 -0800</published>
				<link>http://schamberlain.github.com/2012/01/flora-north-america-scraping/</link>
			</item>
		
			<item>
				<title>RNetLogo - A package for running NetLogo from R</title>
				<description>&lt;p&gt;Described in a new Methods in Ecology and Evolution paper &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2011.00180.x/abstract&quot;&gt;here&lt;/a&gt;, a new &lt;a href=&quot;http://cran.r-project.org/&quot;&gt;R&lt;/a&gt; package &lt;a href=&quot;http://cran.r-project.org/web/packages/RNetLogo/index.html&quot;&gt;RNetLogo&lt;/a&gt; allows you to use &lt;a href=&quot;http://ccl.northwestern.edu/netlogo/&quot;&gt;NetLogo&lt;/a&gt; from R.&lt;/p&gt;

&lt;p&gt;NetLogo is software is a &quot;multi-agent programmable modeling environment&quot;. NetLogo can be used in individual- and agent-based modeling, and is used in the book &lt;a href=&quot;http://www.railsback-grimm-abm-book.com/&quot;&gt;&lt;em&gt;Agent-based and Individual-based Modeling: A Practical Introduction&lt;/em&gt;&lt;/a&gt; by Railsback &amp;amp; Grimm.&lt;/p&gt;

&lt;p&gt;I have not tried the package yet, but looks interesting. I am always a fan of running stand-alone programs from R if possible.&lt;/p&gt;
</description>
				<published>2012-01-23 00:00:00 -0800</published>
				<link>http://schamberlain.github.com/2012/01/RNetLogo/</link>
			</item>
		
			<item>
				<title>Taking a Closer Look at Peer Review</title>
				<description>&lt;p&gt;This post is only tangentially about open science.  It is more directly about the process of peer review and how it might be improved.  I am working on a follow-up post about how these points can be addressed in an open publishing environment.&lt;/p&gt;

&lt;p&gt;A &lt;a href=&quot;http://arxiv.org/abs/1110.0791&quot;&gt;recent paper on the arXiv&lt;/a&gt; got me thinking about the sticking points in the publishing pipeline.  As it stands, most scientists have a pretty good understanding of how peer reviewed publishing is supposed to work.  Once an authorâ€”or more likely, a group of authorsâ€”decides that a manuscript is ready for action, the following series of events will occur:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;the authors submit the manuscript to the journal of choice;&lt;/li&gt;
&lt;li&gt;the journal's editor makes a general decision about whether the article is appropriate for the journal;&lt;/li&gt;
&lt;li&gt;in the affirmative case, the editor selects referees for the manuscript and sends them the text for review;&lt;/li&gt;
&lt;li&gt;the referees return reviews of the manuscript (the referees are not typically identified to the authors);&lt;/li&gt;
&lt;li&gt;the editor makes the decision to reject the manuscript, accept it with minor revisions, or accept it with major revisions.  Rejected manuscripts usually start over the process in another journal.  Minor revisions to accepted manuscripts are usually made quickly and publication proceeds.  In the case of major revisions, the suggested changes are made, if possible, and the manuscript is returned to the editor.  At this point, the referees may get a second crack at the material (but not necessarily), before the editor makes a final accept/reject decision based on the feedback from the referees.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Peer review of manuscripts exists for several reasons.  For one, self-regulation determines the suitability of the material for publication if it was not already obvious to the editor of the journal.  Having peer reviewers also improves the material and its presentation.  Furthermore, having expert reviewers lends credibility to the work and insures that misleading, wrong, or crackpot material does not receive the stamp of credibility.  Finally, finding appropriately skilled referees spreads the workload beyond the editors, who may not have the resources to evaluate every paper arriving at their desk.&lt;/p&gt;

&lt;p&gt;Though peer review has a storied history, it also has its drawbacks.  First, and perhaps foremost, the process is often a slow one, with many months elapsing during even one round of communications between the authors, the editor, and the referees.  Peer review is not always an objective process either: referees have the power to delay, or outright reject, work that their competitors have completed, and thus they may lose their impartiality in the process.  Additionally, the publishing process does not reveal the feedback process that occurs between authors and referees, which can be a scientifically and pedagogically valuable exchange.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://arxiv.org/abs/1110.0791&quot;&gt;One proposal&lt;/a&gt; to address the shortcomings of the peer review process (alluded to in the first paragraph) was posted by Sergey Bozhevolnyi on the &lt;a href=&quot;http://arxiv.org/&quot;&gt;arXiv&lt;/a&gt;, a pre-publication website for many physics-related manuscripts.  Bozhevolnyi calls his model of publishing Rapid, Impartial, and Comprehensive (RIC) publishing.  To him, &quot;rapid&quot; means that editors should approve or reject manuscripts before the manuscripts are sent to the referees for review.  Then, &quot;impartial&quot; means that referees, who might otherwise have an interest in rejecting a perfectly fine paper, lose the power to dictate whether or not a manuscript is published.  Instead, the referees critique the paper without assessing whether it is publication-worthy.  Lastly, &quot;comprehensive&quot; involves publishing everything having to do with the manuscript.  That is, all positive and negative reviews are published in conjunction with the all versions of a manuscript.&lt;/p&gt;

&lt;p&gt;The primary benefit of RIC, according to Bozhevolnyi, is that it saves the energies of authors, editors, and referees, thus allowing them all to do more research and less wrangling.  Since most papers are ultimately accepted somewhere, then we should not cause additional delays in publishing by first rejecting them in multiple places.  Instead, collate the manuscript and the reviews and publish them all together, along with any revisions to the manuscript.  Having the reviews be publicly viewable will encourage referees to be more careful about writing their critiques and supporting their assertions, and the process as a whole will be more transparent than it currently is.&lt;/p&gt;

&lt;p&gt;Before I critique the RIC publishing proposal, I should point out that some aspects of the proposal are very appealing.  I particularly like the idea of publishing all reviews in addition to the manuscript.  That said, I find it difficult to believe that the incentives for authors and referees change for the better under this proposal.  For example, what happens if authors receive feedback, do not wish to invest the time to address the critique, and subsequently allow the original manuscript and the reviews to stand as they are?  This situation seems like a moral hazard for authors that does a disservice to the quality of scientific literature.  On the part of the referees, does removing decision-making authority make reviewing less appealing?  Disempowering the referees by potentially ignoring their critique and only counting it as a minor part of the publishing process will not motivate them to write better reviews.  In the case of editors, what makes us believe that an editor, or an editorial board, has the background to properly evaluate the suitability of work for acceptance into a journal?  The reason we have referees in the current peer review system is because they have the very expertise and familiarity needed for this task.&lt;/p&gt;

&lt;p&gt;Does the fact that Bozhevolnyi's RIC proposal does not make sense mean that peer review is fine as it is?  I do not think so.  Instead, it is worth asking what parts of peer review we like and what parts we would like to improve.  I posit that rejection, or the threat of rejection, is the greatest motivator for authors to make necessary changes to their manuscript.  As such, rejection by peers is still the best way to require and receive revisions.  Though I think that referees should retain their rejecting power (and their anonymity!), I feel strongly that the entire peer review process would benefit from the increased transparency and accountability that publishing unsigned reviews would add.  As far as editors, they play a role in shaping the kind of journal they run by selecting appropriate material on a general level, but they should not play too large a role in determining the &quot;important&quot; research in any field.  The model used by the journal [Public Library of Science One][] is a promising one in this regard, with the only acceptance criterion being whether the science is sound.&lt;/p&gt;

&lt;p&gt;The amount of time that it takes to publish is one of the most frustrating aspects of peer review, however.  Journals could voluntarily publish time-to-publication figures, a number which could then be used by authorsâ€”along with impact factors and acceptance ratesâ€”to decide which journals to submit to.  For instance, an editor of the Journal of Orthodontics writes about just this fact in &lt;a href=&quot;http://jorthod.maneyjournals.org/content/29/3/171.full&quot;&gt;an editorial&lt;/a&gt;.  A Google search for &quot;journal time to publication&quot; reveals that people have been thinking about this problem for a while (e.g. &lt;a href=&quot;http://www.hutter1.net/journals.htm&quot;&gt;computer science comparisons&lt;/a&gt;), but no general standard exists across journals.  In fact, I suspect these are numbers most journals are afraid will hurt them more than help them.  Nevertheless, journals acknowledge the demand for rapid publication when they offer services like [Springer's Fast Track publishing&lt;a href=&quot;http://www.springer.com/societies+%26+publishing+partners/society+%26+partner+zone?SGWID=0-173202-12-772912-0&quot;&gt;fasttrackpub&lt;/a&gt; or &lt;a href=&quot;http://pra.aps.org/highlighting-rapids&quot;&gt;Physical Review's Rapid Communications&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Ultimately, it may not matter what journals do because authors are routing around this problem via pre-publication archives such as the &lt;a href=&quot;http://arxiv.org/&quot;&gt;arXiv&lt;/a&gt; for physics-related subject matter.  Though not without complications, especially in the health sciences (see, for example, &lt;a href=&quot;http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0010782&quot;&gt;&quot;The Promise and Perils of Pre-Publication Review&quot;&lt;/a&gt;), pre-publication allows authors to communicate results and establish priority without stressing about getting through the peer review process as fast as possible.  Instead, the process takes its normal, slower course while authors move along their on-going research.&lt;/p&gt;

&lt;p&gt;I will conclude by leaving an open question that I may address in a future post:  how do you encourage peer reviewers to do the best possible job, in a timely manner, without only relying on their altruism to doing good science and being good members of the community?  It is this question about peer review, I feel, that is the most fraught with complication and subject to the law of unintended consequences if the incentives are changed.&lt;/p&gt;
</description>
				<published>2012-01-16 00:00:00 -0800</published>
				<link>http://schamberlain.github.com/2012/01/reviewing-peer-review-process/</link>
			</item>
		
			<item>
				<title>Function for phylogeny resolution</title>
				<description>&lt;p&gt;UPDATE:  Yeah, so the treeresstats function had a problem in one of the calculations.  I fixed that and added some more calulcations to the function.&lt;/p&gt;

&lt;p&gt;I couldn't find any functions to calculate number of polytomies, and related metrics.&lt;/p&gt;

&lt;p&gt;Here's a simple function that gives four metrics on a phylo tree object:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/1607531.js?file=treeresstats.R&quot;&gt;&lt;/script&gt;


&lt;p&gt;Here's output from the gist above:&lt;/p&gt;

&lt;p&gt;And an example with many trees:&lt;/p&gt;

&lt;table border=&quot;1&quot;&gt;
    &lt;tr&gt;
        &lt;th&gt;trsize_tips&lt;/th&gt;
        &lt;th&gt;trsize_nodes&lt;/th&gt;
        &lt;th&gt;numpolys&lt;/th&gt;
        &lt;th&gt;numpolysbytrsize_tips&lt;/th&gt;
        &lt;th&gt;numpolysbytrsize_nodes&lt;/th&gt;
        &lt;th&gt;proptipsdescpoly&lt;/th&gt;
        &lt;th&gt;propnodesdich&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;20&lt;/td&gt; &lt;td&gt;13&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;td&gt;0.20&lt;/td&gt; &lt;td&gt;0.31&lt;/td&gt; &lt;td&gt;0.7&lt;/td&gt; &lt;td&gt;0.69&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;20&lt;/td&gt; &lt;td&gt;7&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;0.15&lt;/td&gt; &lt;td&gt;0.43&lt;/td&gt; &lt;td&gt;0.9&lt;/td&gt; &lt;td&gt;0.57&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;20&lt;/td&gt; &lt;td&gt;11&lt;/td&gt; &lt;td&gt;6&lt;/td&gt; &lt;td&gt;0.30&lt;/td&gt; &lt;td&gt;0.55&lt;/td&gt; &lt;td&gt;1.0&lt;/td&gt; &lt;td&gt;0.45&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;20&lt;/td&gt; &lt;td&gt;13&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;td&gt;0.20&lt;/td&gt; &lt;td&gt;0.31&lt;/td&gt; &lt;td&gt;0.7&lt;/td&gt; &lt;td&gt;0.69&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;20&lt;/td&gt; &lt;td&gt;9&lt;/td&gt; &lt;td&gt;5&lt;/td&gt; &lt;td&gt;0.25&lt;/td&gt; &lt;td&gt;0.56&lt;/td&gt; &lt;td&gt;1.0&lt;/td&gt; &lt;td&gt;0.44&lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

</description>
				<published>2012-01-13 00:00:00 -0800</published>
				<link>http://schamberlain.github.com/2012/01/phylogeny-resolution/</link>
			</item>
		
	</channel>
</rss>