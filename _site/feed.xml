<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
	<channel>
		<title>Recology</title>
		<description>An exploration of using R for ecology, evolution, and open science.</description>
		<link>http://schamberlain.github.com</link>
		
			<item>
				<title>Journal Articles Need Interactive Graphics</title>
				<description>&lt;p&gt;I should have thought of it earlier: In a day and age when we are increasingly reading scientific literature on computer screens, why is it that we limit our peer-reviewed data representation to static, unchanging graphs and plots? Why do we not try to create dynamic visualizations of our rich and varied data sets? Would we not derive benefits in the quality and clarity of scientific discourse from publishing these visualizations?&lt;/p&gt;

&lt;p&gt;An article in the very good (and under-appreciated, in my opinion) &lt;em&gt;&lt;a href=&quot;http://www.americanscientist.org/&quot;&gt;American Scientist&lt;/a&gt;&lt;/em&gt; magazine written by Brian Hayes started me thinking about these questions.  &lt;a href=&quot;http://www.americanscientist.org/issues/pub/pixels-or-perish&quot;&gt;&quot;Pixels or Perish&quot;&lt;/a&gt; begins by recapping the evolution of graphics in scientific publications and notes that before people were good at making plots digitally, they were good at making figures from using photographic techniques; and before that, from elaborate engravings.  Clearly, the state-of-the-art in scientific publishing is a moving target.&lt;/p&gt;

&lt;p&gt;Hayes points out that one of the primary advantages of static images is that everyone knows how to use them and that almost no one lacks the tools to view them.  That is, printed images in a magazine or static digital images in the portable document format (pdf) are easily viewed on paper or on a screen and can be readily interpreted by a wide audience.  While I agree that this feature is very important, why have we not, as scientists, moved to the next level?  We do not lack the ability to interpret data--it is our job to do so--not to mention that we are some of the heaviest generators of data in the first place.&lt;/p&gt;

&lt;p&gt;The obstacles to progress towards interactive data are two-fold.  First, generating dynamic data visualizations is not as easy as generating static plots.  The data visualization tools simply are not as well developed and they do not show up as frequently in the programming environments in which scientists work.  One example Hayes cites is that the ideas from programs such as &lt;a href=&quot;http://vis.stanford.edu/files/2011-D3-InfoVis.pdf&quot;&gt;D&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; have not yet made an appearance in software, like &lt;a href=&quot;http://www.r-project.org/&quot;&gt;R&lt;/a&gt; and &lt;a href=&quot;http://www.mathworks.com/products/matlab/&quot;&gt;Matlab&lt;/a&gt;, that more scientists use. This is one reason why I am so excited by the work that our very own &lt;a href=&quot;http://schamberlain.github.com/recologyabout.html&quot;&gt;Scott&lt;/a&gt; has been doing with this &lt;a href=&quot;http://schamberlain.github.com/&quot;&gt;Recology&lt;/a&gt; blog, in trying to promote awareness of tools in &lt;a href=&quot;http://www.r-project.org/&quot;&gt;R&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The second is that neither of our currently dominant publishing formats (physical paper and digital pdf files) support dynamic graphics. Hayes says it better than I could: &quot;…the Web is not where scientists publish…[publications are]…available &lt;em&gt;through&lt;/em&gt; the Web, not &lt;em&gt;on&lt;/em&gt; the Web.&quot;  So, not many current publications really take advantage of the new capabilities that the Web has offered us to showcase dynamic data sets.  In fact, while &lt;a href=&quot;http://www.sciencemag.org/&quot;&gt;Science&lt;/a&gt; and &lt;a href=&quot;http://wwww.nature.com&quot;&gt;Nature&lt;/a&gt;--just to name two prominent examples of scientific journals--make available HTML versions of their articles, it seems like most of the interactivity is limited to looking at larger versions of figures in the articles*.  I myself usually just download the pdf version of articles rather than viewing the HTML version.  This obstacle, however, is not a fundamental one; it is only the current situation.&lt;/p&gt;

&lt;p&gt;The more serious obstacle that Hayes foresees in transitioning to dynamic graphics is one of archiving. Figures in journal articles printed in 1900 are still readable today, but there is no guarantee that a particular file format will survive in usable form to 2100, or even 2020.  I do not know the answer to this conundrum.  A balance might need to be struck between generating static and dynamic data.  At least in the medium term, papers should probably also contain static versions of figures representing dynamic data sets. It is inelegant, but it could avoid the situation where we lose access to information that was once there.&lt;/p&gt;

&lt;p&gt;That said, if the &lt;a href=&quot;http://www.nytimes.com&quot;&gt;New York Times&lt;/a&gt; can do it, so can we.  We should not wait to make our data presentation more dynamic and interactive.  At first, it will be difficult to incorporate these kinds of figures into the articles themselves, and they will likely be relegated to the &quot;supplemental material&quot; dead zone that is infrequently viewed.  But the more dynamic material that journals receive from authors, the more incentive they will have to expand upon their current offerings.  Ultimately, doing so will greatly improve the quality of scientific discourse.&lt;/p&gt;

&lt;p&gt;&lt;small&gt;* Whether the lack of dynamic data visualization on these journals' websites is due to the authors not submitting such material or due to restrictions from the journals themselves, I do not know. I suspect the burden falls more on the authors' shoulders at this point than the journals'.&lt;/small&gt;&lt;/p&gt;
</description>
				<published>Sat Feb 25 00:00:00 -0600 2012</published>
				<link>http://schamberlain.github.com/2012/02/science-publications-need-interactive-graphics/</link>
			</item>
		
			<item>
				<title>Take the INNGE survey on math and ecology</title>
				<description>&lt;p&gt;Many ecologists are R users, but we vary in our understanding of the math and statistical theory behind models we use. There is no clear consensus on what should be the basic mathematical training of ecologists.&lt;/p&gt;

&lt;p&gt;To learn what the community thinks, we invite you to fill out a short and anonymous questionnaire on this topic &lt;a href=&quot;https://sites.google.com/site/mathematicsandecologysurvey/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The questionnaire was designed by &lt;a href=&quot;http://www.cebc.cnrs.fr/Fidentite/barraquand/barraquand.htm&quot;&gt;Frédéric Barraquand&lt;/a&gt;, a graduate student at Université Pierre et Marie Curie, in collaboration with the International Network of Next-Generation Ecologists (&lt;a href=&quot;http://www.innge.net&quot;&gt;INNGE&lt;/a&gt;).&lt;/p&gt;
</description>
				<published>Fri Feb 17 00:00:00 -0600 2012</published>
				<link>http://schamberlain.github.com/2012/02/math-ecology-survey/</link>
			</item>
		
			<item>
				<title>Scraping Flora of North America</title>
				<description>&lt;p&gt;So &lt;a href=&quot;http://fna.huh.harvard.edu/&quot;&gt;Flora of North America&lt;/a&gt; is an awesome collection of taxonomic information for plants across the continent.  However, the information within is not easily machine readable.&lt;/p&gt;

&lt;p&gt;So, a little web scraping is called for.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/ropensci/rfna&quot;&gt;rfna&lt;/a&gt; is an R package to collect information from the Flora of North America.&lt;/p&gt;

&lt;p&gt;So far, you can:
1. Get taxonomic names from web pages that index the names.
2. Then get daughter URLs for those taxa, which then have their own 2nd order daughter URLs you can scrape, or scrape the 1st order daughter page.
3. Query Asteraceae taxa for whether they have paleate or epaleate receptacles.  This function is something I needed, but more functions will be made like this to get specific traits.&lt;/p&gt;

&lt;p&gt;Further functions will do search, etc.&lt;/p&gt;

&lt;p&gt;You can install by:&lt;/p&gt;

&lt;p&gt;Liquid error: undefined method `join' for #&amp;lt;String:0x104ab6d78&gt;&lt;/p&gt;

&lt;p&gt;Here is an example where a set of URLs is acquired using function &lt;code&gt;getdaughterURLs&lt;/code&gt;, then the function &lt;code&gt;receptacle&lt;/code&gt; is used to ask whether of each the taxa at those URLs have paleate or epaleate receptacles.&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/1690353.js?file=rfna_demo.r&quot;&gt;&lt;/script&gt;



</description>
				<published>Fri Jan 27 00:00:00 -0600 2012</published>
				<link>http://schamberlain.github.com/2012/01/flora-north-america-scraping/</link>
			</item>
		
			<item>
				<title>RNetLogo - A package for running NetLogo from R</title>
				<description>&lt;p&gt;Described in a new Methods in Ecology and Evolution paper &lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2011.00180.x/abstract&quot;&gt;here&lt;/a&gt;, a new &lt;a href=&quot;http://cran.r-project.org/&quot;&gt;R&lt;/a&gt; package &lt;a href=&quot;http://cran.r-project.org/web/packages/RNetLogo/index.html&quot;&gt;RNetLogo&lt;/a&gt; allows you to use &lt;a href=&quot;http://ccl.northwestern.edu/netlogo/&quot;&gt;NetLogo&lt;/a&gt; from R.&lt;/p&gt;

&lt;p&gt;NetLogo is software is a &quot;multi-agent programmable modeling environment&quot;. NetLogo can be used in individual- and agent-based modeling, and is used in the book &lt;a href=&quot;http://www.railsback-grimm-abm-book.com/&quot;&gt;&lt;em&gt;Agent-based and Individual-based Modeling: A Practical Introduction&lt;/em&gt;&lt;/a&gt; by Railsback &amp;amp; Grimm.&lt;/p&gt;

&lt;p&gt;I have not tried the package yet, but looks interesting. I am always a fan of running stand-alone programs from R if possible.&lt;/p&gt;
</description>
				<published>Mon Jan 23 00:00:00 -0600 2012</published>
				<link>http://schamberlain.github.com/2012/01/RNetLogo/</link>
			</item>
		
			<item>
				<title>Taking a Closer Look at Peer Review</title>
				<description>&lt;p&gt;This post is only tangentially about open science.  It is more directly about the process of peer review and how it might be improved.  I am working on a follow-up post about how these points can be addressed in an open publishing environment.&lt;/p&gt;

&lt;p&gt;A &lt;a href=&quot;http://arxiv.org/abs/1110.0791&quot;&gt;recent paper on the arXiv&lt;/a&gt; got me thinking about the sticking points in the publishing pipeline.  As it stands, most scientists have a pretty good understanding of how peer reviewed publishing is supposed to work.  Once an author—or more likely, a group of authors—decides that a manuscript is ready for action, the following series of events will occur:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;the authors submit the manuscript to the journal of choice;&lt;/li&gt;
&lt;li&gt;the journal's editor makes a general decision about whether the article is appropriate for the journal;&lt;/li&gt;
&lt;li&gt;in the affirmative case, the editor selects referees for the manuscript and sends them the text for review;&lt;/li&gt;
&lt;li&gt;the referees return reviews of the manuscript (the referees are not typically identified to the authors);&lt;/li&gt;
&lt;li&gt;the editor makes the decision to reject the manuscript, accept it with minor revisions, or accept it with major revisions.  Rejected manuscripts usually start over the process in another journal.  Minor revisions to accepted manuscripts are usually made quickly and publication proceeds.  In the case of major revisions, the suggested changes are made, if possible, and the manuscript is returned to the editor.  At this point, the referees may get a second crack at the material (but not necessarily), before the editor makes a final accept/reject decision based on the feedback from the referees.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;Peer review of manuscripts exists for several reasons.  For one, self-regulation determines the suitability of the material for publication if it was not already obvious to the editor of the journal.  Having peer reviewers also improves the material and its presentation.  Furthermore, having expert reviewers lends credibility to the work and insures that misleading, wrong, or crackpot material does not receive the stamp of credibility.  Finally, finding appropriately skilled referees spreads the workload beyond the editors, who may not have the resources to evaluate every paper arriving at their desk.&lt;/p&gt;

&lt;p&gt;Though peer review has a storied history, it also has its drawbacks.  First, and perhaps foremost, the process is often a slow one, with many months elapsing during even one round of communications between the authors, the editor, and the referees.  Peer review is not always an objective process either: referees have the power to delay, or outright reject, work that their competitors have completed, and thus they may lose their impartiality in the process.  Additionally, the publishing process does not reveal the feedback process that occurs between authors and referees, which can be a scientifically and pedagogically valuable exchange.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://arxiv.org/abs/1110.0791&quot;&gt;One proposal&lt;/a&gt; to address the shortcomings of the peer review process (alluded to in the first paragraph) was posted by Sergey Bozhevolnyi on the &lt;a href=&quot;http://arxiv.org/&quot;&gt;arXiv&lt;/a&gt;, a pre-publication website for many physics-related manuscripts.  Bozhevolnyi calls his model of publishing Rapid, Impartial, and Comprehensive (RIC) publishing.  To him, &quot;rapid&quot; means that editors should approve or reject manuscripts before the manuscripts are sent to the referees for review.  Then, &quot;impartial&quot; means that referees, who might otherwise have an interest in rejecting a perfectly fine paper, lose the power to dictate whether or not a manuscript is published.  Instead, the referees critique the paper without assessing whether it is publication-worthy.  Lastly, &quot;comprehensive&quot; involves publishing everything having to do with the manuscript.  That is, all positive and negative reviews are published in conjunction with the all versions of a manuscript.&lt;/p&gt;

&lt;p&gt;The primary benefit of RIC, according to Bozhevolnyi, is that it saves the energies of authors, editors, and referees, thus allowing them all to do more research and less wrangling.  Since most papers are ultimately accepted somewhere, then we should not cause additional delays in publishing by first rejecting them in multiple places.  Instead, collate the manuscript and the reviews and publish them all together, along with any revisions to the manuscript.  Having the reviews be publicly viewable will encourage referees to be more careful about writing their critiques and supporting their assertions, and the process as a whole will be more transparent than it currently is.&lt;/p&gt;

&lt;p&gt;Before I critique the RIC publishing proposal, I should point out that some aspects of the proposal are very appealing.  I particularly like the idea of publishing all reviews in addition to the manuscript.  That said, I find it difficult to believe that the incentives for authors and referees change for the better under this proposal.  For example, what happens if authors receive feedback, do not wish to invest the time to address the critique, and subsequently allow the original manuscript and the reviews to stand as they are?  This situation seems like a moral hazard for authors that does a disservice to the quality of scientific literature.  On the part of the referees, does removing decision-making authority make reviewing less appealing?  Disempowering the referees by potentially ignoring their critique and only counting it as a minor part of the publishing process will not motivate them to write better reviews.  In the case of editors, what makes us believe that an editor, or an editorial board, has the background to properly evaluate the suitability of work for acceptance into a journal?  The reason we have referees in the current peer review system is because they have the very expertise and familiarity needed for this task.&lt;/p&gt;

&lt;p&gt;Does the fact that Bozhevolnyi's RIC proposal does not make sense mean that peer review is fine as it is?  I do not think so.  Instead, it is worth asking what parts of peer review we like and what parts we would like to improve.  I posit that rejection, or the threat of rejection, is the greatest motivator for authors to make necessary changes to their manuscript.  As such, rejection by peers is still the best way to require and receive revisions.  Though I think that referees should retain their rejecting power (and their anonymity!), I feel strongly that the entire peer review process would benefit from the increased transparency and accountability that publishing unsigned reviews would add.  As far as editors, they play a role in shaping the kind of journal they run by selecting appropriate material on a general level, but they should not play too large a role in determining the &quot;important&quot; research in any field.  The model used by the journal [Public Library of Science One][] is a promising one in this regard, with the only acceptance criterion being whether the science is sound.&lt;/p&gt;

&lt;p&gt;The amount of time that it takes to publish is one of the most frustrating aspects of peer review, however.  Journals could voluntarily publish time-to-publication figures, a number which could then be used by authors—along with impact factors and acceptance rates—to decide which journals to submit to.  For instance, an editor of the Journal of Orthodontics writes about just this fact in &lt;a href=&quot;http://jorthod.maneyjournals.org/content/29/3/171.full&quot;&gt;an editorial&lt;/a&gt;.  A Google search for &quot;journal time to publication&quot; reveals that people have been thinking about this problem for a while (e.g. &lt;a href=&quot;http://www.hutter1.net/journals.htm&quot;&gt;computer science comparisons&lt;/a&gt;), but no general standard exists across journals.  In fact, I suspect these are numbers most journals are afraid will hurt them more than help them.  Nevertheless, journals acknowledge the demand for rapid publication when they offer services like [Springer's Fast Track publishing&lt;a href=&quot;http://www.springer.com/societies+%26+publishing+partners/society+%26+partner+zone?SGWID=0-173202-12-772912-0&quot;&gt;fasttrackpub&lt;/a&gt; or &lt;a href=&quot;http://pra.aps.org/highlighting-rapids&quot;&gt;Physical Review's Rapid Communications&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Ultimately, it may not matter what journals do because authors are routing around this problem via pre-publication archives such as the &lt;a href=&quot;http://arxiv.org/&quot;&gt;arXiv&lt;/a&gt; for physics-related subject matter.  Though not without complications, especially in the health sciences (see, for example, &lt;a href=&quot;http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0010782&quot;&gt;&quot;The Promise and Perils of Pre-Publication Review&quot;&lt;/a&gt;), pre-publication allows authors to communicate results and establish priority without stressing about getting through the peer review process as fast as possible.  Instead, the process takes its normal, slower course while authors move along their on-going research.&lt;/p&gt;

&lt;p&gt;I will conclude by leaving an open question that I may address in a future post:  how do you encourage peer reviewers to do the best possible job, in a timely manner, without only relying on their altruism to doing good science and being good members of the community?  It is this question about peer review, I feel, that is the most fraught with complication and subject to the law of unintended consequences if the incentives are changed.&lt;/p&gt;
</description>
				<published>Mon Jan 16 00:00:00 -0600 2012</published>
				<link>http://schamberlain.github.com/2012/01/reviewing-peer-review-process/</link>
			</item>
		
			<item>
				<title>Function for phylogeny resolution</title>
				<description>&lt;p&gt;UPDATE:  Yeah, so the treeresstats function had a problem in one of the calculations.  I fixed that and added some more calulcations to the function.&lt;/p&gt;

&lt;p&gt;I couldn't find any functions to calculate number of polytomies, and related metrics.&lt;/p&gt;

&lt;p&gt;Here's a simple function that gives four metrics on a phylo tree object:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/1607531.js?file=treeresstats.R&quot;&gt;&lt;/script&gt;


&lt;p&gt;Here's output from the gist above:&lt;/p&gt;

&lt;p&gt;Liquid error: undefined method `join' for #&amp;lt;String:0x104b8b2d0&gt;&lt;/p&gt;

&lt;p&gt;And an example with many trees:&lt;/p&gt;

&lt;table border=&quot;1&quot;&gt;
    &lt;tr&gt;
        &lt;th&gt;trsize_tips&lt;/th&gt;
        &lt;th&gt;trsize_nodes&lt;/th&gt;
        &lt;th&gt;numpolys&lt;/th&gt;
        &lt;th&gt;numpolysbytrsize_tips&lt;/th&gt;
        &lt;th&gt;numpolysbytrsize_nodes&lt;/th&gt;
        &lt;th&gt;proptipsdescpoly&lt;/th&gt;
        &lt;th&gt;propnodesdich&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;20&lt;/td&gt; &lt;td&gt;13&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;td&gt;0.20&lt;/td&gt; &lt;td&gt;0.31&lt;/td&gt; &lt;td&gt;0.7&lt;/td&gt; &lt;td&gt;0.69&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;20&lt;/td&gt; &lt;td&gt;7&lt;/td&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;0.15&lt;/td&gt; &lt;td&gt;0.43&lt;/td&gt; &lt;td&gt;0.9&lt;/td&gt; &lt;td&gt;0.57&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;20&lt;/td&gt; &lt;td&gt;11&lt;/td&gt; &lt;td&gt;6&lt;/td&gt; &lt;td&gt;0.30&lt;/td&gt; &lt;td&gt;0.55&lt;/td&gt; &lt;td&gt;1.0&lt;/td&gt; &lt;td&gt;0.45&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;20&lt;/td&gt; &lt;td&gt;13&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;td&gt;0.20&lt;/td&gt; &lt;td&gt;0.31&lt;/td&gt; &lt;td&gt;0.7&lt;/td&gt; &lt;td&gt;0.69&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;20&lt;/td&gt; &lt;td&gt;9&lt;/td&gt; &lt;td&gt;5&lt;/td&gt; &lt;td&gt;0.25&lt;/td&gt; &lt;td&gt;0.56&lt;/td&gt; &lt;td&gt;1.0&lt;/td&gt; &lt;td&gt;0.44&lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

</description>
				<published>Fri Jan 13 00:00:00 -0600 2012</published>
				<link>http://schamberlain.github.com/2012/01/phylogeny-resolution/</link>
			</item>
		
			<item>
				<title>Moving from blogger and wordpress to jekyll</title>
				<description>&lt;p&gt;Recology used to be hosted on Blogger, and my personal website was hosted on Wordpress.  Neither platform was very satisfying.  Blogger is very limited in their layouts, unless you use dynamic views, which suck because they don't allow javascript snippets to render GitHub gists.  Wordpress is just limited all around as you can't put in hardly anythig excep text and some pictures. They both have their place, but not so much for content that requires syntax highlighting, references, etc.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/mojombo/jekyll&quot;&gt;Jekyll&lt;/a&gt; powered sites on &lt;a href=&quot;https://github.com/&quot;&gt;GitHub&lt;/a&gt; are an awesome alternative.  You do have to write the code yourself, but you can copy any number of templates on GitHub with a simple &lt;code&gt;git clone&lt;/code&gt; onto your machine, edit the text a bit, push it up to GitHub, and that's it.&lt;/p&gt;

&lt;p&gt;On Blogger and Wordpress you can't see the code behind why different blogs/sites look different.  But on Jekyll/GitHub you can see the code behind each site (see &lt;a href=&quot;https://github.com/mojombo/jekyll/wiki/sites&quot;&gt;here&lt;/a&gt; for a list of Jekyll/GitHub sites and their source code), which makes learning so easy.&lt;/p&gt;

&lt;p&gt;Here is a video on YouTube that explains in some detail Jekyll/GitHub sites:&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;http://www.youtube.com/embed/7mXeJlFdZ2c&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;


&lt;p&gt;A great point in the video above is that a Jekyll site allows a workflow that is great not only for code-junkies, but for scientists.  What is the most important thing about science?  That it is reproducible of course.   Documenting your code and sharing with everyone on GitHub or SVN, etc. is great for science in facilitating collaboration and facilitating transparency.  Having your website/blog on Jekyll fits right in to this workflow (that is, pull down any changes - write/edit something - commit - push to GitHub).  Although this sort of worklow isn't necessary for a blog, it is nice for scientists to use this workflow all the time.&lt;/p&gt;

&lt;p&gt;Here's how to get started:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;http://git-scm.com/&quot;&gt;Install git&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/signup/free&quot;&gt;Get a free GitHub account&lt;/a&gt; and &lt;a href=&quot;http://help.github.com/mac-set-up-git/&quot;&gt;configure GitHub&lt;/a&gt;.  If you are afraid of the command line, there is a great GitHub app &lt;a href=&quot;http://mac.github.com/&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git clone&lt;/code&gt; a jekyll template to your machine.  There are hundreds of these now.  Look &lt;a href=&quot;https://github.com/mojombo/jekyll/wiki/sites&quot;&gt;here&lt;/a&gt; for your favorite, and &lt;code&gt;git clone&lt;/code&gt; it. ***&lt;/li&gt;
&lt;li&gt;Edit the template you have cloned, and commit and push to GitHub.  That's it.  It will take just a bit to render.&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;There is more to it than that, but that is how you can get started.  If you want to add comments, &lt;a href=&quot;http://disqus.com/&quot;&gt;Disqus&lt;/a&gt; is a great option.  Once you fork someones jekyll site, make sure to change all the personal/site specific information to your information, including the RSS feed.&lt;/p&gt;

&lt;p&gt;*** Note: You can name your repo for your site/blog as yourgithubname.github.com if you want your URL for the site to be http://yourgithubname.github.com.  Or you can name your repo whatever you want, e.g., disrepo, then the URL will be http://yourgithubname.github.com/disrepo.&lt;/p&gt;
</description>
				<published>Wed Jan 11 00:00:00 -0600 2012</published>
				<link>http://schamberlain.github.com/2012/01/moving-from-blogger-wordpress-to-jekyll/</link>
			</item>
		
			<item>
				<title>Presenting results of logistic regression</title>
				<description>&lt;p&gt;So my advisor pointed out this 'new' (well, 2004), way of plotting results of logistic regression results.  The idea was presented in a 2004 Bulletin of the Ecological Society of America issue (&lt;a href=&quot;http://esapubs.org/bulletin/backissues/085-3/bulletinjuly2004_2column.htm#tools1&quot;&gt;here&lt;/a&gt;).  I tried to come up with a  solution using, what else, ggplot2.  I don't have it quite all the way down - I am missing the second y-axis values for the histograms, but someone smarter than me can figure that part out (note that Hadley doesn't want to support second y-axes in ggplot2, but they can probably be hacked on).&lt;/p&gt;

&lt;p&gt;Here's the code:&lt;/p&gt;

&lt;script src=&quot;https://gist.github.com/1589136.js?file=loghistplot.R&quot;&gt;&lt;/script&gt;


&lt;p&gt;Here's a few examples using datasets provided with the ggplot2 package:&lt;/p&gt;

&lt;p&gt;Liquid error: undefined method `join' for &quot;\nloghistplot(mtcars[,c(\&quot;mpg\&quot;,\&quot;vs\&quot;)])\n&quot;:String&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/mtcarsplot.png&quot; alt=&quot;mtcars plot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Liquid error: undefined method `join' for &quot;\nloghistplot(movies[,c(\&quot;rating\&quot;,\&quot;Action\&quot;)])\n&quot;:String&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/moviesplot.png&quot; alt=&quot;movies plot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And two examples of the logpointplot function:&lt;/p&gt;

&lt;p&gt;Liquid error: undefined method `join' for &quot;\nlogpointplot(mtcars[,c(\&quot;mpg\&quot;,\&quot;vs\&quot;)])\n&quot;:String&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/logpointplot1.png&quot; alt=&quot;mtcars point plot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Liquid error: undefined method `join' for &quot;\nlogpointplot(movies[,c(\&quot;rating\&quot;,\&quot;Action\&quot;)])\n&quot;:String&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/logpointplot2.png&quot; alt=&quot;movies point plot&quot; /&gt;&lt;/p&gt;
</description>
				<published>Tue Jan 10 07:50:00 -0600 2012</published>
				<link>http://schamberlain.github.com/2012/01/logistic-regression-barplot-fig/</link>
			</item>
		
			<item>
				<title>Testing twitterfeed</title>
				<description>&lt;p&gt;Does this work on twitterfeed?&lt;/p&gt;
</description>
				<published>Sun Jan 08 11:33:00 -0600 2012</published>
				<link>http://schamberlain.github.com/2012/01/testing-twitterfeed/</link>
			</item>
		
			<item>
				<title>Testing new website</title>
				<description>&lt;p&gt;Test post on new Jekyll hosted website...&lt;/p&gt;
</description>
				<published>Fri Jan 06 08:08:00 -0600 2012</published>
				<link>http://schamberlain.github.com/2012/01/testing-new-website/</link>
			</item>
		
	</channel>
</rss>