<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
	<channel>
		<title></title>
		<link>http://recology.info/</link>
		
			<item>
				<title>scrubr - clean species occurrence records</title>
				<description>&lt;p&gt;&lt;code&gt;scrubr&lt;/code&gt; is an R library for cleaning species occurrence records. It’s general purpose, and has the following approach:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We think using a piping workflow (&lt;code&gt;%&amp;gt;%&lt;/code&gt;) makes code easier to build up, and easier to understand. However, you don’t have to use pipes in this package.&lt;/li&gt;
  &lt;li&gt;All inputs and outputs are data.frame’s - which makes the above point easier&lt;/li&gt;
  &lt;li&gt;Records trimmed off due to various filters are retained as attributes, so can still be accessed for later inspection, but don’t get in the way of the data.frame that gets modified for downstream use&lt;/li&gt;
  &lt;li&gt;User interface vs. speed: This is the kind of package that surely can get faster. However, we’re focusing on the UI first, then make speed improvements down the road.&lt;/li&gt;
  &lt;li&gt;Since occurrence record datasets should all have columns with lat/long information, we automatically look for those columns for you. If identified, we use them, but you can supply lat/long column names manually as well.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We have many packages that fetch species occurrence records from GBIF, iNaturalist, VertNet, iDigBio, Ecoengine, and more. &lt;code&gt;scrubr&lt;/code&gt; fills a crucial missing niche as likely all uses of occurrence data requires cleaning of some kind. When using GBIF data via &lt;code&gt;rgbif&lt;/code&gt;, that package has some utilities for cleaning data based on the issues returned with GBIF data - &lt;code&gt;scrubr&lt;/code&gt; is a companion to do the rest of the cleaning.&lt;/p&gt;

&lt;h2 id=&quot;scrubr-use-cases&quot;&gt;scrubr use cases&lt;/h2&gt;

&lt;h3 id=&quot;those-covered&quot;&gt;Those covered&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Impossible lat/long values: e.g., latitude 75&lt;/li&gt;
  &lt;li&gt;Incomplete cases: one or the other of lat/long missing&lt;/li&gt;
  &lt;li&gt;Unlikely lat/long values: e.g., points at 0,0&lt;/li&gt;
  &lt;li&gt;Deduplication: try to identify duplicates, esp. when pulling data from multiple sources, e.g., can try to use occurrence IDs, if provided&lt;/li&gt;
  &lt;li&gt;Date based cleaning&lt;/li&gt;
  &lt;li&gt;Outside political boundary: User input to check for points in the wrong country, or points outside of a known country&lt;/li&gt;
  &lt;li&gt;Taxonomic name based cleaning: via &lt;code&gt;taxize&lt;/code&gt; (one method so far)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;to-be-covered&quot;&gt;To be covered&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Political centroids: unlikely that occurrences fall exactly on these points, more likely a
default position (Draft function started, but not exported, and commented out)&lt;/li&gt;
  &lt;li&gt;Herbaria/Museums: many specimens may have location of the collection they are housed in&lt;/li&gt;
  &lt;li&gt;Habitat type filtering: e.g., fish should not be on land; marine fish should not be in fresh water&lt;/li&gt;
  &lt;li&gt;Check for contextually wrong values: That is, if 99 out of 100 lat/long coordinates are within the continental US, but 1 is in China, then perhaps something is wrong with that one point&lt;/li&gt;
  &lt;li&gt;and many more…&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What else do you want included? &lt;a href=&quot;https://github.com/ropenscilabs/scrubr/issues&quot;&gt;Open an issue in the repo&lt;/a&gt; to chat about use cases.&lt;/p&gt;

&lt;h2 id=&quot;install&quot;&gt;Install&lt;/h2&gt;

&lt;p&gt;From CRAN (binaries may not be up yet, but source is)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;install.packages(&quot;scrubr&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or from GitHub&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;devtools::install_github(&quot;ropenscilabs/scrubr&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(&quot;scrubr&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;dframe&quot;&gt;dframe&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;dframe()&lt;/code&gt; is a tool to convert your data.frame to a compact &lt;code&gt;dplyr&lt;/code&gt; like data.frame so that you can get a quick peek at your data each time you call a function - BUT, you don’t have to use it.&lt;/p&gt;

&lt;p&gt;Compare &lt;code&gt;mtcars&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;mtcars
#&amp;gt;                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb
#&amp;gt; Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4
#&amp;gt; Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4
#&amp;gt; Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1
#&amp;gt; Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1
#&amp;gt; Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2
#&amp;gt; Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1
#&amp;gt; Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4
#&amp;gt; Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2
#&amp;gt; Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2
#&amp;gt; Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4
#&amp;gt; Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4
#&amp;gt; Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3
#&amp;gt; Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3
#&amp;gt; Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3
#&amp;gt; Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4
#&amp;gt; Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4
#&amp;gt; Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4
#&amp;gt; Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1
#&amp;gt; Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2
#&amp;gt; Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1
#&amp;gt; Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1
#&amp;gt; Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2
#&amp;gt; AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2
#&amp;gt; Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4
#&amp;gt; Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2
#&amp;gt; Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1
#&amp;gt; Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2
#&amp;gt; Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2
#&amp;gt; Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4
#&amp;gt; Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6
#&amp;gt; Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8
#&amp;gt; Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;dframe(mtcars)
#&amp;gt; &amp;lt;scrubr dframe&amp;gt;
#&amp;gt; Size: 32 X 11
#&amp;gt; 
#&amp;gt; 
#&amp;gt;      mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb
#&amp;gt;    (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl)
#&amp;gt; 1   21.0     6 160.0   110  3.90 2.620 16.46     0     1     4     4
#&amp;gt; 2   21.0     6 160.0   110  3.90 2.875 17.02     0     1     4     4
#&amp;gt; 3   22.8     4 108.0    93  3.85 2.320 18.61     1     1     4     1
#&amp;gt; 4   21.4     6 258.0   110  3.08 3.215 19.44     1     0     3     1
#&amp;gt; 5   18.7     8 360.0   175  3.15 3.440 17.02     0     0     3     2
#&amp;gt; 6   18.1     6 225.0   105  2.76 3.460 20.22     1     0     3     1
#&amp;gt; 7   14.3     8 360.0   245  3.21 3.570 15.84     0     0     3     4
#&amp;gt; 8   24.4     4 146.7    62  3.69 3.190 20.00     1     0     4     2
#&amp;gt; 9   22.8     4 140.8    95  3.92 3.150 22.90     1     0     4     2
#&amp;gt; 10  19.2     6 167.6   123  3.92 3.440 18.30     1     0     4     4
#&amp;gt; ..   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;coordinate-based-cleaning&quot;&gt;Coordinate based cleaning&lt;/h2&gt;

&lt;p&gt;Load some sample data that comes with the package&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;data(&quot;sampledata1&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remove impossible coordinates (using sample data included in the pkg)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;dframe(sample_data_1) %&amp;gt;% coord_impossible()
#&amp;gt; &amp;lt;scrubr dframe&amp;gt;
#&amp;gt; Size: 1500 X 5
#&amp;gt; Lat/Lon vars: latitude/longitude
#&amp;gt; 
#&amp;gt;                name  longitude latitude                date        key
#&amp;gt;               (chr)      (dbl)    (dbl)              (time)      (int)
#&amp;gt; 1  Ursus americanus  -79.68283 38.36662 2015-01-14 16:36:45 1065590124
#&amp;gt; 2  Ursus americanus  -82.42028 35.73304 2015-01-13 00:25:39 1065588899
#&amp;gt; 3  Ursus americanus  -99.09625 23.66893 2015-02-20 23:00:00 1098894889
#&amp;gt; 4  Ursus americanus  -72.77432 43.94883 2015-02-13 16:16:41 1065611122
#&amp;gt; 5  Ursus americanus  -72.34617 43.86464 2015-03-01 20:20:45 1088908315
#&amp;gt; 6  Ursus americanus -108.53674 32.65219 2015-03-29 17:06:54 1088932238
#&amp;gt; 7  Ursus americanus -108.53691 32.65237 2015-03-29 17:12:50 1088932273
#&amp;gt; 8  Ursus americanus -123.82900 40.13240 2015-03-28 23:00:00 1132403409
#&amp;gt; 9  Ursus americanus  -78.25027 36.93018 2015-03-20 21:11:24 1088923534
#&amp;gt; 10 Ursus americanus  -76.78671 35.53079 2015-04-05 23:00:00 1088954559
#&amp;gt; ..              ...        ...      ...                 ...        ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remove incomplete coordinates&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;dframe(sample_data_1) %&amp;gt;% coord_incomplete()
#&amp;gt; &amp;lt;scrubr dframe&amp;gt;
#&amp;gt; Size: 1306 X 5
#&amp;gt; Lat/Lon vars: latitude/longitude
#&amp;gt; 
#&amp;gt;                name  longitude latitude                date        key
#&amp;gt;               (chr)      (dbl)    (dbl)              (time)      (int)
#&amp;gt; 1  Ursus americanus  -79.68283 38.36662 2015-01-14 16:36:45 1065590124
#&amp;gt; 2  Ursus americanus  -82.42028 35.73304 2015-01-13 00:25:39 1065588899
#&amp;gt; 3  Ursus americanus  -99.09625 23.66893 2015-02-20 23:00:00 1098894889
#&amp;gt; 4  Ursus americanus  -72.77432 43.94883 2015-02-13 16:16:41 1065611122
#&amp;gt; 5  Ursus americanus  -72.34617 43.86464 2015-03-01 20:20:45 1088908315
#&amp;gt; 6  Ursus americanus -108.53674 32.65219 2015-03-29 17:06:54 1088932238
#&amp;gt; 7  Ursus americanus -108.53691 32.65237 2015-03-29 17:12:50 1088932273
#&amp;gt; 8  Ursus americanus -123.82900 40.13240 2015-03-28 23:00:00 1132403409
#&amp;gt; 9  Ursus americanus  -78.25027 36.93018 2015-03-20 21:11:24 1088923534
#&amp;gt; 10 Ursus americanus  -76.78671 35.53079 2015-04-05 23:00:00 1088954559
#&amp;gt; ..              ...        ...      ...                 ...        ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remove unlikely coordinates (e.g., those at 0,0)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;dframe(sample_data_1) %&amp;gt;% coord_unlikely()
#&amp;gt; &amp;lt;scrubr dframe&amp;gt;
#&amp;gt; Size: 1488 X 5
#&amp;gt; Lat/Lon vars: latitude/longitude
#&amp;gt; 
#&amp;gt;                name  longitude latitude                date        key
#&amp;gt;               (chr)      (dbl)    (dbl)              (time)      (int)
#&amp;gt; 1  Ursus americanus  -79.68283 38.36662 2015-01-14 16:36:45 1065590124
#&amp;gt; 2  Ursus americanus  -82.42028 35.73304 2015-01-13 00:25:39 1065588899
#&amp;gt; 3  Ursus americanus  -99.09625 23.66893 2015-02-20 23:00:00 1098894889
#&amp;gt; 4  Ursus americanus  -72.77432 43.94883 2015-02-13 16:16:41 1065611122
#&amp;gt; 5  Ursus americanus  -72.34617 43.86464 2015-03-01 20:20:45 1088908315
#&amp;gt; 6  Ursus americanus -108.53674 32.65219 2015-03-29 17:06:54 1088932238
#&amp;gt; 7  Ursus americanus -108.53691 32.65237 2015-03-29 17:12:50 1088932273
#&amp;gt; 8  Ursus americanus -123.82900 40.13240 2015-03-28 23:00:00 1132403409
#&amp;gt; 9  Ursus americanus  -78.25027 36.93018 2015-03-20 21:11:24 1088923534
#&amp;gt; 10 Ursus americanus  -76.78671 35.53079 2015-04-05 23:00:00 1088954559
#&amp;gt; ..              ...        ...      ...                 ...        ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Do all three&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;dframe(sample_data_1) %&amp;gt;%
  coord_impossible() %&amp;gt;%
  coord_incomplete() %&amp;gt;%
  coord_unlikely()
#&amp;gt; &amp;lt;scrubr dframe&amp;gt;
#&amp;gt; Size: 1294 X 5
#&amp;gt; Lat/Lon vars: latitude/longitude
#&amp;gt; 
#&amp;gt;                name  longitude latitude                date        key
#&amp;gt;               (chr)      (dbl)    (dbl)              (time)      (int)
#&amp;gt; 1  Ursus americanus  -79.68283 38.36662 2015-01-14 16:36:45 1065590124
#&amp;gt; 2  Ursus americanus  -82.42028 35.73304 2015-01-13 00:25:39 1065588899
#&amp;gt; 3  Ursus americanus  -99.09625 23.66893 2015-02-20 23:00:00 1098894889
#&amp;gt; 4  Ursus americanus  -72.77432 43.94883 2015-02-13 16:16:41 1065611122
#&amp;gt; 5  Ursus americanus  -72.34617 43.86464 2015-03-01 20:20:45 1088908315
#&amp;gt; 6  Ursus americanus -108.53674 32.65219 2015-03-29 17:06:54 1088932238
#&amp;gt; 7  Ursus americanus -108.53691 32.65237 2015-03-29 17:12:50 1088932273
#&amp;gt; 8  Ursus americanus -123.82900 40.13240 2015-03-28 23:00:00 1132403409
#&amp;gt; 9  Ursus americanus  -78.25027 36.93018 2015-03-20 21:11:24 1088923534
#&amp;gt; 10 Ursus americanus  -76.78671 35.53079 2015-04-05 23:00:00 1088954559
#&amp;gt; ..              ...        ...      ...                 ...        ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Do vs. don’t drop bad data&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;# do
dframe(sample_data_1) %&amp;gt;% coord_incomplete(drop = TRUE) %&amp;gt;% NROW
#&amp;gt; [1] 1306
# don&#39;t
dframe(sample_data_1) %&amp;gt;% coord_incomplete(drop = FALSE) %&amp;gt;% NROW
#&amp;gt; [1] 1500
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;deduplicate&quot;&gt;Deduplicate&lt;/h2&gt;

&lt;p&gt;Get a smaller subset of a data.frame&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;smalldf &amp;lt;- sample_data_1[1:20, ]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;create a duplicate record&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;smalldf &amp;lt;- rbind(smalldf, smalldf[10,])
row.names(smalldf) &amp;lt;- NULL
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;make it slightly different&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;smalldf[21, &quot;key&quot;] &amp;lt;- 1088954555
NROW(smalldf)
#&amp;gt; [1] 21
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It’s 21 rows, including 1 duplicate. Do the deduplication&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;(dp &amp;lt;- dframe(smalldf) %&amp;gt;% dedup())
#&amp;gt; &amp;lt;scrubr dframe&amp;gt;
#&amp;gt; Size: 20 X 5
#&amp;gt; 
#&amp;gt; 
#&amp;gt;                name  longitude latitude                date        key
#&amp;gt;               (chr)      (dbl)    (dbl)              (time)      (dbl)
#&amp;gt; 1  Ursus americanus  -79.68283 38.36662 2015-01-14 16:36:45 1065590124
#&amp;gt; 2  Ursus americanus  -82.42028 35.73304 2015-01-13 00:25:39 1065588899
#&amp;gt; 3  Ursus americanus  -99.09625 23.66893 2015-02-20 23:00:00 1098894889
#&amp;gt; 4  Ursus americanus  -72.77432 43.94883 2015-02-13 16:16:41 1065611122
#&amp;gt; 5  Ursus americanus  -72.34617 43.86464 2015-03-01 20:20:45 1088908315
#&amp;gt; 6  Ursus americanus -108.53674 32.65219 2015-03-29 17:06:54 1088932238
#&amp;gt; 7  Ursus americanus -108.53691 32.65237 2015-03-29 17:12:50 1088932273
#&amp;gt; 8  Ursus americanus -123.82900 40.13240 2015-03-28 23:00:00 1132403409
#&amp;gt; 9  Ursus americanus  -78.25027 36.93018 2015-03-20 21:11:24 1088923534
#&amp;gt; 10 Ursus americanus -103.30058 29.27042 2015-04-29 22:00:00 1088964797
#&amp;gt; ..              ...        ...      ...                 ...        ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now its 20 rows, duplicate removed&lt;/p&gt;

&lt;p&gt;Here’s the duplicates&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;attr(dp, &quot;dups&quot;)
#&amp;gt; &amp;lt;scrubr dframe&amp;gt;
#&amp;gt; Size: 1 X 5
#&amp;gt; 
#&amp;gt; 
#&amp;gt;               name longitude latitude                date        key
#&amp;gt;              (chr)     (dbl)    (dbl)              (time)      (dbl)
#&amp;gt; 1 Ursus americanus -76.78671 35.53079 2015-04-05 23:00:00 1088954555
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;dates&quot;&gt;Dates&lt;/h2&gt;

&lt;p&gt;Standardize/convert dates&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;df &amp;lt;- sample_data_1
dframe(df) %&amp;gt;% 
  date_standardize(&quot;%d%b%Y&quot;)
#&amp;gt; &amp;lt;scrubr dframe&amp;gt;
#&amp;gt; Size: 1500 X 5
#&amp;gt; 
#&amp;gt; 
#&amp;gt;                name  longitude latitude      date        key
#&amp;gt;               (chr)      (dbl)    (dbl)     (chr)      (int)
#&amp;gt; 1  Ursus americanus  -79.68283 38.36662 14Jan2015 1065590124
#&amp;gt; 2  Ursus americanus  -82.42028 35.73304 13Jan2015 1065588899
#&amp;gt; 3  Ursus americanus  -99.09625 23.66893 20Feb2015 1098894889
#&amp;gt; 4  Ursus americanus  -72.77432 43.94883 13Feb2015 1065611122
#&amp;gt; 5  Ursus americanus  -72.34617 43.86464 01Mar2015 1088908315
#&amp;gt; 6  Ursus americanus -108.53674 32.65219 29Mar2015 1088932238
#&amp;gt; 7  Ursus americanus -108.53691 32.65237 29Mar2015 1088932273
#&amp;gt; 8  Ursus americanus -123.82900 40.13240 28Mar2015 1132403409
#&amp;gt; 9  Ursus americanus  -78.25027 36.93018 20Mar2015 1088923534
#&amp;gt; 10 Ursus americanus  -76.78671 35.53079 05Apr2015 1088954559
#&amp;gt; ..              ...        ...      ...       ...        ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Drop records without dates&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;NROW(df)
#&amp;gt; [1] 1500
NROW(dframe(df) %&amp;gt;% date_missing())
#&amp;gt; [1] 1498
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Create date field from other fields&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;dframe(sample_data_2) %&amp;gt;% 
  date_create(year, month, day)
#&amp;gt; &amp;lt;scrubr dframe&amp;gt;
#&amp;gt; Size: 1500 X 8
#&amp;gt; 
#&amp;gt; 
#&amp;gt;                name  longitude latitude        key  year month   day
#&amp;gt;               (chr)      (dbl)    (dbl)      (int) (chr) (chr) (chr)
#&amp;gt; 1  Ursus americanus  -79.68283 38.36662 1065590124  2015    01    14
#&amp;gt; 2  Ursus americanus  -82.42028 35.73304 1065588899  2015    01    13
#&amp;gt; 3  Ursus americanus  -99.09625 23.66893 1098894889  2015    02    20
#&amp;gt; 4  Ursus americanus  -72.77432 43.94883 1065611122  2015    02    13
#&amp;gt; 5  Ursus americanus  -72.34617 43.86464 1088908315  2015    03    01
#&amp;gt; 6  Ursus americanus -108.53674 32.65219 1088932238  2015    03    29
#&amp;gt; 7  Ursus americanus -108.53691 32.65237 1088932273  2015    03    29
#&amp;gt; 8  Ursus americanus -123.82900 40.13240 1132403409  2015    03    28
#&amp;gt; 9  Ursus americanus  -78.25027 36.93018 1088923534  2015    03    20
#&amp;gt; 10 Ursus americanus  -76.78671 35.53079 1088954559  2015    04    05
#&amp;gt; ..              ...        ...      ...        ...   ...   ...   ...
#&amp;gt; Variables not shown: date (chr).
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;bugs-and-such&quot;&gt;bugs and such&lt;/h2&gt;

&lt;p&gt;Report them in the &lt;a href=&quot;https://github.com/ropenscilabs/scrubr/issues&quot;&gt;scrubr issue tracker&lt;/a&gt;&lt;/p&gt;
</description>
				<published>2016-03-04 00:00:00 -0800</published>
				<link>http://recology.info//2016/03/scrubr/</link>
			</item>
		
			<item>
				<title>request - a high level HTTP client for R</title>
				<description>&lt;p&gt;&lt;code&gt;request&lt;/code&gt; is DSL for http requests for R, and is inspired by the CLI tool &lt;a href=&quot;https://github.com/jakubroztocil/httpie&quot;&gt;httpie&lt;/a&gt;. It’s built on &lt;code&gt;httr&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The following were driving principles for this package:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The web is increasingly a JSON world, so we assume &lt;code&gt;applications/json&lt;/code&gt; by default, but give back other types if not&lt;/li&gt;
  &lt;li&gt;The workflow follows logically, or at least should, from, &lt;em&gt;hey, I got this url&lt;/em&gt;, to &lt;em&gt;i need to add some options&lt;/em&gt;, to &lt;em&gt;execute request&lt;/em&gt; - and functions support piping so that you can execute functions in this order&lt;/li&gt;
  &lt;li&gt;Whenever possible, we transform output to data.frame’s - facilitating downstream manipulation via &lt;code&gt;dplyr&lt;/code&gt;, etc.&lt;/li&gt;
  &lt;li&gt;We do &lt;code&gt;GET&lt;/code&gt; requests by default. Specify a different type if you don’t want &lt;code&gt;GET&lt;/code&gt;. Given &lt;code&gt;GET&lt;/code&gt; by default, this client is optimized for consumption of data, rather than creating new things on servers&lt;/li&gt;
  &lt;li&gt;You can use non-standard evaluation to easily pass in query parameters without worrying about &lt;code&gt;&amp;amp;&lt;/code&gt;’s, URL escaping, etc. (see &lt;code&gt;api_query()&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;Same for body params (see &lt;code&gt;api_body()&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The following is a brief demo of some of the package functionality:&lt;/p&gt;

&lt;h2 id=&quot;install&quot;&gt;Install&lt;/h2&gt;

&lt;p&gt;From CRAN&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;install.packages(&quot;request&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or from GitHub&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;devtools::install_github(&quot;sckott/request&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(&quot;request&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;execute-on-last-pipe&quot;&gt;Execute on last pipe&lt;/h2&gt;

&lt;p&gt;When using pipes (&lt;code&gt;%&amp;gt;%&lt;/code&gt;) in &lt;code&gt;request&lt;/code&gt;, we autodetect last piped command, and execute &lt;code&gt;http()&lt;/code&gt; if it’s the last. If not the last, the output gets passed to the next command, and so on. This feature (and &lt;code&gt;magrittr&lt;/code&gt;) were done by Stefan Milton Bache.&lt;/p&gt;

&lt;p&gt;This feature is really nice because a) it’s one less thing you need to do, and b) you only need to care about the request itself.&lt;/p&gt;

&lt;p&gt;You can escape auto-execution if you use the function &lt;code&gt;peep()&lt;/code&gt;, which prints out a summary of the request you’ve created, but does not execute an HTTP request.&lt;/p&gt;

&lt;h2 id=&quot;http-requests&quot;&gt;HTTP Requests&lt;/h2&gt;

&lt;p&gt;A high level function &lt;code&gt;http()&lt;/code&gt; wraps a lower level &lt;code&gt;R6&lt;/code&gt; object &lt;code&gt;RequestIterator&lt;/code&gt;, which holds a series of variables and functions to execute &lt;code&gt;GET&lt;/code&gt; and &lt;code&gt;POST&lt;/code&gt; requests, and will hold other HTTP verbs as well. In addition, it can hold state, which will allow us to do paging internally for you (see below). You have direct access to the &lt;code&gt;R6&lt;/code&gt; object if you call &lt;code&gt;http_client()&lt;/code&gt; instead of &lt;code&gt;http()&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;nse-and-se&quot;&gt;NSE and SE&lt;/h2&gt;

&lt;p&gt;Most if not all functions in &lt;code&gt;request&lt;/code&gt; support non-standard evaluation (NSE) as well as standard evaluation (SE). If a function supports both, there’s a version without an underscore for NSE, while a version with an underscore is for SE. For example, here, we make a HTTP request by passing a base URL, then a series of paths that get combined together. First the NSE version&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;api(&#39;https://api.github.com/&#39;) %&amp;gt;%
  api_path(repos, ropensci, rgbif, issues)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then the SE version&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;api(&#39;https://api.github.com/&#39;) %&amp;gt;%
  api_path_(&#39;repos&#39;, &#39;ropensci&#39;, &#39;rgbif&#39;, &#39;issues&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;building-api-routes&quot;&gt;Building API routes&lt;/h2&gt;

&lt;p&gt;The first thing you’ll want to do is lay out the base URL for your request. The function &lt;code&gt;api()&lt;/code&gt; is your friend.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;api()&lt;/code&gt; works with full or partial URLs:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;api(&#39;https://api.github.com/&#39;)
#&amp;gt; URL: https://api.github.com/
api(&#39;http://api.gbif.org/v1&#39;)
#&amp;gt; URL: http://api.gbif.org/v1
api(&#39;api.gbif.org/v1&#39;)
#&amp;gt; URL: api.gbif.org/v1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And works with ports, full or partial&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;api(&#39;http://localhost:9200&#39;)
#&amp;gt; URL: http://localhost:9200
api(&#39;localhost:9200&#39;)
#&amp;gt; URL: http://localhost:9200
api(&#39;:9200&#39;)
#&amp;gt; URL: http://localhost:9200
api(&#39;9200&#39;)
#&amp;gt; URL: http://localhost:9200
api(&#39;9200/stuff&#39;)
#&amp;gt; URL: http://localhost:9200/stuff
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;make-http-requests&quot;&gt;Make HTTP requests&lt;/h2&gt;

&lt;p&gt;The above examples with &lt;code&gt;api()&lt;/code&gt; are not passed through a pipe, so only define a URL, but don’t do an HTTP request. To make an HTTP request, you can either pipe a url or partial url to e.g., &lt;code&gt;api()&lt;/code&gt;, or call &lt;code&gt;http()&lt;/code&gt; at the end of a string of function calls:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;&#39;https://api.github.com/&#39; %&amp;gt;% api()
#&amp;gt; $current_user_url
#&amp;gt; [1] &quot;https://api.github.com/user&quot;
#&amp;gt;
#&amp;gt; $current_user_authorizations_html_url
#&amp;gt; [1] &quot;https://github.com/settings/connections/applications{/client_id}&quot;
#&amp;gt;
#&amp;gt; $authorizations_url
#&amp;gt; [1] &quot;https://api.github.com/authorizations&quot;
#&amp;gt;
#&amp;gt; $code_search_url
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;api(&#39;https://api.github.com/&#39;) %&amp;gt;% http()
#&amp;gt; $current_user_url
#&amp;gt; [1] &quot;https://api.github.com/user&quot;
#&amp;gt;
#&amp;gt; $current_user_authorizations_html_url
#&amp;gt; [1] &quot;https://github.com/settings/connections/applications{/client_id}&quot;
#&amp;gt;
#&amp;gt; $authorizations_url
#&amp;gt; [1] &quot;https://api.github.com/authorizations&quot;
#&amp;gt;
#&amp;gt; $code_search_url
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;http()&lt;/code&gt; is called at the end of a chain of piped commands, so no need to invoke it. However, you can if you like.&lt;/p&gt;

&lt;h2 id=&quot;templating&quot;&gt;Templating&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;repo_info &amp;lt;- list(username = &#39;craigcitro&#39;, repo = &#39;r-travis&#39;)
api(&#39;https://api.github.com/&#39;) %&amp;gt;%
  api_template(template = &#39;repos///issues&#39;, data = repo_info)
#&amp;gt; [[1]]
#&amp;gt; [[1]]$url
#&amp;gt; [1] &quot;https://api.github.com/repos/craigcitro/r-travis/issues/164&quot;
#&amp;gt;
#&amp;gt; [[1]]$labels_url
#&amp;gt; [1] &quot;https://api.github.com/repos/craigcitro/r-travis/issues/164/labels{/name}&quot;
#&amp;gt;
#&amp;gt; [[1]]$comments_url
#&amp;gt; [1] &quot;https://api.github.com/repos/craigcitro/r-travis/issues/164/comments&quot;
#&amp;gt; ...
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;set-paths&quot;&gt;Set paths&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;api_path()&lt;/code&gt; adds paths to the base URL&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;api(&#39;https://api.github.com/&#39;) %&amp;gt;%
  api_path(repos, ropensci, rgbif, issues) %&amp;gt;%
  peep
#&amp;gt; &amp;lt;http request&amp;gt;
#&amp;gt;   url: https://api.github.com/
#&amp;gt;   paths: repos/ropensci/rgbif/issues
#&amp;gt;   query:
#&amp;gt;   body:
#&amp;gt;   paging:
#&amp;gt;   headers:
#&amp;gt;   rate limit:
#&amp;gt;   retry (n/delay (s)): /
#&amp;gt;   error handler:
#&amp;gt;   config:
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;query&quot;&gt;Query&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;api(&quot;http://api.plos.org/search&quot;) %&amp;gt;%
  api_query(q = ecology, wt = json, fl = journal) %&amp;gt;%
  peep
#&amp;gt; &amp;lt;http request&amp;gt;
#&amp;gt;   url: http://api.plos.org/search
#&amp;gt;   paths:
#&amp;gt;   query: q=ecology, wt=json, fl=journal
#&amp;gt;   body:
#&amp;gt;   paging:
#&amp;gt;   headers:
#&amp;gt;   rate limit:
#&amp;gt;   retry (n/delay (s)): /
#&amp;gt;   error handler:
#&amp;gt;   config:
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;headers&quot;&gt;Headers&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;api(&#39;http://httpbin.org/headers&#39;) %&amp;gt;%
  api_headers(`X-FARGO-SEASON` = 3, `X-NARCOS-SEASON` = 5) %&amp;gt;%
  peep
#&amp;gt; &amp;lt;http request&amp;gt;
#&amp;gt;   url: http://httpbin.org/headers
#&amp;gt;   paths:
#&amp;gt;   query:
#&amp;gt;   body:
#&amp;gt;   paging:
#&amp;gt;   headers:
#&amp;gt;     X-FARGO-SEASON: 3
#&amp;gt;     X-NARCOS-SEASON: 5
#&amp;gt;   rate limit:
#&amp;gt;   retry (n/delay (s)): /
#&amp;gt;   error handler:
#&amp;gt;   config:
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;curl-configuration&quot;&gt;curl configuration&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;httr&lt;/code&gt; is exported in &lt;code&gt;request&lt;/code&gt;, so you can use &lt;code&gt;httr&lt;/code&gt; functions like &lt;code&gt;verbose()&lt;/code&gt; to get verbose curl output&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;api(&#39;http://httpbin.org/headers&#39;) %&amp;gt;%
  api_config(verbose())
#&amp;gt; -&amp;gt; GET /headers HTTP/1.1
#&amp;gt; -&amp;gt; Host: httpbin.org
#&amp;gt; -&amp;gt; User-Agent: curl/7.43.0 curl/0.9.4 httr/1.0.0 request/0.1.0
#&amp;gt; -&amp;gt; Accept-Encoding: gzip, deflate
#&amp;gt; -&amp;gt; Accept: application/json, text/xml, application/xml, */*
#&amp;gt; -&amp;gt;
#&amp;gt; &amp;lt;- HTTP/1.1 200 OK
#&amp;gt; &amp;lt;- Server: nginx
#&amp;gt; &amp;lt;- Date: Sun, 03 Jan 2016 16:56:29 GMT
#&amp;gt; &amp;lt;- Content-Type: application/json
#&amp;gt; &amp;lt;- Content-Length: 227
#&amp;gt; &amp;lt;- Connection: keep-alive
#&amp;gt; &amp;lt;- Access-Control-Allow-Origin: *
#&amp;gt; &amp;lt;- Access-Control-Allow-Credentials: true
#&amp;gt; &amp;lt;-
#&amp;gt; $headers
#&amp;gt; $headers$Accept
#&amp;gt; [1] &quot;application/json, text/xml, application/xml, */*&quot;
#&amp;gt; ...
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;coming-soon&quot;&gt;Coming soon&lt;/h2&gt;

&lt;p&gt;There’s a number of interesting features that should be coming soon to &lt;code&gt;request&lt;/code&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Paging - a paging helper will make it easy to do paing, and will attempt to handle any parameters used for paging. Some user input will be required, like what parameter names are, and how many records you want returned  &lt;a href=&quot;https://github.com/sckott/request/issues/2&quot;&gt;sckott/request#2&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Retry - a retry helper will make it easy to retry http requests on any failure, and execute a user defined function on failure &lt;a href=&quot;https://github.com/sckott/request/issues/6&quot;&gt;sckott/request#6&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Rate limit - a rate limit helper will add info to a set of many requests - still in early design stages &lt;a href=&quot;https://github.com/sckott/request/issues/5&quot;&gt;sckott/request#5&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Caching - a caching helper - may use in the background the in development &lt;a href=&quot;https://github.com/ropensci/vcr&quot;&gt;vcr R client&lt;/a&gt; when on CRAN or perhaps &lt;a href=&quot;https://github.com/richfitz/storr&quot;&gt;storr&lt;/a&gt;  &lt;a href=&quot;https://github.com/sckott/request/issues/4&quot;&gt;sckott/request#4&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
				<published>2016-01-05 00:00:00 -0800</published>
				<link>http://recology.info//2016/01/request-hello-world/</link>
			</item>
		
			<item>
				<title>binomen - Tools for slicing and dicing taxonomic names</title>
				<description>&lt;p&gt;The first version of &lt;code&gt;binomen&lt;/code&gt; is now up on &lt;a href=&quot;https://cran.rstudio.com/web/packages/binomen&quot;&gt;CRAN&lt;/a&gt;. It provides various taxonomic classes for defining a single taxon, multiple taxa, and a taxonomic data.frame. It is designed as a companion to &lt;a href=&quot;https://github.com/ropensci/taxize&quot;&gt;taxize&lt;/a&gt;, where you can get taxonomic data on taxonomic names from the web.&lt;/p&gt;

&lt;p&gt;The classes (S3):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;taxon&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;taxonref&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;taxonrefs&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;binomial&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;grouping&lt;/code&gt; (i.e., classification - used different term to avoid conflict with classification in &lt;code&gt;taxize&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For example, the &lt;code&gt;binomial&lt;/code&gt; class is defined by a genus, epithet, authority, and optional full species name and canonical version.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;binomial(&quot;Poa&quot;, &quot;annua&quot;, authority=&quot;L.&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;&amp;lt;binomial&amp;gt;
  genus: Poa
  epithet: annua
  canonical:
  species:
  authority: L.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The package has a suite of functions to work on these taxonomic classes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;gethier()&lt;/code&gt; - get hierarchy from a &lt;code&gt;taxon&lt;/code&gt; class&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;scatter()&lt;/code&gt; - make each row in taxonomic data.frame (&lt;code&gt;taxondf&lt;/code&gt;) a separate &lt;code&gt;taxon&lt;/code&gt; object within a single &lt;code&gt;taxa&lt;/code&gt; object&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;assemble()&lt;/code&gt; - make a &lt;code&gt;taxa&lt;/code&gt; object into a &lt;code&gt;taxondf&lt;/code&gt; data.frame&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;pick()&lt;/code&gt; - pick out one or more taxonomic groups&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;pop()&lt;/code&gt; - pop out (drop) one or more taxonomic groups&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;span()&lt;/code&gt; - pick a range between two taxonomic groups (inclusive)&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;strain()&lt;/code&gt; - filter by taxonomic groups, like dplyr’s filter&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;name()&lt;/code&gt; - get the taxon name for each &lt;code&gt;taxonref&lt;/code&gt; object&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;uri()&lt;/code&gt; - get the reference uri for each &lt;code&gt;taxonref&lt;/code&gt; object&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;rank()&lt;/code&gt; - get the taxonomic rank for each &lt;code&gt;taxonref&lt;/code&gt; object&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;id()&lt;/code&gt; - get the reference uri for each &lt;code&gt;taxonref&lt;/code&gt; object&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The approach in this package I suppose is sort of like &lt;code&gt;split-apply-combine&lt;/code&gt; from &lt;code&gt;plyr&lt;/code&gt;/&lt;code&gt;dplyr&lt;/code&gt;, whereas this is aims to make it easy to do with taxonomic names.&lt;/p&gt;

&lt;h2 id=&quot;install&quot;&gt;Install&lt;/h2&gt;

&lt;p&gt;For examples below, you’ll need the development version:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;install.packages(&quot;binomen&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(&quot;binomen&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;make-a-taxon&quot;&gt;Make a taxon&lt;/h2&gt;

&lt;p&gt;Make a taxon object&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;(obj &amp;lt;- make_taxon(genus=&quot;Poa&quot;, epithet=&quot;annua&quot;, authority=&quot;L.&quot;,
  family=&#39;Poaceae&#39;, clazz=&#39;Poales&#39;, kingdom=&#39;Plantae&#39;, variety=&#39;annua&#39;))
#&amp;gt; &amp;lt;taxon&amp;gt;
#&amp;gt;   binomial: Poa annua
#&amp;gt;   grouping: 
#&amp;gt;     kingdom: Plantae
#&amp;gt;     clazz: Poales
#&amp;gt;     family: Poaceae
#&amp;gt;     genus: Poa
#&amp;gt;     species: Poa annua
#&amp;gt;     variety: annua
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Index to various parts of the object&lt;/p&gt;

&lt;p&gt;The binomial&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;obj$binomial
#&amp;gt; &amp;lt;binomial&amp;gt;
#&amp;gt;   genus: Poa
#&amp;gt;   epithet: annua
#&amp;gt;   canonical: Poa annua
#&amp;gt;   species: Poa annua L.
#&amp;gt;   authority: L.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The authority&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;obj$binomial$authority
#&amp;gt; [1] &quot;L.&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The classification&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;obj$grouping
#&amp;gt; &amp;lt;grouping&amp;gt;
#&amp;gt;   kingdom: Plantae
#&amp;gt;   clazz: Poales
#&amp;gt;   family: Poaceae
#&amp;gt;   genus: Poa
#&amp;gt;   species: Poa annua
#&amp;gt;   variety: annua
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The family&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;obj$grouping$family
#&amp;gt; &amp;lt;taxonref&amp;gt;
#&amp;gt;   rank: family
#&amp;gt;   name: Poaceae
#&amp;gt;   id: none
#&amp;gt;   uri: none
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;subset-taxon-objects&quot;&gt;Subset taxon objects&lt;/h2&gt;

&lt;p&gt;Get one or more ranks via &lt;code&gt;pick()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;obj %&amp;gt;% pick(family)
#&amp;gt; &amp;lt;taxon&amp;gt;
#&amp;gt;   binomial: Poa annua
#&amp;gt;   grouping: 
#&amp;gt;     family: Poaceae
obj %&amp;gt;% pick(family, genus)
#&amp;gt; &amp;lt;taxon&amp;gt;
#&amp;gt;   binomial: Poa annua
#&amp;gt;   grouping: 
#&amp;gt;     family: Poaceae
#&amp;gt;     genus: Poa
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Drop one or more ranks via &lt;code&gt;pop()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;obj %&amp;gt;% pop(family)
#&amp;gt; &amp;lt;taxon&amp;gt;
#&amp;gt;   binomial: Poa annua
#&amp;gt;   grouping: 
#&amp;gt;     kingdom: Plantae
#&amp;gt;     clazz: Poales
#&amp;gt;     genus: Poa
#&amp;gt;     species: Poa annua
#&amp;gt;     variety: annua
obj %&amp;gt;% pop(family, genus)
#&amp;gt; &amp;lt;taxon&amp;gt;
#&amp;gt;   binomial: Poa annua
#&amp;gt;   grouping: 
#&amp;gt;     kingdom: Plantae
#&amp;gt;     clazz: Poales
#&amp;gt;     species: Poa annua
#&amp;gt;     variety: annua
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Get a range of ranks via &lt;code&gt;span()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;obj %&amp;gt;% span(kingdom, family)
#&amp;gt; &amp;lt;taxon&amp;gt;
#&amp;gt;   binomial: Poa annua
#&amp;gt;   grouping: 
#&amp;gt;     kingdom: Plantae
#&amp;gt;     clazz: Poales
#&amp;gt;     family: Poaceae
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Extract classification as a &lt;code&gt;data.frame&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;gethier(obj)
#&amp;gt;      rank      name
#&amp;gt; 1 kingdom   Plantae
#&amp;gt; 2   clazz    Poales
#&amp;gt; 3  family   Poaceae
#&amp;gt; 4   genus       Poa
#&amp;gt; 5 species Poa annua
#&amp;gt; 6 variety     annua
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;taxonomic-dataframes&quot;&gt;Taxonomic data.frame’s&lt;/h2&gt;

&lt;p&gt;Make one&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;df &amp;lt;- data.frame(order = c(&#39;Asterales&#39;,&#39;Asterales&#39;,&#39;Fagales&#39;,&#39;Poales&#39;,&#39;Poales&#39;,&#39;Poales&#39;),
  family = c(&#39;Asteraceae&#39;,&#39;Asteraceae&#39;,&#39;Fagaceae&#39;,&#39;Poaceae&#39;,&#39;Poaceae&#39;,&#39;Poaceae&#39;),
  genus = c(&#39;Helianthus&#39;,&#39;Helianthus&#39;,&#39;Quercus&#39;,&#39;Poa&#39;,&#39;Festuca&#39;,&#39;Holodiscus&#39;),
  stringsAsFactors = FALSE)
(df2 &amp;lt;- taxon_df(df))
#&amp;gt;       order     family      genus
#&amp;gt; 1 Asterales Asteraceae Helianthus
#&amp;gt; 2 Asterales Asteraceae Helianthus
#&amp;gt; 3   Fagales   Fagaceae    Quercus
#&amp;gt; 4    Poales    Poaceae        Poa
#&amp;gt; 5    Poales    Poaceae    Festuca
#&amp;gt; 6    Poales    Poaceae Holodiscus
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Parse - get rank order via &lt;code&gt;pick()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;df2 %&amp;gt;% pick(order)
#&amp;gt;       order
#&amp;gt; 1 Asterales
#&amp;gt; 2 Asterales
#&amp;gt; 3   Fagales
#&amp;gt; 4    Poales
#&amp;gt; 5    Poales
#&amp;gt; 6    Poales
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;get ranks order, family, and genus via &lt;code&gt;pick()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;df2 %&amp;gt;% pick(order, family, genus)
#&amp;gt;       order     family      genus
#&amp;gt; 1 Asterales Asteraceae Helianthus
#&amp;gt; 2 Asterales Asteraceae Helianthus
#&amp;gt; 3   Fagales   Fagaceae    Quercus
#&amp;gt; 4    Poales    Poaceae        Poa
#&amp;gt; 5    Poales    Poaceae    Festuca
#&amp;gt; 6    Poales    Poaceae Holodiscus
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;get range of names via &lt;code&gt;span()&lt;/code&gt;, from rank &lt;code&gt;X&lt;/code&gt; to rank &lt;code&gt;Y&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;df2 %&amp;gt;% span(family, genus)
#&amp;gt;       family      genus
#&amp;gt; 1 Asteraceae Helianthus
#&amp;gt; 2 Asteraceae Helianthus
#&amp;gt; 3   Fagaceae    Quercus
#&amp;gt; 4    Poaceae        Poa
#&amp;gt; 5    Poaceae    Festuca
#&amp;gt; 6    Poaceae Holodiscus
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Separate each row into a &lt;code&gt;taxon&lt;/code&gt; class (many &lt;code&gt;taxon&lt;/code&gt; objects are a &lt;code&gt;taxa&lt;/code&gt; class)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;scatter(df2)
#&amp;gt; [[1]]
#&amp;gt; &amp;lt;taxon&amp;gt;
#&amp;gt;   binomial: Helianthus none
#&amp;gt;   grouping: 
#&amp;gt;     order: Asterales
#&amp;gt;     family: Asteraceae
#&amp;gt;     genus: Helianthus
#&amp;gt;     species: Helianthus none
#&amp;gt; 
#&amp;gt; [[2]]
#&amp;gt; &amp;lt;taxon&amp;gt;
#&amp;gt;   binomial: Helianthus none
#&amp;gt;   grouping: 
#&amp;gt;     order: Asterales
#&amp;gt;     family: Asteraceae
#&amp;gt;     genus: Helianthus
#&amp;gt;     species: Helianthus none
#&amp;gt; 
#&amp;gt; [[3]]
#&amp;gt; &amp;lt;taxon&amp;gt;
#&amp;gt;   binomial: Quercus none
#&amp;gt;   grouping: 
#&amp;gt;     order: Fagales
#&amp;gt;     family: Fagaceae
#&amp;gt;     genus: Quercus
#&amp;gt;     species: Quercus none
#&amp;gt; 
#&amp;gt; [[4]]
#&amp;gt; &amp;lt;taxon&amp;gt;
#&amp;gt;   binomial: Poa none
#&amp;gt;   grouping: 
#&amp;gt;     order: Poales
#&amp;gt;     family: Poaceae
#&amp;gt;     genus: Poa
#&amp;gt;     species: Poa none
#&amp;gt; 
#&amp;gt; [[5]]
#&amp;gt; &amp;lt;taxon&amp;gt;
#&amp;gt;   binomial: Festuca none
#&amp;gt;   grouping: 
#&amp;gt;     order: Poales
#&amp;gt;     family: Poaceae
#&amp;gt;     genus: Festuca
#&amp;gt;     species: Festuca none
#&amp;gt; 
#&amp;gt; [[6]]
#&amp;gt; &amp;lt;taxon&amp;gt;
#&amp;gt;   binomial: Holodiscus none
#&amp;gt;   grouping: 
#&amp;gt;     order: Poales
#&amp;gt;     family: Poaceae
#&amp;gt;     genus: Holodiscus
#&amp;gt;     species: Holodiscus none
#&amp;gt; 
#&amp;gt; attr(,&quot;class&quot;)
#&amp;gt; [1] &quot;taxa&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And you can re-assemble a data.frame from the output of &lt;code&gt;scatter()&lt;/code&gt; with &lt;code&gt;assemble()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;out &amp;lt;- scatter(df2)
assemble(out)
#&amp;gt;       order     family      genus         species
#&amp;gt; 1 Asterales Asteraceae Helianthus Helianthus none
#&amp;gt; 2 Asterales Asteraceae Helianthus Helianthus none
#&amp;gt; 3   Fagales   Fagaceae    Quercus    Quercus none
#&amp;gt; 4    Poales    Poaceae        Poa        Poa none
#&amp;gt; 5    Poales    Poaceae    Festuca    Festuca none
#&amp;gt; 6    Poales    Poaceae Holodiscus Holodiscus none
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;thoughts&quot;&gt;Thoughts?&lt;/h2&gt;

&lt;p&gt;I’m really curious what people think of &lt;code&gt;binomen&lt;/code&gt;. I’m not sure how useful this will be in the wild. Try it. Let me know. Thanks much :)&lt;/p&gt;

</description>
				<published>2015-12-08 00:00:00 -0800</published>
				<link>http://recology.info//2015/12/binomen-taxonomy-tools/</link>
			</item>
		
			<item>
				<title>Crossref programmatic clients</title>
				<description>&lt;p&gt;I gave two talks recently at the annual &lt;a href=&quot;http://www.crossref.org/annualmeeting/agenda.html&quot;&gt;Crossref meeting&lt;/a&gt;, one of which was a somewhat technical overview of programmatic clients for Crossref APIs. Check out the talk &lt;a href=&quot;https://crossref.wistia.com/medias/8rh0jm5eda&quot;&gt;here&lt;/a&gt;. I talked about the motivation for working with Crossref data by writing code/etc. rather than going the GUI route, then went over the various clients, with brief examples.&lt;/p&gt;

&lt;p&gt;We (rOpenSci) have been working on the R client &lt;a href=&quot;https://github.com/ropensci/rcrossref&quot;&gt;rcrossref&lt;/a&gt; for a while now, but I’m also working on the Python and Ruby clients for Crossref. In addition, the Ruby client has a CLI client inside. The Javascript client is worked on independently by &lt;a href=&quot;https://science.ai/&quot;&gt;ScienceAI&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The R, Ruby, and Python clients are useable but not feature complete yet, and would benefit from lots of users surfacing bugs and highlighting nice to have features.&lt;/p&gt;

&lt;p&gt;The main Crossref API used in all the clients is documented at &lt;a href=&quot;https://github.com/CrossRef/rest-api-doc/blob/master/rest_api.md&quot;&gt;api.crossref.org&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I’ve tried to make the APIs similar-ish across clients. Functions in each client match the main Crossref search API (api.crossref.org) routes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;/works&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;/members&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;/funders&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;/journals&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;/types&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;/licenses&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Other methods in all three clients:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Get DOI minting agency
    &lt;ul&gt;
      &lt;li&gt;Uses api.crossref.org API&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Get random DOIs
    &lt;ul&gt;
      &lt;li&gt;Uses api.crossref.org API&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Content negotiation
    &lt;ul&gt;
      &lt;li&gt;Documented at &lt;a href=&quot;http://www.crosscite.org/cn&quot;&gt;http://www.crosscite.org/cn&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Get full text
    &lt;ul&gt;
      &lt;li&gt;other clients in each language will focus on this use case&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Get citation count
    &lt;ul&gt;
      &lt;li&gt;Uses service at &lt;a href=&quot;http://www.crossref.org/openurl&quot;&gt;http://www.crossref.org/openurl&lt;/a&gt; - though this functionality may be in the api.crossref.org API at some point&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The following shows how to install, and then examples from each client for a few use cases.&lt;/p&gt;

&lt;h2 id=&quot;installation&quot;&gt;Installation&lt;/h2&gt;

&lt;h3 id=&quot;python&quot;&gt;Python&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;pip install habanero
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;ruby&quot;&gt;Ruby&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;gem install serrano
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;r&quot;&gt;R&lt;/h3&gt;

&lt;p&gt;Inside R:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-R&quot;&gt;install.packages(&quot;rcrossref&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;javascript&quot;&gt;Javascript&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;npm install crossref
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I won’t do any examples with the js library, as I don’t maintain it.&lt;/p&gt;

&lt;h2 id=&quot;use-case-get-orcid-ids-for-authors&quot;&gt;Use case: get ORCID IDs for authors&lt;/h2&gt;

&lt;p&gt;Python&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from habanero import Crossref
cr = Crossref()
res = cr.works(filter = {&#39;has_orcid&#39;: True}, limit = 10)
res2 = [ [ z.get(&#39;ORCID&#39;) for z in x[&#39;author&#39;] ] for x in res.result[&#39;message&#39;][&#39;items&#39;] ]
filter(None, reduce(lambda x, y: x+y, res2))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;[u&#39;http://orcid.org/0000-0003-4087-8021&#39;,
 u&#39;http://orcid.org/0000-0002-2076-5452&#39;,
 u&#39;http://orcid.org/0000-0003-4087-8021&#39;,
 u&#39;http://orcid.org/0000-0002-2076-5452&#39;,
 u&#39;http://orcid.org/0000-0003-1710-1580&#39;,
 u&#39;http://orcid.org/0000-0003-1710-1580&#39;,
 u&#39;http://orcid.org/0000-0003-4637-238X&#39;,
 u&#39;http://orcid.org/0000-0003-4637-238X&#39;,
 u&#39;http://orcid.org/0000-0003-4637-238X&#39;,
 u&#39;http://orcid.org/0000-0003-4637-238X&#39;,
 u&#39;http://orcid.org/0000-0003-4637-238X&#39;,
 u&#39;http://orcid.org/0000-0003-2510-4271&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ruby&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-ruby&quot;&gt;require &#39;serrano&#39;
res = Serrano.works(filter: {&#39;has_orcid&#39;: true}, limit: 10)
res2 = res[&#39;message&#39;][&#39;items&#39;].collect { |x| x[&#39;author&#39;].collect { |z| z[&#39;ORCID&#39;] } }
res2.flatten.compact
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-ruby&quot;&gt;=&amp;gt; [&quot;http://orcid.org/0000-0003-4087-8021&quot;,
 &quot;http://orcid.org/0000-0002-2076-5452&quot;,
 &quot;http://orcid.org/0000-0003-4087-8021&quot;,
 &quot;http://orcid.org/0000-0002-2076-5452&quot;,
 &quot;http://orcid.org/0000-0003-1710-1580&quot;,
 &quot;http://orcid.org/0000-0003-1710-1580&quot;,
 &quot;http://orcid.org/0000-0003-4637-238X&quot;,
 &quot;http://orcid.org/0000-0003-4637-238X&quot;,
 &quot;http://orcid.org/0000-0003-4637-238X&quot;,
 &quot;http://orcid.org/0000-0003-4637-238X&quot;,
 &quot;http://orcid.org/0000-0003-4637-238X&quot;,
 &quot;http://orcid.org/0000-0003-2510-4271&quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;R&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-R&quot;&gt;library(&quot;rcrossref&quot;)
res &amp;lt;- cr_works(filter=c(has_orcid=TRUE), limit = 10)
orcids &amp;lt;- unlist(lapply(res$data$author, function(z) z$ORCID))
Filter(function(x) !is.na(x), orcids)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-R&quot;&gt; [1] &quot;http://orcid.org/0000-0003-4087-8021&quot;
 [2] &quot;http://orcid.org/0000-0002-2076-5452&quot;
 [3] &quot;http://orcid.org/0000-0003-4087-8021&quot;
 [4] &quot;http://orcid.org/0000-0002-2076-5452&quot;
 [5] &quot;http://orcid.org/0000-0003-1710-1580&quot;
 [6] &quot;http://orcid.org/0000-0003-1710-1580&quot;
 [7] &quot;http://orcid.org/0000-0003-4637-238X&quot;
 [8] &quot;http://orcid.org/0000-0003-4637-238X&quot;
 [9] &quot;http://orcid.org/0000-0003-4637-238X&quot;
[10] &quot;http://orcid.org/0000-0003-4637-238X&quot;
[11] &quot;http://orcid.org/0000-0003-4637-238X&quot;
[12] &quot;http://orcid.org/0000-0003-2510-4271&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CLI&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;serrano works --filter=has_orcid:true --json --limit=12 | jq &#39;.message.items[].author[].ORCID | select(. != null)&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;&quot;http://orcid.org/0000-0003-4087-8021&quot;
&quot;http://orcid.org/0000-0002-2076-5452&quot;
&quot;http://orcid.org/0000-0003-4087-8021&quot;
&quot;http://orcid.org/0000-0002-2076-5452&quot;
&quot;http://orcid.org/0000-0003-1710-1580&quot;
&quot;http://orcid.org/0000-0003-1710-1580&quot;
&quot;http://orcid.org/0000-0003-4637-238X&quot;
&quot;http://orcid.org/0000-0003-4637-238X&quot;
&quot;http://orcid.org/0000-0003-4637-238X&quot;
&quot;http://orcid.org/0000-0003-4637-238X&quot;
&quot;http://orcid.org/0000-0003-4637-238X&quot;
&quot;http://orcid.org/0000-0003-2510-4271&quot;
&quot;http://orcid.org/0000-0001-9408-8207&quot;
&quot;http://orcid.org/0000-0002-2076-5452&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;use-case-content-negotation&quot;&gt;Use case: content negotation&lt;/h2&gt;

&lt;p&gt;Python&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from habanero import cn
cn.content_negotiation(ids = &#39;10.1126/science.169.3946.635&#39;, format = &quot;text&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;u&#39;Frank, H. S. (1970). The Structure of Ordinary Water: New data and interpretations are yielding new insights into this fascinating substance. Science, 169(3946), 635\xe2\x80\x93641. doi:10.1126/science.169.3946.635\n&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ruby&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-ruby&quot;&gt;require &#39;serrano&#39;
Serrano.content_negotiation(ids: &#39;10.1126/science.169.3946.635&#39;, format: &quot;text&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-ruby&quot;&gt;=&amp;gt; [&quot;Frank, H. S. (1970). The Structure of Ordinary Water: New data and interpretations are yielding new insights into this fascinating substance. Science, 169(3946), 635\xE2\x80\x93641. doi:10.1126/science.169.3946.635\n&quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;R&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(&quot;rcrossref&quot;)
cr_cn(dois=&quot;10.1126/science.169.3946.635&quot;, &quot;text&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;[1] &quot;Frank, H. S. (1970). The Structure of Ordinary Water: New data and interpretations are yielding new insights into this fascinating substance. Science, 169(3946), 635–641. doi:10.1126/science.169.3946.635&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CLI&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;serrano contneg 10.1890/13-0590.1 --format=text
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;Murtaugh, P. A. (2014).  In defense of P values . Ecology, 95(3), 611–617. doi:10.1890/13-0590.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;more&quot;&gt;More&lt;/h2&gt;

&lt;p&gt;There are definitely issues with data in the Crossref search API, some of which I cover in my talks. However, it is still the best place to go for scholarly metadata.&lt;/p&gt;

&lt;p&gt;Let us know of other use cases - there are others not covered here for brevity sake.&lt;/p&gt;

&lt;p&gt;There are lots of examples in the docs for each client. If you can think of any doc improvements file an issue.&lt;/p&gt;

&lt;p&gt;If you find any bugs, please do file an issue.&lt;/p&gt;

</description>
				<published>2015-11-30 00:00:00 -0800</published>
				<link>http://recology.info//2015/11/crossref-clients/</link>
			</item>
		
			<item>
				<title>pygbif - GBIF client for Python</title>
				<description>&lt;p&gt;I maintain an R client for the GBIF API, at &lt;a href=&quot;https://github.com/ropensci/rgbif&quot;&gt;rgbif&lt;/a&gt;. Been working on it for a few years, and recently been thinking that there should be a nice low level client for Python as well. I didn’t see one searching Github, etc. so I started working on one recently: &lt;a href=&quot;https://github.com/sckott/pygbif&quot;&gt;pygbif&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It’s up on &lt;a href=&quot;https://pypi.python.org/pypi/pygbif/0.1.1&quot;&gt;pypi&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;There’s not much in &lt;code&gt;pygbif&lt;/code&gt; yet - I wanted to get something up to start getting some users to more quickly make the library useful to people.&lt;/p&gt;

&lt;p&gt;There’s three modules, with a few methods each:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;species
    &lt;ul&gt;
      &lt;li&gt;&lt;code&gt;name_backbone()&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;name_suggest()&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;registry
    &lt;ul&gt;
      &lt;li&gt;&lt;code&gt;nodes()&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;dataset_metrics()&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;datasets()&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;occurrences
    &lt;ul&gt;
      &lt;li&gt;&lt;code&gt;search()&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;get()&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;get_verbatim()&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;get_fragment()&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;count()&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;count_basisofrecord()&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;count_year()&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;count_datasets()&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;count_countries()&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;count_publishingcountries()&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code&gt;count_schema()&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Here’s a quick intro (&lt;a href=&quot;https://github.com/sckott/pygbif/blob/master/demos/pygbif-intro.ipynb&quot;&gt;in a Jupyter notebook&lt;/a&gt;):&lt;/p&gt;

&lt;h3 id=&quot;install&quot;&gt;Install&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;pip install pygbif
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;registrydatasets&quot;&gt;Registry/datasets&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from pygbif import registry
registry.dataset_metrics(uuid=&#39;3f8a1297-3259-4700-91fc-acc4170b27ce&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;{u&#39;colCoveragePct&#39;: 79,
 u&#39;colMatchingCount&#39;: 24335,
 u&#39;countByConstituent&#39;: {},
 u&#39;countByIssue&#39;: {u&#39;BACKBONE_MATCH_FUZZY&#39;: 573,
  u&#39;BACKBONE_MATCH_NONE&#39;: 1306,
  u&#39;VERNACULAR_NAME_INVALID&#39;: 7777},
 u&#39;countByKingdom&#39;: {u&#39;ANIMALIA&#39;: 30,
  u&#39;FUNGI&#39;: 3,
  u&#39;INCERTAE_SEDIS&#39;: 26,
  u&#39;PLANTAE&#39;: 10997,
  u&#39;PROTOZOA&#39;: 1},
 ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;taxonomic-names&quot;&gt;Taxonomic names&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from pygbif import species
species.name_suggest(q=&#39;Puma concolor&#39;, limit = 1)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;{&#39;data&#39;: [{u&#39;canonicalName&#39;: u&#39;Puma concolor&#39;,
   u&#39;class&#39;: u&#39;Mammalia&#39;,
   u&#39;classKey&#39;: 359,
   u&#39;family&#39;: u&#39;Felidae&#39;,
   u&#39;familyKey&#39;: 9703,
   u&#39;genus&#39;: u&#39;Puma&#39;,
   u&#39;genusKey&#39;: 2435098,
   u&#39;key&#39;: 2435099,
   u&#39;kingdom&#39;: u&#39;Animalia&#39;,
   u&#39;kingdomKey&#39;: 1,
   u&#39;nubKey&#39;: 2435099,
   u&#39;order&#39;: u&#39;Carnivora&#39;,
   u&#39;orderKey&#39;: 732,
   u&#39;parent&#39;: u&#39;Puma&#39;,
   u&#39;parentKey&#39;: 2435098,
   u&#39;phylum&#39;: u&#39;Chordata&#39;,
   u&#39;phylumKey&#39;: 44,
   u&#39;rank&#39;: u&#39;SPECIES&#39;,
   u&#39;species&#39;: u&#39;Puma concolor&#39;,
   u&#39;speciesKey&#39;: 2435099}],
 &#39;hierarchy&#39;: [{u&#39;1&#39;: u&#39;Animalia&#39;,
   u&#39;2435098&#39;: u&#39;Puma&#39;,
   u&#39;359&#39;: u&#39;Mammalia&#39;,
   u&#39;44&#39;: u&#39;Chordata&#39;,
   u&#39;732&#39;: u&#39;Carnivora&#39;,
   u&#39;9703&#39;: u&#39;Felidae&#39;}]}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;occurrence-data&quot;&gt;Occurrence data&lt;/h3&gt;

&lt;p&gt;Search&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;from pygbif import occurrences
res = occurrences.search(taxonKey = 3329049, limit = 10)
[ x[&#39;phylum&#39;] for x in res[&#39;results&#39;] ]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;[u&#39;Basidiomycota&#39;,
 u&#39;Basidiomycota&#39;,
 u&#39;Basidiomycota&#39;,
 u&#39;Basidiomycota&#39;,
 u&#39;Basidiomycota&#39;,
 u&#39;Basidiomycota&#39;,
 u&#39;Basidiomycota&#39;,
 u&#39;Basidiomycota&#39;,
 u&#39;Basidiomycota&#39;,
 u&#39;Basidiomycota&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Fetch specific occurrences&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;occurrences.get(key = 252408386)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;{u&#39;basisOfRecord&#39;: u&#39;OBSERVATION&#39;,
 u&#39;catalogNumber&#39;: u&#39;70875196&#39;,
 u&#39;collectionCode&#39;: u&#39;7472&#39;,
 u&#39;continent&#39;: u&#39;EUROPE&#39;,
 u&#39;country&#39;: u&#39;United Kingdom&#39;,
 u&#39;countryCode&#39;: u&#39;GB&#39;,
 u&#39;datasetKey&#39;: u&#39;26a49731-9457-45b2-9105-1b96063deb26&#39;,
 u&#39;day&#39;: 30,
...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Occurrence counts API&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;occurrences.count(isGeoreferenced = True)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;500283031
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;feedback&quot;&gt;feedback&lt;/h3&gt;

&lt;p&gt;Would love any feedback…&lt;/p&gt;

</description>
				<published>2015-11-12 00:00:00 -0800</published>
				<link>http://recology.info//2015/11/pygbif/</link>
			</item>
		
			<item>
				<title>noaa - Integrated Surface Database data</title>
				<description>&lt;p&gt;I’ve recently made some improvements to the functions that work with ISD 
(Integrated Surface Database) data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;isd data&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;code&gt;isd()&lt;/code&gt; function now caches more intelligently. We now cache using 
&lt;code&gt;.rds&lt;/code&gt; files via &lt;code&gt;saveRDS&lt;/code&gt;/&lt;code&gt;readRDS&lt;/code&gt;, whereas we used to use &lt;code&gt;.csv&lt;/code&gt; files, 
which take up much more disk space, and we have to worry about not changing 
data formats on reading data back into an R session. This has the downside
that you can’t just go directly to open up a cached file in your favorite 
spreadsheet viewer, but you can do that manually after reading in to R.&lt;/li&gt;
  &lt;li&gt;In addition, &lt;code&gt;isd()&lt;/code&gt; now has a function &lt;code&gt;cleanup&lt;/code&gt;, if &lt;code&gt;TRUE&lt;/code&gt; after 
downloading the data file from NOAA’s ftp server and processing, we delete 
the file. That’s fine since we have the cached processed file. But you 
can choose not to cleanup the original data files.&lt;/li&gt;
  &lt;li&gt;Data processing in &lt;code&gt;isd()&lt;/code&gt; is improved as well. We convert key variables
to appropriate classes to be more useful.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;isd stations&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In &lt;code&gt;isd_stations()&lt;/code&gt;, there’s now a cached version of the station data in 
the package, or you can get optionally get fresh station data from NOAA’s 
FTP server.&lt;/li&gt;
  &lt;li&gt;There’s a new function &lt;code&gt;isd_stations_search()&lt;/code&gt; that uses the station data
to allow you to search for stations via either:
    &lt;ul&gt;
      &lt;li&gt;A bounding box&lt;/li&gt;
      &lt;li&gt;Radius froma point&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;install&quot;&gt;Install&lt;/h2&gt;

&lt;p&gt;For examples below, you’ll need the development version:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;devtools::install_github(&quot;ropensci/rnoaa&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Load &lt;code&gt;rnoaa&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(&quot;rnoaa&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;isd-stations&quot;&gt;ISD stations&lt;/h2&gt;

&lt;h3 id=&quot;get-stations&quot;&gt;Get stations&lt;/h3&gt;

&lt;p&gt;There’s a cached version of the station data in the package, or you can get fresh
station data from NOAA’s FTP server.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;stations &amp;lt;- isd_stations()
head(stations)
#&amp;gt;   usaf  wban station_name ctry state icao lat lon elev_m    begin      end
#&amp;gt; 1 7005 99999   CWOS 07005                  NA  NA     NA 20120127 20120127
#&amp;gt; 2 7011 99999   CWOS 07011                  NA  NA     NA 20111025 20121129
#&amp;gt; 3 7018 99999   WXPOD 7018                   0   0   7018 20110309 20130730
#&amp;gt; 4 7025 99999   CWOS 07025                  NA  NA     NA 20120127 20120127
#&amp;gt; 5 7026 99999   WXPOD 7026   AF              0   0   7026 20120713 20141120
#&amp;gt; 6 7034 99999   CWOS 07034                  NA  NA     NA 20121024 20121106
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;filter-and-visualize-stations&quot;&gt;Filter and visualize stations&lt;/h3&gt;

&lt;p&gt;In addition to getting the entire station data.frame, you can also search for stations,
either with a bounding box or within a radius from a point. First, the bounding box&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;bbox &amp;lt;- c(-125.0, 38.4, -121.8, 40.9)
out &amp;lt;- isd_stations_search(bbox = bbox)
head(out)
#&amp;gt;     usaf  wban                          station_name ctry state icao
#&amp;gt; 1 720193 99999 LONNIE POOL FLD / WEAVERVILLE AIRPORT   US    CA KO54
#&amp;gt; 2 724834 99999                        POINT CABRILLO   US    CA     
#&amp;gt; 3 724953 99999                              RIO NIDO   US    CA     
#&amp;gt; 4 724957 23213                 SONOMA COUNTY AIRPORT   US    CA KSTS
#&amp;gt; 5 724957 99999                  C M SCHULZ SONOMA CO   US    CA KSTS
#&amp;gt; 6 724970 99999                  CHICO CALIFORNIA MAP   US    CA  CIC
#&amp;gt;   elev_m    begin      end      lon    lat
#&amp;gt; 1  716.0 20101030 20150831 -122.922 40.747
#&amp;gt; 2   20.0 19810906 19871007 -123.820 39.350
#&amp;gt; 3 -999.0 19891111 19900303 -122.917 38.517
#&amp;gt; 4   34.8 20000101 20150831 -122.810 38.504
#&amp;gt; 5   38.0 19430404 19991231 -122.817 38.517
#&amp;gt; 6   69.0 19420506 19760305 -121.850 39.783
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Where is the bounding box? (you’ll need &lt;a href=&quot;https://cran.rstudio.com/web/packages/lawn/&quot;&gt;lawn&lt;/a&gt;, or you can vizualize some other way)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(&quot;lawn&quot;)
lawn::lawn_bbox_polygon(bbox) %&amp;gt;% view
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/2015-10-21-noaa-isd/bbox_area.png&quot; alt=&quot;plot1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Vizualize station subset - yep, looks right&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(&quot;leaflet&quot;)
leaflet(data = out) %&amp;gt;%
  addTiles() %&amp;gt;%
  addCircles()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/2015-10-21-noaa-isd/bbox_result.png&quot; alt=&quot;plot1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Next, search with a lat/lon coordinate, with a radius. That is, we search for stations
within X km from the coordinate.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;out &amp;lt;- isd_stations_search(lat = 38.4, lon = -123, radius = 250)
head(out)
#&amp;gt;     usaf  wban             station_name ctry state icao elev_m    begin
#&amp;gt; 1 690070 93217            FRITZSCHE AAF   US    CA KOAR   43.0 19600404
#&amp;gt; 2 720267 23224 AUBURN MUNICIPAL AIRPORT   US    CA KAUN  466.7 20060101
#&amp;gt; 3 720267 99999         AUBURN MUNICIPAL   US    CA KAUN  468.0 20040525
#&amp;gt; 4 720406 99999      GNOSS FIELD AIRPORT   US    CA KDVO    0.6 20071114
#&amp;gt; 5 720576   174       UNIVERSITY AIRPORT   US    CA KEDU   21.0 20130101
#&amp;gt; 6 720576 99999                    DAVIS   US    CA KEDU   21.0 20080721
#&amp;gt;        end      lon    lat
#&amp;gt; 1 19930831 -121.767 36.683
#&amp;gt; 2 20150831 -121.082 38.955
#&amp;gt; 3 20051231 -121.082 38.955
#&amp;gt; 4 20150831 -122.550 38.150
#&amp;gt; 5 20150831 -121.783 38.533
#&amp;gt; 6 20121231 -121.783 38.533
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Again, compare search area to stations found&lt;/p&gt;

&lt;p&gt;&lt;em&gt;search area&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;pt &amp;lt;- lawn::lawn_point(c(-123, 38.4))
lawn::lawn_buffer(pt, dist = 250) %&amp;gt;% view
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/2015-10-21-noaa-isd/circle_radius.png&quot; alt=&quot;plot1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;stations found&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;leaflet(data = out) %&amp;gt;%
  addTiles() %&amp;gt;%
  addCircles()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/2015-10-21-noaa-isd/lastplot.png&quot; alt=&quot;plot1&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;isd-data&quot;&gt;ISD data&lt;/h2&gt;

&lt;h3 id=&quot;get-isd-data&quot;&gt;Get ISD data&lt;/h3&gt;

&lt;p&gt;Here, I get data for four stations.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;res1 &amp;lt;- isd(usaf=&quot;011690&quot;, wban=&quot;99999&quot;, year=1993)
res2 &amp;lt;- isd(usaf=&quot;172007&quot;, wban=&quot;99999&quot;, year=2015)
res3 &amp;lt;- isd(usaf=&quot;702700&quot;, wban=&quot;00489&quot;, year=2015)
res4 &amp;lt;- isd(usaf=&quot;109711&quot;, wban=99999, year=1970)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then, combine data, with &lt;code&gt;rnoaa:::rbind.isd()&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;res_all &amp;lt;- rbind(res1, res2, res3, res4)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Add date time&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(&quot;lubridate&quot;)
res_all$date_time &amp;lt;- ymd_hm(
  sprintf(&quot;%s %s&quot;, as.character(res_all$date), res_all$time)
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Remove 999’s (NOAA’s way to indicate missing/no data)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(&quot;dplyr&quot;)
res_all &amp;lt;- res_all %&amp;gt;% filter(temperature &amp;lt; 900)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;visualize-isd-data&quot;&gt;Visualize ISD data&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(&quot;ggplot2&quot;)
ggplot(res_all, aes(date_time, temperature)) +
  geom_line() + 
  facet_wrap(~usaf_station, scales = &quot;free_x&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/2015-10-21-noaa-isd/unnamed-chunk-12-1.png&quot; alt=&quot;img&quot; /&gt;&lt;/p&gt;
</description>
				<published>2015-10-21 00:00:00 -0700</published>
				<link>http://recology.info//2015/10/noaa-isd/</link>
			</item>
		
			<item>
				<title>Metrics for open source projects</title>
				<description>&lt;p&gt;Measuring use of open source software isn’t always straightforward. The problem is especially acute for software targeted largely at academia, where usage is not measured just by software downloads, but also by citations.&lt;/p&gt;

&lt;p&gt;Citations are a well-known pain point because the citation graph is privately held by iron doors (e.g., &lt;a href=&quot;http://www.scopus.com/&quot;&gt;Scopus&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/&quot;&gt;Google Scholar&lt;/a&gt;). New ventures aim to open up citation data, but of course it’s an immense amount of work, and so does not come quickly.&lt;/p&gt;

&lt;p&gt;The following is a laundry list of metrics on software of which I am aware, and some of which I use in our &lt;a href=&quot;http://ropensci.github.io/biweekly/&quot;&gt;rOpenSci twice monthly updates&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I primarily develop software for the R language, so some of the metrics are specific to R, but many are not. In addition, we (rOpenSci) don’t develop web apps, which may bring in an additional set of metrics not covered below.&lt;/p&gt;

&lt;p&gt;I organize by source instead of type of data because some sources give multiple kinds of data - I note what kinds of data they give with &lt;span class=&quot;label label-default&quot;&gt;labels&lt;/span&gt;.&lt;/p&gt;

&lt;h2 id=&quot;cran-downloads&quot;&gt;CRAN downloads&lt;/h2&gt;

&lt;p&gt;&lt;span class=&quot;label label-warning&quot;&gt;downloads&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Link: &lt;a href=&quot;https://github.com/metacran/cranlogs.app&quot;&gt;https://github.com/metacran/cranlogs.app&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;This is a REST API for CRAN downloads from the RStudio CRAN CDN. Note however, that the RStudio CDN is only one of many - there are other mirrors users can insall packages from, and are not included in this count. However, a significant portion of downloads probably come from the RStudio CDN.&lt;/li&gt;
  &lt;li&gt;Other programming languages have similar support, e.g., &lt;a href=&quot;http://guides.rubygems.org/rubygems-org-api/&quot;&gt;Ruby&lt;/a&gt; and &lt;a href=&quot;https://github.com/npm/download-counts&quot;&gt;Node&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lagotto&quot;&gt;Lagotto&lt;/h2&gt;

&lt;p&gt;&lt;small&gt;&lt;span class=&quot;label label-success&quot;&gt;citations&lt;/span&gt; &lt;span class=&quot;label label-info&quot;&gt;github&lt;/span&gt; &lt;span class=&quot;label label-primary&quot;&gt;social-media&lt;/span&gt;&lt;/small&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Link: &lt;a href=&quot;http://software.lagotto.io/works&quot;&gt;http://software.lagotto.io/works&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Lagotto is a Rails application, developed by &lt;a href=&quot;https://github.com/mfenner&quot;&gt;Martin Fenner&lt;/a&gt;, originally designed to collect and provide article level metrics for scientific publications at Public Library of Science. It is now used by many publishers, and there are installations of Lagotto targeting &lt;a href=&quot;http://mdc.lagotto.io/&quot;&gt;datasets&lt;/a&gt; and &lt;a href=&quot;http://software.lagotto.io/works&quot;&gt;software&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Discussion forum: &lt;a href=&quot;http://discuss.lagotto.io/&quot;&gt;http://discuss.lagotto.io/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;depsy&quot;&gt;Depsy&lt;/h2&gt;

&lt;p&gt;&lt;small&gt;&lt;span class=&quot;label label-success&quot;&gt;citations&lt;/span&gt; &lt;span class=&quot;label label-info&quot;&gt;github&lt;/span&gt;&lt;/small&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Link: &lt;a href=&quot;http://depsy.org&quot;&gt;http://depsy.org&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;This is a nascent venture by the &lt;a href=&quot;https://impactstory.org/about&quot;&gt;ImpactStory team&lt;/a&gt; that seeks to uncover the impact of research software. As far as I can tell, they’ll collect usage via software downloads and citations in the literature.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;web-site-analytics&quot;&gt;Web Site Analytics&lt;/h2&gt;

&lt;p&gt;&lt;small&gt;&lt;span class=&quot;label label-danger&quot;&gt;page-views&lt;/span&gt;&lt;/small&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If you happen to have a website for your project, collecting analytics is a way to gauge views of the landing page, and any help/tutorial pages you may have. A good easy way to do this is a deploy a basic site on your &lt;code&gt;gh-pages&lt;/code&gt; branch of your GitHub repo, and use the easily integrated Google Analytics.&lt;/li&gt;
  &lt;li&gt;Whatever analytics you use, in my experience this mostly brings up links from google searches and blog posts that may mention your project&lt;/li&gt;
  &lt;li&gt;Google Analytics beacon (for README views): &lt;a href=&quot;https://github.com/igrigorik/ga-beacon&quot;&gt;https://github.com/igrigorik/ga-beacon&lt;/a&gt;. I haven’t tried this yet, but seems promising.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;auomated-tracking-ssnmp&quot;&gt;Auomated tracking: SSNMP&lt;/h2&gt;

&lt;p&gt;&lt;small&gt;&lt;span class=&quot;label label-success&quot;&gt;citations&lt;/span&gt; &lt;span class=&quot;label label-info&quot;&gt;github&lt;/span&gt;&lt;/small&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Link: &lt;a href=&quot;http://scisoft-net-map.isri.cmu.edu&quot;&gt;http://scisoft-net-map.isri.cmu.edu&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Scientific Software Network Map Project&lt;/li&gt;
  &lt;li&gt;This is a cool NSF funded project by Chris Bogart that tracks software usage via GitHub and citations in literature.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;google-scholar&quot;&gt;Google Scholar&lt;/h2&gt;

&lt;p&gt;&lt;small&gt;&lt;span class=&quot;label label-success&quot;&gt;citations&lt;/span&gt;&lt;/small&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Link: &lt;a href=&quot;https://scholar.google.com/&quot;&gt;https://scholar.google.com/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Searching Google Scholar for software citations manually is fine at a small scale, but at a larger scale scraping is best. However, you’re not legally supposed to do this, and Google will shut you down.&lt;/li&gt;
  &lt;li&gt;Could try using g-scholar alerts as well, especially if new citations of your work are infrequent.&lt;/li&gt;
  &lt;li&gt;If you have institutional access to Scopus/Web of Science, you could search those, but I don’t push this as an option since it’s available to so few.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;github&quot;&gt;GitHub&lt;/h2&gt;

&lt;p&gt;&lt;small&gt;&lt;span class=&quot;label label-info&quot;&gt;github&lt;/span&gt;&lt;/small&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Links: &lt;a href=&quot;https://developer.github.com/v3/&quot;&gt;https://developer.github.com/v3/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;I keep a list of rOpenSci uses found in GitHub repos at &lt;a href=&quot;https://discuss.ropensci.org/t/use-of-some-ropensci-packages-on-github/137&quot;&gt;https://discuss.ropensci.org/t/use-of-some-ropensci-packages-on-github/137&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;GitHub does collect traffic data on each repo (clones, downloads, page views), but they are not exposed in the API. I’ve bugged them a bit about this - hopefully we’ll be able to get that dat in their API soon.&lt;/li&gt;
  &lt;li&gt;Bitbucket/Gitlab - don’t use them, but I assume they also provide some metrics via their APIs&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;other&quot;&gt;Other&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Support forums: Whether you use UserVoice, Discourse, Google Groups, Gitter, etc., depending on your viewpoint, these interactions could be counted as metrics of software usage.&lt;/li&gt;
  &lt;li&gt;Emails: I personally get a lot of emails asking for help with software I maintain. I imagine this is true for most software developers. Counting these could be another metric of software usage, although I never have counted mine.&lt;/li&gt;
  &lt;li&gt;Social media: See Lagotto above, which tracks some social media outlets.&lt;/li&gt;
  &lt;li&gt;Code coverage: There are many options now for code coverage, integrated with each Travis-CI build. A good option is &lt;a href=&quot;https://codecov.io&quot;&gt;CodeCov&lt;/a&gt;. CodeCov gives percentage test coverage, which one could use as one measure of code quality.&lt;/li&gt;
  &lt;li&gt;Reviews: There isn’t a lot of code review going on that I’m aware of. Even if there was, I suppose this would just be a logical TRUE/FALSE.&lt;/li&gt;
  &lt;li&gt;Cash money y’all: Grants/consulting income/etc. could be counted as a metric.&lt;/li&gt;
  &lt;li&gt;Users: If you require users to create an account or similar before getting your software, you have a sense of number of users and perhaps their demographics.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;promising&quot;&gt;Promising&lt;/h2&gt;

&lt;p&gt;Some software metrics things on the horizon that look interesting:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://geodynamics.org/cig/projects/saga/&quot;&gt;Software Attribution for Geoscience Applications&lt;/a&gt; (SAGA)&lt;/li&gt;
  &lt;li&gt;Crossref: They have &lt;a href=&quot;https://github.com/CrossRef/rest-api-doc/blob/master/rest_api.md&quot;&gt;a very nice API&lt;/a&gt;, but they don’t yet provide citation counts - but &lt;a href=&quot;https://github.com/CrossRef/rest-api-doc/issues/46&quot;&gt;they may soon&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/njsmith/sempervirens&quot;&gt;njsmith/sempervirens&lt;/a&gt; - a prototype for &lt;em&gt;gathering anonymous, opt-in usage data for open scientific software&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/force11/force11-scwg&quot;&gt;Force11 Software Citation Working Group&lt;/a&gt; - &lt;em&gt;…produce a consolidated set of citation principles in order to encourage broad adoption of a consistent policy for software citation across disciplines and venues&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;missed&quot;&gt;Missed?&lt;/h2&gt;

&lt;p&gt;I’m sure I missed things. Let me know.&lt;/p&gt;

</description>
				<published>2015-10-19 00:00:00 -0700</published>
				<link>http://recology.info//2015/10/open-source-metrics/</link>
			</item>
		
			<item>
				<title>analogsea - an R client for the Digital Ocean API</title>
				<description>&lt;p&gt;&lt;code&gt;analogsea&lt;/code&gt; is now on CRAN. We started developing the pkg back in &lt;a href=&quot;https://github.com/sckott/analogsea/commit/b129164dd87969d2fc6bcf3b51576fe1da932fdb&quot;&gt;May 2014&lt;/a&gt;, but just 
now getting the first version on CRAN. It’s a collaboration with &lt;a href=&quot;http://had.co.nz/&quot;&gt;Hadley&lt;/a&gt; and &lt;a href=&quot;https://github.com/wch/&quot;&gt;Winston Chang&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Most of &lt;code&gt;analogsea&lt;/code&gt; package is for interacting with the &lt;a href=&quot;https://developers.digitalocean.com/documentation/v2/&quot;&gt;Digital Ocean API&lt;/a&gt;, including:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Manage domains&lt;/li&gt;
  &lt;li&gt;Manage ssh keys&lt;/li&gt;
  &lt;li&gt;Get actions&lt;/li&gt;
  &lt;li&gt;Manage images&lt;/li&gt;
  &lt;li&gt;Manage droplets (servers)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A number of convenience functions are included for doing tasks (e.g., resizing 
a droplet) that aren’t supported by Digital Ocean’s API out of the box (i.e., 
there’s no API route for it).&lt;/p&gt;

&lt;p&gt;In addition to wrapping their API routes, we provide other functionality, e.g.:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;execute shell commands on a droplet (server)&lt;/li&gt;
  &lt;li&gt;execute R commands on a droplet&lt;/li&gt;
  &lt;li&gt;install R&lt;/li&gt;
  &lt;li&gt;install RStudio server&lt;/li&gt;
  &lt;li&gt;install Shiny server&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Other functionality we’re working on, not yet available:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;install OpenCPU&lt;/li&gt;
  &lt;li&gt;use &lt;code&gt;packrat&lt;/code&gt; to move projects from local to server, and vice versa&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;See also: two previous blog posts on this package &lt;a href=&quot;http://recology.info/2014/05/analogsea/&quot;&gt;http://recology.info/2014/05/analogsea/&lt;/a&gt; and &lt;a href=&quot;http://recology.info/2014/06/analogsea-v01/&quot;&gt;http://recology.info/2014/06/analogsea-v01/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;install&quot;&gt;Install&lt;/h2&gt;

&lt;p&gt;Binaries are not yet on CRAN, but you can install from source.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;# install.packages(&quot;analogsea&quot;) # when binaries available
install.packages(&quot;analogsea&quot;, repos = &quot;https://cran.r-project.org&quot;, type = &quot;source&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or install development version from GitHub&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;devtools::install_github(&quot;sckott/analogsea&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Load &lt;code&gt;analogsea&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(&quot;analogsea&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;etc&quot;&gt;Etc.&lt;/h2&gt;

&lt;p&gt;As this post is mostly to announce that this pkg is on CRAN now, I won’t go through examples, but instead point you to the package &lt;a href=&quot;https://github.com/sckott/analogsea/blob/master/README.md&quot;&gt;README&lt;/a&gt; and &lt;a href=&quot;https://github.com/sckott/analogsea/blob/master/vignettes/doapi.Rmd&quot;&gt;vignette&lt;/a&gt; in which we cover 
creating a Digital Ocean account, authenticating, and have many examples.&lt;/p&gt;

&lt;h2 id=&quot;feedback&quot;&gt;Feedback&lt;/h2&gt;

&lt;p&gt;Let us know what you think. We’d love to hear about any problems, use cases, feature requests.&lt;/p&gt;

</description>
				<published>2015-10-02 00:00:00 -0700</published>
				<link>http://recology.info//2015/10/analogsea-cran/</link>
			</item>
		
			<item>
				<title>oai - an OAI-PMH client</title>
				<description>&lt;p&gt;&lt;code&gt;oai&lt;/code&gt; is a general purpose client to work with any ‘OAI-PMH’ service. The ‘OAI-PMH’ protocol is described at &lt;a href=&quot;http://www.openarchives.org/OAI/openarchivesprotocol.html&quot;&gt;http://www.openarchives.org/OAI/openarchivesprotocol.html&lt;/a&gt;. The main functions follow the OAI-PMH verbs:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;GetRecord&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;Identify&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;ListIdentifiers&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;ListMetadataFormats&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;ListRecords&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;ListSets&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The repo is at &lt;a href=&quot;https://github.com/sckott/oai&quot;&gt;https://github.com/sckott/oai&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I will be using this in a number of packages I maintain that use OAI-PMH data services. If you try it, let me know what you think.&lt;/p&gt;

&lt;p&gt;This package is heading to rOpenSci soon: &lt;a href=&quot;https://github.com/ropensci/onboarding/issues/19&quot;&gt;https://github.com/ropensci/onboarding/issues/19&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Here’s a few usage examples:&lt;/p&gt;

&lt;h2 id=&quot;install&quot;&gt;Install&lt;/h2&gt;

&lt;p&gt;Is on CRAN now, but binaries may not be available yet.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;install.packages(&quot;oai&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or install development version from GitHub&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;devtools::install_github(&quot;sckott/oai&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Load &lt;code&gt;oai&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(&quot;oai&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;identify&quot;&gt;Identify&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;id(&quot;http://oai.datacite.org/oai&quot;)
#&amp;gt;   repositoryName                     baseURL protocolVersion
#&amp;gt; 1   DataCite MDS http://oai.datacite.org/oai             2.0
#&amp;gt;           adminEmail    earliestDatestamp deletedRecord
#&amp;gt; 1 admin@datacite.org 2011-01-01T00:00:00Z    persistent
#&amp;gt;            granularity compression compression.1
#&amp;gt; 1 YYYY-MM-DDThh:mm:ssZ        gzip       deflate
#&amp;gt;                                      description
#&amp;gt; 1 oaioai.datacite.org:oai:oai.datacite.org:12425
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;listidentifiers&quot;&gt;ListIdentifiers&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;list_identifiers(from = &#39;2011-05-01T&#39;, until = &#39;2011-09-01T&#39;)
#&amp;gt; &amp;lt;ListRecords&amp;gt; 925 X 6 
#&amp;gt; 
#&amp;gt;                    identifier            datestamp setSpec setSpec.1
#&amp;gt; 1  oai:oai.datacite.org:32153 2011-06-08T08:57:11Z     TIB  TIB.WDCC
#&amp;gt; 2  oai:oai.datacite.org:32200 2011-06-20T08:12:41Z     TIB TIB.DAGST
#&amp;gt; 3  oai:oai.datacite.org:32220 2011-06-28T14:11:08Z     TIB TIB.DAGST
#&amp;gt; 4  oai:oai.datacite.org:32241 2011-06-30T13:24:45Z     TIB TIB.DAGST
#&amp;gt; 5  oai:oai.datacite.org:32255 2011-07-01T12:09:24Z     TIB TIB.DAGST
#&amp;gt; 6  oai:oai.datacite.org:32282 2011-07-05T09:08:10Z     TIB TIB.DAGST
#&amp;gt; 7  oai:oai.datacite.org:32309 2011-07-06T12:30:54Z     TIB TIB.DAGST
#&amp;gt; 8  oai:oai.datacite.org:32310 2011-07-06T12:42:32Z     TIB TIB.DAGST
#&amp;gt; 9  oai:oai.datacite.org:32325 2011-07-07T11:17:46Z     TIB TIB.DAGST
#&amp;gt; 10 oai:oai.datacite.org:32326 2011-07-07T11:18:47Z     TIB TIB.DAGST
#&amp;gt; ..                        ...                  ...     ...       ...
#&amp;gt; Variables not shown: setSpec.2 (chr), setSpec.3 (chr)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;count-identifiers&quot;&gt;Count Identifiers&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;count_identifiers()
#&amp;gt;                           url   count
#&amp;gt; 1 http://oai.datacite.org/oai 6350706
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;listrecords&quot;&gt;ListRecords&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;list_records(from = &#39;2011-05-01T&#39;, until = &#39;2011-08-15T&#39;)
#&amp;gt; &amp;lt;ListRecords&amp;gt; 126 X 46 
#&amp;gt; 
#&amp;gt;                    identifier            datestamp setSpec setSpec.1
#&amp;gt; 1  oai:oai.datacite.org:32153 2011-06-08T08:57:11Z     TIB  TIB.WDCC
#&amp;gt; 2  oai:oai.datacite.org:32200 2011-06-20T08:12:41Z     TIB TIB.DAGST
#&amp;gt; 3  oai:oai.datacite.org:32220 2011-06-28T14:11:08Z     TIB TIB.DAGST
#&amp;gt; 4  oai:oai.datacite.org:32241 2011-06-30T13:24:45Z     TIB TIB.DAGST
#&amp;gt; 5  oai:oai.datacite.org:32255 2011-07-01T12:09:24Z     TIB TIB.DAGST
#&amp;gt; 6  oai:oai.datacite.org:32282 2011-07-05T09:08:10Z     TIB TIB.DAGST
#&amp;gt; 7  oai:oai.datacite.org:32309 2011-07-06T12:30:54Z     TIB TIB.DAGST
#&amp;gt; 8  oai:oai.datacite.org:32310 2011-07-06T12:42:32Z     TIB TIB.DAGST
#&amp;gt; 9  oai:oai.datacite.org:32325 2011-07-07T11:17:46Z     TIB TIB.DAGST
#&amp;gt; 10 oai:oai.datacite.org:32326 2011-07-07T11:18:47Z     TIB TIB.DAGST
#&amp;gt; ..                        ...                  ...     ...       ...
#&amp;gt; Variables not shown: title (chr), creator (chr), creator.1 (chr),
#&amp;gt;      creator.2 (chr), creator.3 (chr), creator.4 (chr), creator.5 (chr),
#&amp;gt;      creator.6 (chr), creator.7 (chr), publisher (chr), date (chr),
#&amp;gt;      identifier.2 (chr), identifier.1 (chr), subject (chr), description
#&amp;gt;      (chr), description.1 (chr), contributor (chr), language (chr), type
#&amp;gt;      (chr), type.1 (chr), format (chr), format.1 (chr), rights (chr),
#&amp;gt;      subject.1 (chr), relation (chr), subject.2 (chr), subject.3 (chr),
#&amp;gt;      subject.4 (chr), setSpec.2 (chr), setSpec.3 (chr), format.2 (chr),
#&amp;gt;      subject.5 (chr), subject.6 (chr), subject.7 (chr), description.2
#&amp;gt;      (chr), description.3 (chr), description.4 (chr), description.5 (chr),
#&amp;gt;      title.1 (chr), relation.1 (chr), relation.2 (chr), contributor.1
#&amp;gt;      (chr)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;getrecords&quot;&gt;GetRecords&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;get_records(c(&quot;oai:oai.datacite.org:32255&quot;, &quot;oai:oai.datacite.org:32325&quot;))
#&amp;gt; &amp;lt;GetRecord&amp;gt; 2 X 23 
#&amp;gt; 
#&amp;gt;                   identifier            datestamp setSpec setSpec.1
#&amp;gt; 1 oai:oai.datacite.org:32255 2011-07-01T12:09:24Z     TIB TIB.DAGST
#&amp;gt; 2 oai:oai.datacite.org:32325 2011-07-07T11:17:46Z     TIB TIB.DAGST
#&amp;gt; Variables not shown: title (chr), creator (chr), creator.1 (chr),
#&amp;gt;      creator.2 (chr), creator.3 (chr), publisher (chr), date (chr),
#&amp;gt;      identifier.1 (chr), subject (chr), subject.1 (chr), description
#&amp;gt;      (chr), description.1 (chr), contributor (chr), language (chr), type
#&amp;gt;      (chr), type.1 (chr), format (chr), format.1 (chr), rights (chr)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;list-metadataformats&quot;&gt;List MetadataFormats&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;list_metadataformats(id = &quot;oai:oai.datacite.org:32348&quot;)
#&amp;gt; $`oai:oai.datacite.org:32348`
#&amp;gt;   metadataPrefix
#&amp;gt; 1         oai_dc
#&amp;gt; 2       datacite
#&amp;gt; 3   oai_datacite
#&amp;gt;                                                        schema
#&amp;gt; 1              http://www.openarchives.org/OAI/2.0/oai_dc.xsd
#&amp;gt; 2 http://schema.datacite.org/meta/nonexistant/nonexistant.xsd
#&amp;gt; 3              http://schema.datacite.org/oai/oai-1.0/oai.xsd
#&amp;gt;                             metadataNamespace
#&amp;gt; 1 http://www.openarchives.org/OAI/2.0/oai_dc/
#&amp;gt; 2      http://datacite.org/schema/nonexistant
#&amp;gt; 3     http://schema.datacite.org/oai/oai-1.0/
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;list-sets&quot;&gt;List Sets&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;list_sets(&quot;http://oai.datacite.org/oai&quot;)
#&amp;gt; &amp;lt;ListSets&amp;gt; 1227 X 2 
#&amp;gt; 
#&amp;gt;                     setSpec
#&amp;gt; 1                REFQUALITY
#&amp;gt; 2                      ANDS
#&amp;gt; 3           ANDS.REFQUALITY
#&amp;gt; 4             ANDS.CENTRE-1
#&amp;gt; 5  ANDS.CENTRE-1.REFQUALITY
#&amp;gt; 6             ANDS.CENTRE-2
#&amp;gt; 7  ANDS.CENTRE-2.REFQUALITY
#&amp;gt; 8             ANDS.CENTRE-3
#&amp;gt; 9  ANDS.CENTRE-3.REFQUALITY
#&amp;gt; 10            ANDS.CENTRE-5
#&amp;gt; ..                      ...
#&amp;gt; Variables not shown: setName (chr)
&lt;/code&gt;&lt;/pre&gt;
</description>
				<published>2015-09-11 00:00:00 -0700</published>
				<link>http://recology.info//2015/09/oai-client/</link>
			</item>
		
			<item>
				<title>fulltext - a package to help you mine text</title>
				<description>&lt;p&gt;Finally, we got &lt;code&gt;fulltext&lt;/code&gt; up on CRAN - our first commit was &lt;a href=&quot;https://github.com/ropensci/fulltext/commit/2d4f7e270040b2c8914853113073fc4d3134445e&quot;&gt;May last year&lt;/a&gt;. &lt;code&gt;fulltext&lt;/code&gt; is a package to facilitate text mining. It focuses on open access journals. This package makes it easier to search for articles, download those articles in full text if available, convert pdf format to plain text, and extract text chunks for vizualization/analysis. We are planning to add bits for analysis in future versions. We’ve been working on this package for a while now. It has a lot of moving parts and package dependencies, so it took a while to get a first useable version.&lt;/p&gt;

&lt;p&gt;The tasks facilitated by &lt;code&gt;fulltext&lt;/code&gt; in bullet form:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Search - search for articles&lt;/li&gt;
  &lt;li&gt;Retrieve - get full text&lt;/li&gt;
  &lt;li&gt;Convert - convert from format X to Y&lt;/li&gt;
  &lt;li&gt;Text - if needed, get text from pdfs/etc.&lt;/li&gt;
  &lt;li&gt;Extract - pull out the bits of articles that you want&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I won’t be surprised if users uncover a lot of bugs in this package given the huge number of publishers/journals users want to get literature data from, and the surely wide diversity of use cases. But I thought it was important to get out a first version to get feedback on the user interface, and gather use cases.&lt;/p&gt;

&lt;p&gt;We hope that this package can help bring text-mining to the masses - making it easy for anyone to do do, not just text-mining experts.&lt;/p&gt;

&lt;p&gt;If you have any feedback, please do get in touch in the issue tracker for &lt;code&gt;fulltext&lt;/code&gt; at https://github.com/ropensci/fulltext/issues - If you have use case thoughts, the &lt;a href=&quot;https://discuss.ropensci.org/&quot;&gt;rOpenSci discussion forum&lt;/a&gt; might be a good place to go.&lt;/p&gt;

&lt;p&gt;Let’s kick the tires, shall we?&lt;/p&gt;

&lt;h2 id=&quot;install&quot;&gt;Install&lt;/h2&gt;

&lt;p&gt;Will be on CRAN soon, not as of AM PDT on 2015-08-07.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;install.packages(&quot;fulltext&quot;)
# if binaries not avail. yet on your favorite CRAN mirror
install.packages(&quot;https://cran.rstudio.com/src/contrib/fulltext_0.1.0.tar.gz&quot;, repos = NULL, type = &quot;source&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or install development version from GitHub&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;devtools::install_github(&quot;ropensci/fulltext&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Load &lt;code&gt;fulltext&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(&quot;fulltext&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;search-for-articles&quot;&gt;Search for articles&lt;/h2&gt;

&lt;p&gt;Currently, there are hooks for searching for articles from PLOS, BMC, Crossref, Entrez, arXiv, and BioRxiv. We’ll add more in the future, but that does cover a lot of articles, especially given inclusion of Crossref (which mints most DOIs) and Entrez (which houses PMC and Pubmed).&lt;/p&gt;

&lt;p&gt;An example: Search for the term &lt;em&gt;ecology&lt;/em&gt; in PLOS journals.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;(res1 &amp;lt;- ft_search(query = &#39;ecology&#39;, from = &#39;plos&#39;))
#&amp;gt; Query:
#&amp;gt;   [ecology] 
#&amp;gt; Found:
#&amp;gt;   [PLoS: 28589; BMC: 0; Crossref: 0; Entrez: 0; arxiv: 0; biorxiv: 0] 
#&amp;gt; Returned:
#&amp;gt;   [PLoS: 10; BMC: 0; Crossref: 0; Entrez: 0; arxiv: 0; biorxiv: 0]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each publisher/search-engine has a slot with metadata and data, saying how many articles were found and how many were returned. We can dig into what PLOS gave us:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;res1$plos
#&amp;gt; Query: [ecology] 
#&amp;gt; Records found, returned: [28589, 10] 
#&amp;gt; License: [CC-BY] 
#&amp;gt;                                                         id
#&amp;gt; 1                             10.1371/journal.pone.0059813
#&amp;gt; 2                             10.1371/journal.pone.0001248
#&amp;gt; 3  10.1371/annotation/69333ae7-757a-4651-831c-f28c5eb02120
#&amp;gt; 4                             10.1371/journal.pone.0080763
#&amp;gt; 5                             10.1371/journal.pone.0102437
#&amp;gt; 6                             10.1371/journal.pone.0017342
#&amp;gt; 7                             10.1371/journal.pone.0091497
#&amp;gt; 8                             10.1371/journal.pone.0092931
#&amp;gt; 9  10.1371/annotation/28ac6052-4f87-4b88-a817-0cd5743e83d6
#&amp;gt; 10                            10.1371/journal.pcbi.1003594
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For each of the data sources to search on you can pass in additional options (basically, you can use the query parameters in the functions that hit each service). Here, we can modify our search to PLOS by requesting a particular set of fields with the &lt;code&gt;fl&lt;/code&gt; parameter (PLOS uses a Solr backed search engine, and &lt;code&gt;fl&lt;/code&gt; is short for &lt;code&gt;fields&lt;/code&gt; in Solr land):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;ft_search(query = &#39;ecology&#39;, from = &#39;plos&#39;, plosopts = list(
   fl = c(&#39;id&#39;,&#39;author&#39;,&#39;eissn&#39;,&#39;journal&#39;,&#39;counter_total_all&#39;,&#39;alm_twitterCount&#39;)))
#&amp;gt; Query:
#&amp;gt;   [ecology] 
#&amp;gt; Found:
#&amp;gt;   [PLoS: 28589; BMC: 0; Crossref: 0; Entrez: 0; arxiv: 0; biorxiv: 0] 
#&amp;gt; Returned:
#&amp;gt;   [PLoS: 10; BMC: 0; Crossref: 0; Entrez: 0; arxiv: 0; biorxiv: 0]
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note that PLOS is a bit unique in allowing you to request specific parts of articles. Other sources in ft_search() don’t let you do that.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;get-full-text&quot;&gt;Get full text&lt;/h2&gt;

&lt;p&gt;After you’ve found the set of articles you want to get full text for, we can use the results from &lt;code&gt;ft_search()&lt;/code&gt; to grab full text. &lt;code&gt;ft_get()&lt;/code&gt; accepts a character vector of list of DOIs (or PMC IDs if fetching from Entrez), or the output of &lt;code&gt;ft_search()&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;(out &amp;lt;- ft_get(res1))
#&amp;gt; [Docs] 8 
#&amp;gt; [Source] R session  
#&amp;gt; [IDs] 10.1371/journal.pone.0059813 10.1371/journal.pone.0001248
#&amp;gt;      10.1371/journal.pone.0080763 10.1371/journal.pone.0102437
#&amp;gt;      10.1371/journal.pone.0017342 10.1371/journal.pone.0091497
#&amp;gt;      10.1371/journal.pone.0092931 10.1371/journal.pcbi.1003594 ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We got eight articles in full text in the result. We didn’t get 10, even though 10 were returned from &lt;code&gt;ft_search()&lt;/code&gt; because PLOS often returns records for annotations, that is, comments on articles, which we auto-seive out within &lt;code&gt;ft_get()&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Dig in to the PLOS data&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;out$plos
#&amp;gt; $found
#&amp;gt; [1] 8
#&amp;gt; 
#&amp;gt; $dois
#&amp;gt; [1] &quot;10.1371/journal.pone.0059813&quot; &quot;10.1371/journal.pone.0001248&quot;
#&amp;gt; [3] &quot;10.1371/journal.pone.0080763&quot; &quot;10.1371/journal.pone.0102437&quot;
#&amp;gt; [5] &quot;10.1371/journal.pone.0017342&quot; &quot;10.1371/journal.pone.0091497&quot;
#&amp;gt; [7] &quot;10.1371/journal.pone.0092931&quot; &quot;10.1371/journal.pcbi.1003594&quot;
#&amp;gt; 
#&amp;gt; $data
#&amp;gt; $data$backend
#&amp;gt; NULL
#&amp;gt; 
#&amp;gt; $data$path
#&amp;gt; [1] &quot;session&quot;
#&amp;gt; 
#&amp;gt; $data$data
#&amp;gt; 8 full-text articles retrieved 
#&amp;gt; Min. Length: 3828 - Max. Length: 104702 
#&amp;gt; DOIs: 10.1371/journal.pone.0059813 10.1371/journal.pone.0001248
#&amp;gt;   10.1371/journal.pone.0080763 10.1371/journal.pone.0102437
#&amp;gt;   10.1371/journal.pone.0017342 10.1371/journal.pone.0091497
#&amp;gt;   10.1371/journal.pone.0092931 10.1371/journal.pcbi.1003594 ... 
#&amp;gt; 
#&amp;gt; NOTE: extract xml strings like output[&#39;&amp;lt;doi&amp;gt;&#39;]
#&amp;gt; 
#&amp;gt; $opts
#&amp;gt; $opts$doi
#&amp;gt; [1] &quot;10.1371/journal.pone.0059813&quot; &quot;10.1371/journal.pone.0001248&quot;
#&amp;gt; [3] &quot;10.1371/journal.pone.0080763&quot; &quot;10.1371/journal.pone.0102437&quot;
#&amp;gt; [5] &quot;10.1371/journal.pone.0017342&quot; &quot;10.1371/journal.pone.0091497&quot;
#&amp;gt; [7] &quot;10.1371/journal.pone.0092931&quot; &quot;10.1371/journal.pcbi.1003594&quot;
#&amp;gt; 
#&amp;gt; $opts$callopts
#&amp;gt; list()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dig in further to get to one of the articles in XML format&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(&quot;xml2&quot;)
xml2::read_xml(out$plos$data$data$`10.1371/journal.pone.0059813`)
#&amp;gt; {xml_document}
#&amp;gt; &amp;lt;article&amp;gt;
#&amp;gt; [1] &amp;lt;front&amp;gt;\n&amp;lt;journal-meta&amp;gt;\n&amp;lt;journal-id journal-id-type=&quot;nlm-ta&quot;&amp;gt;PLoS O ...
#&amp;gt; [2] &amp;lt;body&amp;gt;\n  &amp;lt;sec id=&quot;s1&quot;&amp;gt;\n&amp;lt;title&amp;gt;Introduction&amp;lt;/title&amp;gt;\n&amp;lt;p&amp;gt;Ecologists  ...
#&amp;gt; [3] &amp;lt;back&amp;gt;\n&amp;lt;ack&amp;gt;\n&amp;lt;p&amp;gt;Curtis Flather, Mark Burgman, Leon Blaustein, Yaac ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now with the xml, you can dig into whatever you like, e.g., using &lt;code&gt;xml2&lt;/code&gt; or &lt;code&gt;rvest&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;extract-text-from-pdfs&quot;&gt;Extract text from pdfs&lt;/h2&gt;

&lt;p&gt;Ideally for text mining you have access to XML or other text based formats. However, sometimes you only have access to PDFs. In this case you want to extract text from PDFs. &lt;code&gt;fulltext&lt;/code&gt; can help with that.&lt;/p&gt;

&lt;p&gt;You can extract from any pdf from a file path, like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;path &amp;lt;- system.file(&quot;examples&quot;, &quot;example1.pdf&quot;, package = &quot;fulltext&quot;)
ft_extract(path)
#&amp;gt; &amp;lt;document&amp;gt;/Library/Frameworks/R.framework/Versions/3.2/Resources/library/fulltext/examples/example1.pdf
#&amp;gt;   Pages: 18
#&amp;gt;   Title: Suffering and mental health among older people living in nursing homes---a mixed-methods study
#&amp;gt;   Producer: pdfTeX-1.40.10
#&amp;gt;   Creation date: 2015-07-17
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let’s search for articles from arXiv, a preprint service. Here, get pdf from an article with ID &lt;code&gt;cond-mat/9309029&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;res &amp;lt;- ft_get(&#39;cond-mat/9309029&#39;, from = &quot;arxiv&quot;)
res2 &amp;lt;- ft_extract(res)
res2$arxiv$data
#&amp;gt; $backend
#&amp;gt; NULL
#&amp;gt; 
#&amp;gt; $path
#&amp;gt; $path$`cond-mat/9309029`
#&amp;gt; [1] &quot;~/.fulltext/cond-mat_9309029.pdf&quot;
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $data
#&amp;gt; $data[[1]]
#&amp;gt; &amp;lt;document&amp;gt;/Users/sacmac/.fulltext/cond-mat_9309029.pdf
#&amp;gt;   Pages: 14
#&amp;gt;   Title: arXiv:cond-mat/9309029v8  26 Jan 1994
#&amp;gt;   Producer: GPL Ghostscript SVN PRE-RELEASE 8.62
#&amp;gt;   Creation date: 2008-02-06
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And a short snippet of the full text&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;res2$arxiv$data$data[[1]]$data
#&amp;gt; &quot;arXiv:cond-mat/9309029v8 26 Jan 1994, , FERMILAB-PUB-93/15-T March 1993, Revised:
#&amp;gt; January 1994, The Thermodynamics and Economics of Waste, Dallas C. Kennedy, Research
#&amp;gt; Associate, Fermi National Accelerator Laboratory, P.O. Box 500 MS106, Batavia, Illinois
#&amp;gt; 60510 USA, Abstract, The increasingly relevant problem of natural resource use and
#&amp;gt; waste production, disposal, and reuse is examined from several viewpoints: economic,
#&amp;gt; technical, and thermodynamic. Alternative economies are studied, with emphasis on
#&amp;gt; recycling of waste to close the natural resource cycle. The physical nature of human
#&amp;gt; economies and constraints on recycling and energy efficiency are stated in terms
#&amp;gt; ...&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;extract-text-chunks&quot;&gt;Extract text chunks&lt;/h2&gt;

&lt;p&gt;We have a few functions to help you pull out certain parts of an article. For example, perhaps you want to get just the authors from your articles, or just the abstracts.&lt;/p&gt;

&lt;p&gt;Here, we’ll search for some PLOS articles, then get their full text, then extract various parts of each article with &lt;code&gt;chunks()&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;res &amp;lt;- ft_search(query = &quot;ecology&quot;, from = &quot;plos&quot;)
(x &amp;lt;- ft_get(res))
#&amp;gt; [Docs] 8 
#&amp;gt; [Source] R session  
#&amp;gt; [IDs] 10.1371/journal.pone.0059813 10.1371/journal.pone.0001248
#&amp;gt;      10.1371/journal.pone.0080763 10.1371/journal.pone.0102437
#&amp;gt;      10.1371/journal.pone.0017342 10.1371/journal.pone.0091497
#&amp;gt;      10.1371/journal.pone.0092931 10.1371/journal.pcbi.1003594 ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Extract DOIs&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;x %&amp;gt;% chunks(&quot;doi&quot;)
#&amp;gt; $plos
#&amp;gt; $plos$`10.1371/journal.pone.0059813`
#&amp;gt; $plos$`10.1371/journal.pone.0059813`$doi
#&amp;gt; [1] &quot;10.1371/journal.pone.0059813&quot;
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pone.0001248`
#&amp;gt; $plos$`10.1371/journal.pone.0001248`$doi
#&amp;gt; [1] &quot;10.1371/journal.pone.0001248&quot;
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pone.0080763`
#&amp;gt; $plos$`10.1371/journal.pone.0080763`$doi
#&amp;gt; [1] &quot;10.1371/journal.pone.0080763&quot;
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pone.0102437`
#&amp;gt; $plos$`10.1371/journal.pone.0102437`$doi
#&amp;gt; [1] &quot;10.1371/journal.pone.0102437&quot;
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pone.0017342`
#&amp;gt; $plos$`10.1371/journal.pone.0017342`$doi
#&amp;gt; [1] &quot;10.1371/journal.pone.0017342&quot;
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pone.0091497`
#&amp;gt; $plos$`10.1371/journal.pone.0091497`$doi
#&amp;gt; [1] &quot;10.1371/journal.pone.0091497&quot;
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pone.0092931`
#&amp;gt; $plos$`10.1371/journal.pone.0092931`$doi
#&amp;gt; [1] &quot;10.1371/journal.pone.0092931&quot;
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pcbi.1003594`
#&amp;gt; $plos$`10.1371/journal.pcbi.1003594`$doi
#&amp;gt; [1] &quot;10.1371/journal.pcbi.1003594&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Extract DOIs and categories&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;x %&amp;gt;% chunks(c(&quot;doi&quot;,&quot;categories&quot;))
#&amp;gt; $plos
#&amp;gt; $plos$`10.1371/journal.pone.0059813`
#&amp;gt; $plos$`10.1371/journal.pone.0059813`$doi
#&amp;gt; [1] &quot;10.1371/journal.pone.0059813&quot;
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pone.0059813`$categories
#&amp;gt;  [1] &quot;Research Article&quot;                 &quot;Biology&quot;                         
#&amp;gt;  [3] &quot;Ecology&quot;                          &quot;Community ecology&quot;               
#&amp;gt;  [5] &quot;Species interactions&quot;             &quot;Science policy&quot;                  
#&amp;gt;  [7] &quot;Research assessment&quot;              &quot;Research monitoring&quot;             
#&amp;gt;  [9] &quot;Research funding&quot;                 &quot;Government funding of science&quot;   
#&amp;gt; [11] &quot;Research laboratories&quot;            &quot;Science policy and economics&quot;    
#&amp;gt; [13] &quot;Science and technology workforce&quot; &quot;Careers in research&quot;             
#&amp;gt; [15] &quot;Social and behavioral sciences&quot;   &quot;Sociology&quot;                       
#&amp;gt; [17] &quot;Sociology of knowledge&quot;          
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pone.0001248`
#&amp;gt; $plos$`10.1371/journal.pone.0001248`$doi
#&amp;gt; [1] &quot;10.1371/journal.pone.0001248&quot;
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pone.0001248`$categories
#&amp;gt; [1] &quot;Research Article&quot;             &quot;Ecology&quot;                     
#&amp;gt; [3] &quot;Ecology/Ecosystem Ecology&quot;    &quot;Ecology/Evolutionary Ecology&quot;
#&amp;gt; [5] &quot;Ecology/Theoretical Ecology&quot; 
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pone.0080763`
#&amp;gt; $plos$`10.1371/journal.pone.0080763`$doi
#&amp;gt; [1] &quot;10.1371/journal.pone.0080763&quot;
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pone.0080763`$categories
#&amp;gt;  [1] &quot;Research Article&quot;     &quot;Biology&quot;              &quot;Ecology&quot;             
#&amp;gt;  [4] &quot;Autecology&quot;           &quot;Behavioral ecology&quot;   &quot;Community ecology&quot;   
#&amp;gt;  [7] &quot;Evolutionary ecology&quot; &quot;Population ecology&quot;   &quot;Evolutionary biology&quot;
#&amp;gt; [10] &quot;Behavioral ecology&quot;   &quot;Evolutionary ecology&quot; &quot;Population biology&quot;  
#&amp;gt; [13] &quot;Population ecology&quot;  
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pone.0102437`
#&amp;gt; $plos$`10.1371/journal.pone.0102437`$doi
#&amp;gt; [1] &quot;10.1371/journal.pone.0102437&quot;
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pone.0102437`$categories
#&amp;gt;  [1] &quot;Research Article&quot;                  
#&amp;gt;  [2] &quot;Biology and life sciences&quot;         
#&amp;gt;  [3] &quot;Biogeography&quot;                      
#&amp;gt;  [4] &quot;Ecology&quot;                           
#&amp;gt;  [5] &quot;Ecosystems&quot;                        
#&amp;gt;  [6] &quot;Ecosystem engineering&quot;             
#&amp;gt;  [7] &quot;Ecosystem functioning&quot;             
#&amp;gt;  [8] &quot;Industrial ecology&quot;                
#&amp;gt;  [9] &quot;Spatial and landscape ecology&quot;     
#&amp;gt; [10] &quot;Urban ecology&quot;                     
#&amp;gt; [11] &quot;Computer and information sciences&quot; 
#&amp;gt; [12] &quot;Geoinformatics&quot;                    
#&amp;gt; [13] &quot;Spatial analysis&quot;                  
#&amp;gt; [14] &quot;Earth sciences&quot;                    
#&amp;gt; [15] &quot;Geography&quot;                         
#&amp;gt; [16] &quot;Human geography&quot;                   
#&amp;gt; [17] &quot;Cultural geography&quot;                
#&amp;gt; [18] &quot;Social geography&quot;                  
#&amp;gt; [19] &quot;Ecology and environmental sciences&quot;
#&amp;gt; [20] &quot;Conservation science&quot;              
#&amp;gt; [21] &quot;Environmental protection&quot;          
#&amp;gt; [22] &quot;Nature-society interactions&quot;       
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pone.0017342`
#&amp;gt; $plos$`10.1371/journal.pone.0017342`$doi
#&amp;gt; [1] &quot;10.1371/journal.pone.0017342&quot;
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pone.0017342`$categories
#&amp;gt;  [1] &quot;Research Article&quot;     &quot;Biology&quot;              &quot;Ecology&quot;             
#&amp;gt;  [4] &quot;Community ecology&quot;    &quot;Community assembly&quot;   &quot;Community structure&quot; 
#&amp;gt;  [7] &quot;Niche construction&quot;   &quot;Ecological metrics&quot;   &quot;Species diversity&quot;   
#&amp;gt; [10] &quot;Species richness&quot;     &quot;Biodiversity&quot;         &quot;Biogeography&quot;        
#&amp;gt; [13] &quot;Population ecology&quot;   &quot;Mathematics&quot;          &quot;Statistics&quot;          
#&amp;gt; [16] &quot;Biostatistics&quot;        &quot;Statistical theories&quot; &quot;Ecology&quot;             
#&amp;gt; [19] &quot;Mathematics&quot;         
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pone.0091497`
#&amp;gt; $plos$`10.1371/journal.pone.0091497`$doi
#&amp;gt; [1] &quot;10.1371/journal.pone.0091497&quot;
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pone.0091497`$categories
#&amp;gt; [1] &quot;Correction&quot;
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pone.0092931`
#&amp;gt; $plos$`10.1371/journal.pone.0092931`$doi
#&amp;gt; [1] &quot;10.1371/journal.pone.0092931&quot;
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pone.0092931`$categories
#&amp;gt; [1] &quot;Correction&quot;
#&amp;gt; 
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pcbi.1003594`
#&amp;gt; $plos$`10.1371/journal.pcbi.1003594`$doi
#&amp;gt; [1] &quot;10.1371/journal.pcbi.1003594&quot;
#&amp;gt; 
#&amp;gt; $plos$`10.1371/journal.pcbi.1003594`$categories
#&amp;gt; [1] &quot;Research Article&quot;          &quot;Biology and life sciences&quot;
#&amp;gt; [3] &quot;Computational biology&quot;     &quot;Microbiology&quot;             
#&amp;gt; [5] &quot;Theoretical biology&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;tabularize&lt;/code&gt; attempts to help you put the data that comes out of &lt;code&gt;chunks()&lt;/code&gt; in to a &lt;code&gt;data.frame&lt;/code&gt;, that we all know and love.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;x %&amp;gt;% chunks(c(&quot;doi&quot;, &quot;history&quot;)) %&amp;gt;% tabularize()
#&amp;gt; $plos
#&amp;gt;                            doi history.received history.accepted
#&amp;gt; 1 10.1371/journal.pone.0059813       2012-09-16       2013-02-19
#&amp;gt; 2 10.1371/journal.pone.0001248       2007-07-02       2007-11-06
#&amp;gt; 3 10.1371/journal.pone.0080763       2013-08-15       2013-10-16
#&amp;gt; 4 10.1371/journal.pone.0102437       2013-11-27       2014-06-19
#&amp;gt; 5 10.1371/journal.pone.0017342       2010-08-24       2011-01-31
#&amp;gt; 6 10.1371/journal.pone.0091497             &amp;lt;NA&amp;gt;             &amp;lt;NA&amp;gt;
#&amp;gt; 7 10.1371/journal.pone.0092931             &amp;lt;NA&amp;gt;             &amp;lt;NA&amp;gt;
#&amp;gt; 8 10.1371/journal.pcbi.1003594       2014-01-09       2014-03-14
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;bring-it-all-together&quot;&gt;Bring it all together&lt;/h2&gt;

&lt;p&gt;With the pieces above, let’s see what it looks like all in one go. Here, we’ll search for articles on &lt;em&gt;climate change&lt;/em&gt;, then visualize word usage in those articles.&lt;/p&gt;

&lt;h3 id=&quot;search&quot;&gt;Search&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;(out &amp;lt;- ft_search(query = &#39;climate change&#39;, from = &#39;plos&#39;, limit = 100))
#&amp;gt; Query:
#&amp;gt;   [climate change] 
#&amp;gt; Found:
#&amp;gt;   [PLoS: 11737; BMC: 0; Crossref: 0; Entrez: 0; arxiv: 0; biorxiv: 0] 
#&amp;gt; Returned:
#&amp;gt;   [PLoS: 100; BMC: 0; Crossref: 0; Entrez: 0; arxiv: 0; biorxiv: 0]
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;get-full-text-1&quot;&gt;Get full text&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;(texts &amp;lt;- ft_get(out))
#&amp;gt; [Docs] 99 
#&amp;gt; [Source] R session  
#&amp;gt; [IDs] 10.1371/journal.pone.0054839 10.1371/journal.pone.0045683
#&amp;gt;      10.1371/journal.pone.0050182 10.1371/journal.pone.0118489
#&amp;gt;      10.1371/journal.pone.0053646 10.1371/journal.pone.0015103
#&amp;gt;      10.1371/journal.pone.0008320 10.1371/journal.pmed.1001227
#&amp;gt;      10.1371/journal.pmed.1001374 10.1371/journal.pone.0097480 ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Because PLOS returns XML, we don’t need to do a PDF extraction step. However, if we got full text from arXiv or bioRxiv, we’d need to extract from PDFs first.&lt;/p&gt;

&lt;h3 id=&quot;pull-out-chunks&quot;&gt;Pull out chunks&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;abs &amp;lt;- texts %&amp;gt;% chunks(&quot;abstract&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let’s pull out just the text&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;abs &amp;lt;- lapply(abs$plos, function(z) {
  paste0(z$abstract, collapse = &quot; &quot;)
})
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;analyze&quot;&gt;Analyze&lt;/h3&gt;

&lt;p&gt;Using the &lt;code&gt;tm&lt;/code&gt; package, we can analyze our articles&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(&quot;tm&quot;)
corp &amp;lt;- VCorpus(VectorSource(abs))
# remove stop words, strip whitespace, remove punctuation
corp &amp;lt;- tm_map(corp, removeWords, stopwords(&quot;english&quot;))
corp &amp;lt;- tm_map(corp, stripWhitespace)
corp &amp;lt;- tm_map(corp, removePunctuation)
# Make a term document matrix
tdm &amp;lt;- TermDocumentMatrix(corp)
# remove sparse terms
tdm &amp;lt;- removeSparseTerms(tdm, sparse = 0.8)
# get data
rs &amp;lt;- rowSums(as.matrix(tdm))
df &amp;lt;- data.frame(word = names(rs), n = unname(rs), stringsAsFactors = FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;visualize&quot;&gt;Visualize&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&quot;language-r&quot;&gt;library(&quot;ggplot2&quot;)
ggplot(df, aes(reorder(word, n), n)) +
  geom_point() +
  coord_flip() +
  labs(y = &quot;Count&quot;, x = &quot;Word&quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/2015-08-07-full-text/unnamed-chunk-23-1.png&quot; alt=&quot;plot of chunk unnamed-chunk-23&quot; /&gt;&lt;/p&gt;
</description>
				<published>2015-08-07 00:00:00 -0700</published>
				<link>http://recology.info//2015/08/full-text/</link>
			</item>
		
	</channel>
</rss>
