<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  <link href="http://gmpg.org/xfn/11" rel="profile">

  <title>
    fulltext - a package to help you mine text &middot; 
    Recology, R/etc.
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Open+Sans:300,400italic,400,600,700|Abril+Fatface">

  <link rel="stylesheet" href="/public/css/bootstrap/css/bootstrap.css">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/favicon.ico">
  <link rel="shortcut icon" href="/public/favicon.ico">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.css" rel="stylesheet">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body class="theme-base-0f layout-reverse">

    <header class="masthead">
      <div class="masthead-inner">
        <h1>Recology</h1>
        <!-- <h1> <a href="http://recology.info/">Recology</a></h1> -->
        <p class="lead">R/etc.</p>

        <div class="colophon">
          <ul class="colophon-links">
            <li>
              <a href="/"><i class="fa fa-home fa-lg"></i></a>&nbsp;
              <a href="/about"><i class="fa fa-info-circle fa-lg"></i></a>&nbsp;
              <a href="/archives"><i class="fa fa-archive fa-lg"></i></a>&nbsp;
              <a href="/rresources"><i class="fa fa-book fa-lg"></i></a>&nbsp;
              <a href="http://rforcats.net/" rel><i class="fa fa-graduation-cap fa-lg"></i></a>&nbsp;
              <a href="/feed.xml"><i class="fa fa-rss fa-lg"></i></a>&nbsp;
              <a href="https://twitter.com/sckottie"><i class="fa fa-twitter fa-lg"></i></a>&nbsp;
              <a href="/fork"><i class="fa fa-spinner fa-lg"></i></a>
            </li>
          </ul>
          <!-- <small><a href="https://github.com/mdo/hyde">Hyde</a> from <a href="https://twitter.com/mdo" target="_blank">@mdo</a>.</small> -->
        </div>
      </div>
    </header>

    <div class="content container">
      <div class="post">
  <h1>fulltext - a package to help you mine text</h1><a style="float:right;" href="/archives"><i class="fa fa-archive fa-lg"></i></a>&nbsp;<a style="float:right;" href="/tags"><i class="fa fa-tags fa-lg"></i></a>
  <span class="post-date">07 Aug 2015</span>
  <i class="fa fa-tags fa-large"></i>&nbsp;
     <a href="/tags/literature" class="badge" rel="tooltip" data-placement="bottom" title="View posts tagged with &quot;literature&quot;"><span class="blog_tag">literature</span></a>   <a href="/tags/text-mining" class="badge" rel="tooltip" data-placement="bottom" title="View posts tagged with &quot;text-mining&quot;"><span class="blog_tag">text-mining</span></a>   <a href="/tags/R" class="badge" rel="tooltip" data-placement="bottom" title="View posts tagged with &quot;R&quot;"><span class="blog_tag">R</span></a>   <br>
  <!-- <i class="fa fa-code fa-large"></i>&nbsp;Source: <a href="https://github.com/sckott/sckott.github.com/tree/master/_drafts/2015-08-07-full-text.Rmd">.Rmd</a> -->
  <i class="fa fa-code fa-large"></i>&nbsp;Source: <a href="https://github.com/sckott/sckott.github.com/tree/master/_drafts/2015-08-07-full-text.Rmd">.Rmd/.md</a>
  <br><br>
  <p>Finally, we got <code class="highlighter-rouge">fulltext</code> up on CRAN - our first commit was <a href="https://github.com/ropensci/fulltext/commit/2d4f7e270040b2c8914853113073fc4d3134445e">May last year</a>. <code class="highlighter-rouge">fulltext</code> is a package to facilitate text mining. It focuses on open access journals. This package makes it easier to search for articles, download those articles in full text if available, convert pdf format to plain text, and extract text chunks for vizualization/analysis. We are planning to add bits for analysis in future versions. We’ve been working on this package for a while now. It has a lot of moving parts and package dependencies, so it took a while to get a first useable version.</p>

<p>The tasks facilitated by <code class="highlighter-rouge">fulltext</code> in bullet form:</p>

<ul>
  <li>Search - search for articles</li>
  <li>Retrieve - get full text</li>
  <li>Convert - convert from format X to Y</li>
  <li>Text - if needed, get text from pdfs/etc.</li>
  <li>Extract - pull out the bits of articles that you want</li>
</ul>

<p>I won’t be surprised if users uncover a lot of bugs in this package given the huge number of publishers/journals users want to get literature data from, and the surely wide diversity of use cases. But I thought it was important to get out a first version to get feedback on the user interface, and gather use cases.</p>

<p>We hope that this package can help bring text-mining to the masses - making it easy for anyone to do do, not just text-mining experts.</p>

<p>If you have any feedback, please do get in touch in the issue tracker for <code class="highlighter-rouge">fulltext</code> at https://github.com/ropensci/fulltext/issues - If you have use case thoughts, the <a href="https://discuss.ropensci.org/">rOpenSci discussion forum</a> might be a good place to go.</p>

<p>Let’s kick the tires, shall we?</p>

<h2 id="install">Install</h2>

<p>Will be on CRAN soon, not as of AM PDT on 2015-08-07.</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">install.packages</span><span class="p">(</span><span class="s2">"fulltext"</span><span class="p">)</span><span class="w">
</span><span class="c1"># if binaries not avail. yet on your favorite CRAN mirror
</span><span class="n">install.packages</span><span class="p">(</span><span class="s2">"https://cran.rstudio.com/src/contrib/fulltext_0.1.0.tar.gz"</span><span class="p">,</span><span class="w"> </span><span class="n">repos</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">NULL</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"source"</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<p>Or install development version from GitHub</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">devtools</span><span class="o">::</span><span class="n">install_github</span><span class="p">(</span><span class="s2">"ropensci/fulltext"</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<p>Load <code class="highlighter-rouge">fulltext</code></p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="s2">"fulltext"</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<h2 id="search-for-articles">Search for articles</h2>

<p>Currently, there are hooks for searching for articles from PLOS, BMC, Crossref, Entrez, arXiv, and BioRxiv. We’ll add more in the future, but that does cover a lot of articles, especially given inclusion of Crossref (which mints most DOIs) and Entrez (which houses PMC and Pubmed).</p>

<p>An example: Search for the term <em>ecology</em> in PLOS journals.</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="p">(</span><span class="n">res1</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ft_search</span><span class="p">(</span><span class="n">query</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'ecology'</span><span class="p">,</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'plos'</span><span class="p">))</span><span class="w">
</span><span class="c1">#&gt; Query:
#&gt;   [ecology] 
#&gt; Found:
#&gt;   [PLoS: 28589; BMC: 0; Crossref: 0; Entrez: 0; arxiv: 0; biorxiv: 0] 
#&gt; Returned:
#&gt;   [PLoS: 10; BMC: 0; Crossref: 0; Entrez: 0; arxiv: 0; biorxiv: 0]
</span></code></pre>
</div>

<p>Each publisher/search-engine has a slot with metadata and data, saying how many articles were found and how many were returned. We can dig into what PLOS gave us:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">res1</span><span class="o">$</span><span class="n">plos</span><span class="w">
</span><span class="c1">#&gt; Query: [ecology] 
#&gt; Records found, returned: [28589, 10] 
#&gt; License: [CC-BY] 
#&gt;                                                         id
#&gt; 1                             10.1371/journal.pone.0059813
#&gt; 2                             10.1371/journal.pone.0001248
#&gt; 3  10.1371/annotation/69333ae7-757a-4651-831c-f28c5eb02120
#&gt; 4                             10.1371/journal.pone.0080763
#&gt; 5                             10.1371/journal.pone.0102437
#&gt; 6                             10.1371/journal.pone.0017342
#&gt; 7                             10.1371/journal.pone.0091497
#&gt; 8                             10.1371/journal.pone.0092931
#&gt; 9  10.1371/annotation/28ac6052-4f87-4b88-a817-0cd5743e83d6
#&gt; 10                            10.1371/journal.pcbi.1003594
</span></code></pre>
</div>

<p>For each of the data sources to search on you can pass in additional options (basically, you can use the query parameters in the functions that hit each service). Here, we can modify our search to PLOS by requesting a particular set of fields with the <code class="highlighter-rouge">fl</code> parameter (PLOS uses a Solr backed search engine, and <code class="highlighter-rouge">fl</code> is short for <code class="highlighter-rouge">fields</code> in Solr land):</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">ft_search</span><span class="p">(</span><span class="n">query</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'ecology'</span><span class="p">,</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'plos'</span><span class="p">,</span><span class="w"> </span><span class="n">plosopts</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="w">
   </span><span class="n">fl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s1">'id'</span><span class="p">,</span><span class="s1">'author'</span><span class="p">,</span><span class="s1">'eissn'</span><span class="p">,</span><span class="s1">'journal'</span><span class="p">,</span><span class="s1">'counter_total_all'</span><span class="p">,</span><span class="s1">'alm_twitterCount'</span><span class="p">)))</span><span class="w">
</span><span class="c1">#&gt; Query:
#&gt;   [ecology] 
#&gt; Found:
#&gt;   [PLoS: 28589; BMC: 0; Crossref: 0; Entrez: 0; arxiv: 0; biorxiv: 0] 
#&gt; Returned:
#&gt;   [PLoS: 10; BMC: 0; Crossref: 0; Entrez: 0; arxiv: 0; biorxiv: 0]
</span></code></pre>
</div>

<blockquote>
  <p>Note that PLOS is a bit unique in allowing you to request specific parts of articles. Other sources in ft_search() don’t let you do that.</p>
</blockquote>

<h2 id="get-full-text">Get full text</h2>

<p>After you’ve found the set of articles you want to get full text for, we can use the results from <code class="highlighter-rouge">ft_search()</code> to grab full text. <code class="highlighter-rouge">ft_get()</code> accepts a character vector of list of DOIs (or PMC IDs if fetching from Entrez), or the output of <code class="highlighter-rouge">ft_search()</code>.</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="p">(</span><span class="n">out</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ft_get</span><span class="p">(</span><span class="n">res1</span><span class="p">))</span><span class="w">
</span><span class="c1">#&gt; [Docs] 8 
#&gt; [Source] R session  
#&gt; [IDs] 10.1371/journal.pone.0059813 10.1371/journal.pone.0001248
#&gt;      10.1371/journal.pone.0080763 10.1371/journal.pone.0102437
#&gt;      10.1371/journal.pone.0017342 10.1371/journal.pone.0091497
#&gt;      10.1371/journal.pone.0092931 10.1371/journal.pcbi.1003594 ...
</span></code></pre>
</div>

<p>We got eight articles in full text in the result. We didn’t get 10, even though 10 were returned from <code class="highlighter-rouge">ft_search()</code> because PLOS often returns records for annotations, that is, comments on articles, which we auto-seive out within <code class="highlighter-rouge">ft_get()</code>.</p>

<p>Dig in to the PLOS data</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">out</span><span class="o">$</span><span class="n">plos</span><span class="w">
</span><span class="c1">#&gt; $found
#&gt; [1] 8
#&gt; 
#&gt; $dois
#&gt; [1] "10.1371/journal.pone.0059813" "10.1371/journal.pone.0001248"
#&gt; [3] "10.1371/journal.pone.0080763" "10.1371/journal.pone.0102437"
#&gt; [5] "10.1371/journal.pone.0017342" "10.1371/journal.pone.0091497"
#&gt; [7] "10.1371/journal.pone.0092931" "10.1371/journal.pcbi.1003594"
#&gt; 
#&gt; $data
#&gt; $data$backend
#&gt; NULL
#&gt; 
#&gt; $data$path
#&gt; [1] "session"
#&gt; 
#&gt; $data$data
#&gt; 8 full-text articles retrieved 
#&gt; Min. Length: 3828 - Max. Length: 104702 
#&gt; DOIs: 10.1371/journal.pone.0059813 10.1371/journal.pone.0001248
#&gt;   10.1371/journal.pone.0080763 10.1371/journal.pone.0102437
#&gt;   10.1371/journal.pone.0017342 10.1371/journal.pone.0091497
#&gt;   10.1371/journal.pone.0092931 10.1371/journal.pcbi.1003594 ... 
#&gt; 
#&gt; NOTE: extract xml strings like output['&lt;doi&gt;']
#&gt; 
#&gt; $opts
#&gt; $opts$doi
#&gt; [1] "10.1371/journal.pone.0059813" "10.1371/journal.pone.0001248"
#&gt; [3] "10.1371/journal.pone.0080763" "10.1371/journal.pone.0102437"
#&gt; [5] "10.1371/journal.pone.0017342" "10.1371/journal.pone.0091497"
#&gt; [7] "10.1371/journal.pone.0092931" "10.1371/journal.pcbi.1003594"
#&gt; 
#&gt; $opts$callopts
#&gt; list()
</span></code></pre>
</div>

<p>Dig in further to get to one of the articles in XML format</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="s2">"xml2"</span><span class="p">)</span><span class="w">
</span><span class="n">xml2</span><span class="o">::</span><span class="n">read_xml</span><span class="p">(</span><span class="n">out</span><span class="o">$</span><span class="n">plos</span><span class="o">$</span><span class="n">data</span><span class="o">$</span><span class="n">data</span><span class="o">$</span><span class="n">`10.1371/journal.pone.0059813`</span><span class="p">)</span><span class="w">
</span><span class="c1">#&gt; {xml_document}
#&gt; &lt;article&gt;
#&gt; [1] &lt;front&gt;\n&lt;journal-meta&gt;\n&lt;journal-id journal-id-type="nlm-ta"&gt;PLoS O ...
#&gt; [2] &lt;body&gt;\n  &lt;sec id="s1"&gt;\n&lt;title&gt;Introduction&lt;/title&gt;\n&lt;p&gt;Ecologists  ...
#&gt; [3] &lt;back&gt;\n&lt;ack&gt;\n&lt;p&gt;Curtis Flather, Mark Burgman, Leon Blaustein, Yaac ...
</span></code></pre>
</div>

<p>Now with the xml, you can dig into whatever you like, e.g., using <code class="highlighter-rouge">xml2</code> or <code class="highlighter-rouge">rvest</code>.</p>

<h2 id="extract-text-from-pdfs">Extract text from pdfs</h2>

<p>Ideally for text mining you have access to XML or other text based formats. However, sometimes you only have access to PDFs. In this case you want to extract text from PDFs. <code class="highlighter-rouge">fulltext</code> can help with that.</p>

<p>You can extract from any pdf from a file path, like:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">path</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">system.file</span><span class="p">(</span><span class="s2">"examples"</span><span class="p">,</span><span class="w"> </span><span class="s2">"example1.pdf"</span><span class="p">,</span><span class="w"> </span><span class="n">package</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"fulltext"</span><span class="p">)</span><span class="w">
</span><span class="n">ft_extract</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="w">
</span><span class="c1">#&gt; &lt;document&gt;/Library/Frameworks/R.framework/Versions/3.2/Resources/library/fulltext/examples/example1.pdf
#&gt;   Pages: 18
#&gt;   Title: Suffering and mental health among older people living in nursing homes---a mixed-methods study
#&gt;   Producer: pdfTeX-1.40.10
#&gt;   Creation date: 2015-07-17
</span></code></pre>
</div>

<p>Let’s search for articles from arXiv, a preprint service. Here, get pdf from an article with ID <code class="highlighter-rouge">cond-mat/9309029</code>:</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">res</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ft_get</span><span class="p">(</span><span class="s1">'cond-mat/9309029'</span><span class="p">,</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"arxiv"</span><span class="p">)</span><span class="w">
</span><span class="n">res2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ft_extract</span><span class="p">(</span><span class="n">res</span><span class="p">)</span><span class="w">
</span><span class="n">res2</span><span class="o">$</span><span class="n">arxiv</span><span class="o">$</span><span class="n">data</span><span class="w">
</span><span class="c1">#&gt; $backend
#&gt; NULL
#&gt; 
#&gt; $path
#&gt; $path$`cond-mat/9309029`
#&gt; [1] "~/.fulltext/cond-mat_9309029.pdf"
#&gt; 
#&gt; 
#&gt; $data
#&gt; $data[[1]]
#&gt; &lt;document&gt;/Users/sacmac/.fulltext/cond-mat_9309029.pdf
#&gt;   Pages: 14
#&gt;   Title: arXiv:cond-mat/9309029v8  26 Jan 1994
#&gt;   Producer: GPL Ghostscript SVN PRE-RELEASE 8.62
#&gt;   Creation date: 2008-02-06
</span></code></pre>
</div>

<p>And a short snippet of the full text</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">res2</span><span class="o">$</span><span class="n">arxiv</span><span class="o">$</span><span class="n">data</span><span class="o">$</span><span class="n">data</span><span class="p">[[</span><span class="m">1</span><span class="p">]]</span><span class="o">$</span><span class="n">data</span><span class="w">
</span><span class="c1">#&gt; "arXiv:cond-mat/9309029v8 26 Jan 1994, , FERMILAB-PUB-93/15-T March 1993, Revised:
#&gt; January 1994, The Thermodynamics and Economics of Waste, Dallas C. Kennedy, Research
#&gt; Associate, Fermi National Accelerator Laboratory, P.O. Box 500 MS106, Batavia, Illinois
#&gt; 60510 USA, Abstract, The increasingly relevant problem of natural resource use and
#&gt; waste production, disposal, and reuse is examined from several viewpoints: economic,
#&gt; technical, and thermodynamic. Alternative economies are studied, with emphasis on
#&gt; recycling of waste to close the natural resource cycle. The physical nature of human
#&gt; economies and constraints on recycling and energy efficiency are stated in terms
#&gt; ..."
</span></code></pre>
</div>

<h2 id="extract-text-chunks">Extract text chunks</h2>

<p>We have a few functions to help you pull out certain parts of an article. For example, perhaps you want to get just the authors from your articles, or just the abstracts.</p>

<p>Here, we’ll search for some PLOS articles, then get their full text, then extract various parts of each article with <code class="highlighter-rouge">chunks()</code>.</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">res</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ft_search</span><span class="p">(</span><span class="n">query</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"ecology"</span><span class="p">,</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"plos"</span><span class="p">)</span><span class="w">
</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ft_get</span><span class="p">(</span><span class="n">res</span><span class="p">))</span><span class="w">
</span><span class="c1">#&gt; [Docs] 8 
#&gt; [Source] R session  
#&gt; [IDs] 10.1371/journal.pone.0059813 10.1371/journal.pone.0001248
#&gt;      10.1371/journal.pone.0080763 10.1371/journal.pone.0102437
#&gt;      10.1371/journal.pone.0017342 10.1371/journal.pone.0091497
#&gt;      10.1371/journal.pone.0092931 10.1371/journal.pcbi.1003594 ...
</span></code></pre>
</div>

<p>Extract DOIs</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">x</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">chunks</span><span class="p">(</span><span class="s2">"doi"</span><span class="p">)</span><span class="w">
</span><span class="c1">#&gt; $plos
#&gt; $plos$`10.1371/journal.pone.0059813`
#&gt; $plos$`10.1371/journal.pone.0059813`$doi
#&gt; [1] "10.1371/journal.pone.0059813"
#&gt; 
#&gt; 
#&gt; $plos$`10.1371/journal.pone.0001248`
#&gt; $plos$`10.1371/journal.pone.0001248`$doi
#&gt; [1] "10.1371/journal.pone.0001248"
#&gt; 
#&gt; 
#&gt; $plos$`10.1371/journal.pone.0080763`
#&gt; $plos$`10.1371/journal.pone.0080763`$doi
#&gt; [1] "10.1371/journal.pone.0080763"
#&gt; 
#&gt; 
#&gt; $plos$`10.1371/journal.pone.0102437`
#&gt; $plos$`10.1371/journal.pone.0102437`$doi
#&gt; [1] "10.1371/journal.pone.0102437"
#&gt; 
#&gt; 
#&gt; $plos$`10.1371/journal.pone.0017342`
#&gt; $plos$`10.1371/journal.pone.0017342`$doi
#&gt; [1] "10.1371/journal.pone.0017342"
#&gt; 
#&gt; 
#&gt; $plos$`10.1371/journal.pone.0091497`
#&gt; $plos$`10.1371/journal.pone.0091497`$doi
#&gt; [1] "10.1371/journal.pone.0091497"
#&gt; 
#&gt; 
#&gt; $plos$`10.1371/journal.pone.0092931`
#&gt; $plos$`10.1371/journal.pone.0092931`$doi
#&gt; [1] "10.1371/journal.pone.0092931"
#&gt; 
#&gt; 
#&gt; $plos$`10.1371/journal.pcbi.1003594`
#&gt; $plos$`10.1371/journal.pcbi.1003594`$doi
#&gt; [1] "10.1371/journal.pcbi.1003594"
</span></code></pre>
</div>

<p>Extract DOIs and categories</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">x</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">chunks</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s2">"doi"</span><span class="p">,</span><span class="s2">"categories"</span><span class="p">))</span><span class="w">
</span><span class="c1">#&gt; $plos
#&gt; $plos$`10.1371/journal.pone.0059813`
#&gt; $plos$`10.1371/journal.pone.0059813`$doi
#&gt; [1] "10.1371/journal.pone.0059813"
#&gt; 
#&gt; $plos$`10.1371/journal.pone.0059813`$categories
#&gt;  [1] "Research Article"                 "Biology"                         
#&gt;  [3] "Ecology"                          "Community ecology"               
#&gt;  [5] "Species interactions"             "Science policy"                  
#&gt;  [7] "Research assessment"              "Research monitoring"             
#&gt;  [9] "Research funding"                 "Government funding of science"   
#&gt; [11] "Research laboratories"            "Science policy and economics"    
#&gt; [13] "Science and technology workforce" "Careers in research"             
#&gt; [15] "Social and behavioral sciences"   "Sociology"                       
#&gt; [17] "Sociology of knowledge"          
#&gt; 
#&gt; 
#&gt; $plos$`10.1371/journal.pone.0001248`
#&gt; $plos$`10.1371/journal.pone.0001248`$doi
#&gt; [1] "10.1371/journal.pone.0001248"
#&gt; 
#&gt; $plos$`10.1371/journal.pone.0001248`$categories
#&gt; [1] "Research Article"             "Ecology"                     
#&gt; [3] "Ecology/Ecosystem Ecology"    "Ecology/Evolutionary Ecology"
#&gt; [5] "Ecology/Theoretical Ecology" 
#&gt; 
#&gt; 
#&gt; $plos$`10.1371/journal.pone.0080763`
#&gt; $plos$`10.1371/journal.pone.0080763`$doi
#&gt; [1] "10.1371/journal.pone.0080763"
#&gt; 
#&gt; $plos$`10.1371/journal.pone.0080763`$categories
#&gt;  [1] "Research Article"     "Biology"              "Ecology"             
#&gt;  [4] "Autecology"           "Behavioral ecology"   "Community ecology"   
#&gt;  [7] "Evolutionary ecology" "Population ecology"   "Evolutionary biology"
#&gt; [10] "Behavioral ecology"   "Evolutionary ecology" "Population biology"  
#&gt; [13] "Population ecology"  
#&gt; 
#&gt; 
#&gt; $plos$`10.1371/journal.pone.0102437`
#&gt; $plos$`10.1371/journal.pone.0102437`$doi
#&gt; [1] "10.1371/journal.pone.0102437"
#&gt; 
#&gt; $plos$`10.1371/journal.pone.0102437`$categories
#&gt;  [1] "Research Article"                  
#&gt;  [2] "Biology and life sciences"         
#&gt;  [3] "Biogeography"                      
#&gt;  [4] "Ecology"                           
#&gt;  [5] "Ecosystems"                        
#&gt;  [6] "Ecosystem engineering"             
#&gt;  [7] "Ecosystem functioning"             
#&gt;  [8] "Industrial ecology"                
#&gt;  [9] "Spatial and landscape ecology"     
#&gt; [10] "Urban ecology"                     
#&gt; [11] "Computer and information sciences" 
#&gt; [12] "Geoinformatics"                    
#&gt; [13] "Spatial analysis"                  
#&gt; [14] "Earth sciences"                    
#&gt; [15] "Geography"                         
#&gt; [16] "Human geography"                   
#&gt; [17] "Cultural geography"                
#&gt; [18] "Social geography"                  
#&gt; [19] "Ecology and environmental sciences"
#&gt; [20] "Conservation science"              
#&gt; [21] "Environmental protection"          
#&gt; [22] "Nature-society interactions"       
#&gt; 
#&gt; 
#&gt; $plos$`10.1371/journal.pone.0017342`
#&gt; $plos$`10.1371/journal.pone.0017342`$doi
#&gt; [1] "10.1371/journal.pone.0017342"
#&gt; 
#&gt; $plos$`10.1371/journal.pone.0017342`$categories
#&gt;  [1] "Research Article"     "Biology"              "Ecology"             
#&gt;  [4] "Community ecology"    "Community assembly"   "Community structure" 
#&gt;  [7] "Niche construction"   "Ecological metrics"   "Species diversity"   
#&gt; [10] "Species richness"     "Biodiversity"         "Biogeography"        
#&gt; [13] "Population ecology"   "Mathematics"          "Statistics"          
#&gt; [16] "Biostatistics"        "Statistical theories" "Ecology"             
#&gt; [19] "Mathematics"         
#&gt; 
#&gt; 
#&gt; $plos$`10.1371/journal.pone.0091497`
#&gt; $plos$`10.1371/journal.pone.0091497`$doi
#&gt; [1] "10.1371/journal.pone.0091497"
#&gt; 
#&gt; $plos$`10.1371/journal.pone.0091497`$categories
#&gt; [1] "Correction"
#&gt; 
#&gt; 
#&gt; $plos$`10.1371/journal.pone.0092931`
#&gt; $plos$`10.1371/journal.pone.0092931`$doi
#&gt; [1] "10.1371/journal.pone.0092931"
#&gt; 
#&gt; $plos$`10.1371/journal.pone.0092931`$categories
#&gt; [1] "Correction"
#&gt; 
#&gt; 
#&gt; $plos$`10.1371/journal.pcbi.1003594`
#&gt; $plos$`10.1371/journal.pcbi.1003594`$doi
#&gt; [1] "10.1371/journal.pcbi.1003594"
#&gt; 
#&gt; $plos$`10.1371/journal.pcbi.1003594`$categories
#&gt; [1] "Research Article"          "Biology and life sciences"
#&gt; [3] "Computational biology"     "Microbiology"             
#&gt; [5] "Theoretical biology"
</span></code></pre>
</div>

<p><code class="highlighter-rouge">tabularize</code> attempts to help you put the data that comes out of <code class="highlighter-rouge">chunks()</code> in to a <code class="highlighter-rouge">data.frame</code>, that we all know and love.</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">x</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">chunks</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s2">"doi"</span><span class="p">,</span><span class="w"> </span><span class="s2">"history"</span><span class="p">))</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">tabularize</span><span class="p">()</span><span class="w">
</span><span class="c1">#&gt; $plos
#&gt;                            doi history.received history.accepted
#&gt; 1 10.1371/journal.pone.0059813       2012-09-16       2013-02-19
#&gt; 2 10.1371/journal.pone.0001248       2007-07-02       2007-11-06
#&gt; 3 10.1371/journal.pone.0080763       2013-08-15       2013-10-16
#&gt; 4 10.1371/journal.pone.0102437       2013-11-27       2014-06-19
#&gt; 5 10.1371/journal.pone.0017342       2010-08-24       2011-01-31
#&gt; 6 10.1371/journal.pone.0091497             &lt;NA&gt;             &lt;NA&gt;
#&gt; 7 10.1371/journal.pone.0092931             &lt;NA&gt;             &lt;NA&gt;
#&gt; 8 10.1371/journal.pcbi.1003594       2014-01-09       2014-03-14
</span></code></pre>
</div>

<h2 id="bring-it-all-together">Bring it all together</h2>

<p>With the pieces above, let’s see what it looks like all in one go. Here, we’ll search for articles on <em>climate change</em>, then visualize word usage in those articles.</p>

<h3 id="search">Search</h3>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="p">(</span><span class="n">out</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ft_search</span><span class="p">(</span><span class="n">query</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'climate change'</span><span class="p">,</span><span class="w"> </span><span class="n">from</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'plos'</span><span class="p">,</span><span class="w"> </span><span class="n">limit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">100</span><span class="p">))</span><span class="w">
</span><span class="c1">#&gt; Query:
#&gt;   [climate change] 
#&gt; Found:
#&gt;   [PLoS: 11737; BMC: 0; Crossref: 0; Entrez: 0; arxiv: 0; biorxiv: 0] 
#&gt; Returned:
#&gt;   [PLoS: 100; BMC: 0; Crossref: 0; Entrez: 0; arxiv: 0; biorxiv: 0]
</span></code></pre>
</div>

<h3 id="get-full-text-1">Get full text</h3>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="p">(</span><span class="n">texts</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">ft_get</span><span class="p">(</span><span class="n">out</span><span class="p">))</span><span class="w">
</span><span class="c1">#&gt; [Docs] 99 
#&gt; [Source] R session  
#&gt; [IDs] 10.1371/journal.pone.0054839 10.1371/journal.pone.0045683
#&gt;      10.1371/journal.pone.0050182 10.1371/journal.pone.0118489
#&gt;      10.1371/journal.pone.0053646 10.1371/journal.pone.0015103
#&gt;      10.1371/journal.pone.0008320 10.1371/journal.pmed.1001227
#&gt;      10.1371/journal.pmed.1001374 10.1371/journal.pone.0097480 ...
</span></code></pre>
</div>

<p>Because PLOS returns XML, we don’t need to do a PDF extraction step. However, if we got full text from arXiv or bioRxiv, we’d need to extract from PDFs first.</p>

<h3 id="pull-out-chunks">Pull out chunks</h3>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">abs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">texts</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="n">chunks</span><span class="p">(</span><span class="s2">"abstract"</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<p>Let’s pull out just the text</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">abs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">lapply</span><span class="p">(</span><span class="n">abs</span><span class="o">$</span><span class="n">plos</span><span class="p">,</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
  </span><span class="n">paste0</span><span class="p">(</span><span class="n">z</span><span class="o">$</span><span class="n">abstract</span><span class="p">,</span><span class="w"> </span><span class="n">collapse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">" "</span><span class="p">)</span><span class="w">
</span><span class="p">})</span><span class="w">
</span></code></pre>
</div>

<h3 id="analyze">Analyze</h3>

<p>Using the <code class="highlighter-rouge">tm</code> package, we can analyze our articles</p>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="s2">"tm"</span><span class="p">)</span><span class="w">
</span><span class="n">corp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">VCorpus</span><span class="p">(</span><span class="n">VectorSource</span><span class="p">(</span><span class="n">abs</span><span class="p">))</span><span class="w">
</span><span class="c1"># remove stop words, strip whitespace, remove punctuation
</span><span class="n">corp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">tm_map</span><span class="p">(</span><span class="n">corp</span><span class="p">,</span><span class="w"> </span><span class="n">removeWords</span><span class="p">,</span><span class="w"> </span><span class="n">stopwords</span><span class="p">(</span><span class="s2">"english"</span><span class="p">))</span><span class="w">
</span><span class="n">corp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">tm_map</span><span class="p">(</span><span class="n">corp</span><span class="p">,</span><span class="w"> </span><span class="n">stripWhitespace</span><span class="p">)</span><span class="w">
</span><span class="n">corp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">tm_map</span><span class="p">(</span><span class="n">corp</span><span class="p">,</span><span class="w"> </span><span class="n">removePunctuation</span><span class="p">)</span><span class="w">
</span><span class="c1"># Make a term document matrix
</span><span class="n">tdm</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">TermDocumentMatrix</span><span class="p">(</span><span class="n">corp</span><span class="p">)</span><span class="w">
</span><span class="c1"># remove sparse terms
</span><span class="n">tdm</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">removeSparseTerms</span><span class="p">(</span><span class="n">tdm</span><span class="p">,</span><span class="w"> </span><span class="n">sparse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0.8</span><span class="p">)</span><span class="w">
</span><span class="c1"># get data
</span><span class="n">rs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">rowSums</span><span class="p">(</span><span class="n">as.matrix</span><span class="p">(</span><span class="n">tdm</span><span class="p">))</span><span class="w">
</span><span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">data.frame</span><span class="p">(</span><span class="n">word</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">names</span><span class="p">(</span><span class="n">rs</span><span class="p">),</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">unname</span><span class="p">(</span><span class="n">rs</span><span class="p">),</span><span class="w"> </span><span class="n">stringsAsFactors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">FALSE</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<h3 id="visualize">Visualize</h3>

<div class="language-r highlighter-rouge"><pre class="highlight"><code><span class="n">library</span><span class="p">(</span><span class="s2">"ggplot2"</span><span class="p">)</span><span class="w">
</span><span class="n">ggplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">aes</span><span class="p">(</span><span class="n">reorder</span><span class="p">(</span><span class="n">word</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="p">),</span><span class="w"> </span><span class="n">n</span><span class="p">))</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">geom_point</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">coord_flip</span><span class="p">()</span><span class="w"> </span><span class="o">+</span><span class="w">
  </span><span class="n">labs</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Count"</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"Word"</span><span class="p">)</span><span class="w">
</span></code></pre>
</div>

<p><img src="/public/img/2015-08-07-full-text/unnamed-chunk-23-1.png" alt="plot of chunk unnamed-chunk-23" /></p>

</div>

<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'coffeehaus'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

<!-- <div class="related">
  <h2>Related Posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/2016/06/marine-regions/">
            Marine Regions data in R
            <small>09 Jun 2016</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/2016/04/atomize/">
            atomize - make new packages from other packages
            <small>07 Apr 2016</small>
          </a>
        </h3>
      </li>
    
      <li>
        <h3>
          <a href="/2016/03/genbank-ids/">
            GenBank IDs API - get, match, swap id types
            <small>29 Mar 2016</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>
 -->

    </div>

    <!-- for bootstrap tooltips -->
    <script type="text/javascript">
      $("[data-toggle=\"tooltip\"]").tooltip();
    </script>

  </body>

  <footer>
  <!-- Disqus code -->
  <script type="text/javascript">
      /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
      var disqus_shortname = 'recology'; // required: replace example with your forum shortname

      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function () {
          var s = document.createElement('script'); s.async = true;
          s.type = 'text/javascript';
          s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
          (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
      }());
  </script>

  <!-- google analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-63197374-1', 'auto');
    ga('send', 'pageview');
  </script>
</footer>

</html>
