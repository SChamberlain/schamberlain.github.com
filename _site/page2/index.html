<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  <link href="http://gmpg.org/xfn/11" rel="profile">

  <title>
    
    Recology, R/etc.
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Open+Sans:300,400italic,400,600,700|Abril+Fatface">

  <link rel="stylesheet" href="/public/css/bootstrap/css/bootstrap.css">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/favicon.ico">
  <link rel="shortcut icon" href="/public/favicon.ico">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.css" rel="stylesheet">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body class="theme-base-0f layout-reverse">

    <header class="masthead">
      <div class="masthead-inner">
        <h1>Recology</h1>
        <!-- <h1> <a href="http://recology.info/">Recology</a></h1> -->
        <p class="lead">R/etc.</p>

        <div class="colophon">
          <ul class="colophon-links">
            <li>
              <a href="/"><i class="fa fa-home fa-lg"></i></a>&nbsp;
              <a href="/about"><i class="fa fa-info-circle fa-lg"></i></a>&nbsp;
              <a href="/archives"><i class="fa fa-archive fa-lg"></i></a>&nbsp;
              <a href="/rresources"><i class="fa fa-book fa-lg"></i></a>&nbsp;
              <a href="http://rforcats.net/" rel><i class="fa fa-graduation-cap fa-lg"></i></a>&nbsp;
              <a href="/feed.xml"><i class="fa fa-rss fa-lg"></i></a>&nbsp;
              <a href="https://twitter.com/sckottie"><i class="fa fa-twitter fa-lg"></i></a>&nbsp;
              <a href="/fork"><i class="fa fa-spinner fa-lg"></i></a>
            </li>
          </ul>
          <!-- <small><a href="https://github.com/mdo/hyde">Hyde</a> from <a href="https://twitter.com/mdo" target="_blank">@mdo</a>.</small> -->
        </div>
      </div>
    </header>

    <div class="content container">
      <div class="posts">
  <a style="float:right;" href="/archives" data-toggle="tooltip" data-placement="bottom" title="Archives"><i class="fa fa-archive fa-lg"></i></a>
  <a style="float:right;" href="/tags"><i class="fa fa-tags fa-lg"></i></a>&nbsp;
  
  <div class="post">
    <h1>
      <a href="/2016/03/genbank-ids/">
        GenBank IDs API - get, match, swap id types
      </a>
    </h1>

    <span class="post-date">29 Mar 2016</span>

    GenBank IDs, accession numbers and GI identifiers, are the two types of identifiers for entries in GenBank. (see [this page](http://www.ncbi.nlm.nih.gov/Sitemap/sequenceIDs.html) for why there are two types of identifiers). Actually, [recent news](http://www.ncbi.nlm.nih.gov/news/03-02-2016-phase-out-of-GI-numbers/) from NCBI is that GI identifiers will be phased out by September this year, which affects what I'll talk about below.

There are a lot of sequences in GenBank. Sometimes you have identifiers and you want to check if they exist in GenBank, or want to get one type from another (accession from GI, or vice versa; although GI phase out will make this use case no longer needed), or just get a bunch of identifiers for software testing purposes perhaps.

Currently, the ENTREZ web services aren't super performant or easy to use for the above use cases. Thus, I've built out a RESTful API for these use cases, called [gbids][gbids].

`gbids` on GitHub: [sckott/gbids][gbids]

Here's the tech stack:

* API: Ruby/Sinatra
* Storage: MySQL
* Caching: Redis
  * each key cached for 3 hours
* Server: Caddy
  * https
* Authentication: none

Will soon have a cron job update when new dump is available every Sunday, but for now we're about a month behind the current dump of identifiers. If usage of the API picks up, I'll know it's worth maintaining and make sure data is up to date.

The base url is [https://gbids.xyz](https://gbids.xyz).

Here's a rundown of the API routes:

* `/` re-routes to `/heartbeat`
* `/heartbeat` - list routes
* `/acc` - `GET` - list accession ids
* `/acc/:id,:id,...` - `GET` - submit many accession numbers, get back boolean (match or no match)
* `/acc` - `POST`
* `/gi` - `GET` - list gi numbers
* `/gi/:id,:id,...` - `GET` - submit many gi numbers, get back boolean (match or no match)
* `/gi` - `POST`
* `/acc2gi/:id,:id,...` - `GET` - get gi numbers from accession numbers
* `/acc2gi` - `POST`
* `/gi2acc/:id,:id,...` - `GET` - get accession numbers from gi numbers
* `/gi2acc` - `POST`

Of course after GI identifiers are phased out, all `gi` routes will be removed.

The API docs are at [recology.info/gbidsdocs](http://recology.info/gbidsdocs) - let me know if you have any feedback on those.

I also have a status page up at [recology.info/gbidsstatus](http://recology.info/gbidsstatus/) - it's not automated, I have to update the status manually, but I do update that page whenever I'm doing maintenance and the API will be down, or if it goes down due to any other reason.

## examples

Request to list accession identifiers, limit to 5

```
curl 'https://gbids.xyz/acc?limit=5' | jq .
{
  "matched": 692006925,
  "returned": 5,
  "data": [
    "A00002",
    "A00003",
    "X17276",
    "X60065",
    "CAA42669"
  ],
  "error": null
}
```

Request to match accession identifiers, some exist, while some do not

```
curl 'https://gbids.xyz/acc/AACY024124486,AACY024124483,asdfd,asdf,AACY024124476' | jq .
{
  "matched": 3,
  "returned": 5,
  "data": {
    "AACY024124486": true,
    "AACY024124483": true,
    "asdfd": false,
    "asdf": false,
    "AACY024124476": true
  },
  "error": null
}
```

## to do

I think it'd probably be worth adding routes for getting accession from taxonomy id and vice versa since that's something that is currently not very easy. We could use the dumped accession2taxid data from ftp://ftp.ncbi.nih.gov/pub/taxonomy/accession2taxid/

## feedback!

If you think this could be potentially useful, do try it out and send any feedback. I watch logs from the API, so I'm hoping for an increase in usage so I know people find it useful.

Since servers aren't free, costs add up, and if I don't see usage pick up I'll discontinue the service at some point. So do use it!

And if anyone can offer free servers, I'd gladly take advantage of that. I've applied for AWS research grant, but won't hear back for a few months.

[gbids]: https://github.com/sckott/gbids

  </div>
  
  <div class="post">
    <h1>
      <a href="/2016/03/hey-there/">
        heythere - a robot to automate GitHub issue comments
      </a>
    </h1>

    <span class="post-date">24 Mar 2016</span>

    GitHub issues are great for humans to correspond over software, or any other project. At rOpenSci we use an issue based software review system ([ropensci/onboarding](https://github.com/ropensci/onboarding)). Software authors and reviewers go back and forth on the software, making a better product in the end.

We have a relatively small number of pieces of software under review at any one time compared to e.g., scientific journals - however, even with the small number, we as organizers, and authors and reviewers can forget things. For example:

* an organizer can forget to remind a reviewer to get a review in
* a reviewer can forget about a review, and may benefit from a friendly reminder
* an author may forget about updating software based on the review

As we are managing more package submissions through our system, automated things done by machine, or robot, will be increasingly helpful to keep the system moving smoothly.

A big red flag with automated systems is the annoyance factor. We can try to be smart about this and only remind people when it's really needed.

I've been working on a thing for a while now, it's called `heythere`. It's a Ruby application that is currently set up to run on Heroku, though you could run it anywhere you want. It's running right now once per day to check to see if it should send any reminders to organizers, authors, reviewers.

`heythere` on GitHub: [ropenscilabs/heythere][ht]

## How it works

`heythere` is controlled through a series of environment variables that controls GitHub authentication, the first day post reviewer assignment when a reminder should be sent, how many days after reviews are submitted to ask if the author needs any help, and more. Check out the [repo][ht] for all the env var options.

The Ruby app can be run via a rake task from the command line, or triggered with a scheduler on something like Heroku.

When the app runs, we look for environment variables that you set. If we don't find them we use sensible defaults.

Using the env vars, we grab the issues for the repository you chose, limit to a subset of your choosing based on a series of labels, then compare dates on comments compared to your env vars, and either skip or send of comments on issues.

We use [ockokit](https://github.com/octokit/octokit.rb) under the hood to work with GitHub issues.

## How to use it

### clone

```
git clone git@github.com:ropenscilabs/heythere.git
cd heythere
```

### setup

Change the repo in `Rakefile` to whatever your repository is.

```
Heythere.hey_there(repo = 'ropensci/onboarding')
```

Create the app (use a different name, of course)

```
heroku apps:create ropensci-hey-there
```

Add the repository that you are targeting:

```
heroku config:add HEYTHERE_REPOSITORY=<github-repository> (like `owner/repo`)
```

Create a GitHub personal access token just for this application. You'll need to set a env var for your username and the token. We read these in the app.

```
heroku config:add GITHUB_USERNAME=<github-user>
heroku config:add GITHUB_PAT_OCTOKIT=<github-pat-for-octokit>
```

Optionally, set env vars for various options. You don't have to set these - we'll use defaults

```
heroku config:add HEYTHERE_PRE_DEADLINE_DAYS=<number-of-days-integer>
heroku config:add HEYTHERE_DEADLINE_DAYS=<number-of-days-integer>
heroku config:add HEYTHERE_POST_DEADLINE_EVERY_DAYS=<number-of-days-integer>
heroku config:add HEYTHERE_POST_REVIEW_IN_DAYS=<number-of-days-integer>
heroku config:add HEYTHERE_POST_REVIEW_TOGGLE=<boolean>
heroku config:add HEYTHERE_BOT_NICKNAME=<string>
```

Also save all these env vars in your `.bash_profile`, `.zshrc`, or similar so you can run the app locally. E.g. with entries like `export HEYTHERE_PRE_DEADLINE_DAYS=15`

You can see all your Heroku config vars using `heroku config` or use `rake envs`

Push your app to Heroku

```
git push heroku master
```

Add the scheduler to your heroku app

```
heroku addons:create scheduler:standard
heroku addons:open scheduler
```

Add the task ```rake hey``` to your heroku scheduler and set to whatever schedule you want.


### usage

If you have your repo in an env var as above, run the rake task `hey`

```
rake hey
```

If not, then pass the repo to `hey` like

```
rake hey repo=owner/repo
```

### what does it look like?

This is what a comment looks like in a thread

![assertr_img](/public/img/2016-03-24-hey-there/testhey.png)

You could set up a different GitHub account as your robot so it's clearly not coming from a real person.


## feedback

I'll continue to improve `heythere` as we get feedback on its use in `ropensci/onboarding`. Would also love any feedback from you, internet. Thanks!

[ht]: https://github.com/ropenscilabs/heythere


  </div>
  
  <div class="post">
    <h1>
      <a href="/2016/03/scrubr/">
        scrubr - clean species occurrence records
      </a>
    </h1>

    <span class="post-date">04 Mar 2016</span>

    `scrubr` is an R library for cleaning species occurrence records. It's general purpose, and has the following approach:

* We think using a piping workflow (`%>%`) makes code easier to build up, and easier to understand. However, you don't have to use pipes in this package.
* All inputs and outputs are data.frame's - which makes the above point easier
* Records trimmed off due to various filters are retained as attributes, so can still be accessed for later inspection, but don't get in the way of the data.frame that gets modified for downstream use
* User interface vs. speed: This is the kind of package that surely can get faster. However, we're focusing on the UI first, then make speed improvements down the road. 
* Since occurrence record datasets should all have columns with lat/long information, we automatically look for those columns for you. If identified, we use them, but you can supply lat/long column names manually as well.

We have many packages that fetch species occurrence records from GBIF, iNaturalist, VertNet, iDigBio, Ecoengine, and more. `scrubr` fills a crucial missing niche as likely all uses of occurrence data requires cleaning of some kind. When using GBIF data via `rgbif`, that package has some utilities for cleaning data based on the issues returned with GBIF data - `scrubr` is a companion to do the rest of the cleaning.

## scrubr use cases

### Those covered

- Impossible lat/long values: e.g., latitude 75
- Incomplete cases: one or the other of lat/long missing
- Unlikely lat/long values: e.g., points at 0,0
- Deduplication: try to identify duplicates, esp. when pulling data from multiple sources, e.g., can try to use occurrence IDs, if provided
- Date based cleaning
- Outside political boundary: User input to check for points in the wrong country, or points outside of a known country
- Taxonomic name based cleaning: via `taxize` (one method so far)

### To be covered

* Political centroids: unlikely that occurrences fall exactly on these points, more likely a
default position (Draft function started, but not exported, and commented out)
* Herbaria/Museums: many specimens may have location of the collection they are housed in
* Habitat type filtering: e.g., fish should not be on land; marine fish should not be in fresh water
* Check for contextually wrong values: That is, if 99 out of 100 lat/long coordinates are within the continental US, but 1 is in China, then perhaps something is wrong with that one point
* and many more...

What else do you want included? [Open an issue in the repo](https://github.com/ropenscilabs/scrubr/issues) to chat about use cases.


## Install

From CRAN (binaries may not be up yet, but source is)


```r
install.packages("scrubr")
```

Or from GitHub


```r
devtools::install_github("ropenscilabs/scrubr")
```


```r
library("scrubr")
```

## dframe

`dframe()` is a tool to convert your data.frame to a compact `dplyr` like data.frame so that you can get a quick peek at your data each time you call a function - BUT, you don't have to use it.

Compare `mtcars`


```r
mtcars
#>                      mpg cyl  disp  hp drat    wt  qsec vs am gear carb
#> Mazda RX4           21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4
#> Mazda RX4 Wag       21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4
#> Datsun 710          22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1
#> Hornet 4 Drive      21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1
#> Hornet Sportabout   18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2
#> Valiant             18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1
#> Duster 360          14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4
#> Merc 240D           24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2
#> Merc 230            22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2
#> Merc 280            19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4
#> Merc 280C           17.8   6 167.6 123 3.92 3.440 18.90  1  0    4    4
#> Merc 450SE          16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3
#> Merc 450SL          17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3
#> Merc 450SLC         15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3
#> Cadillac Fleetwood  10.4   8 472.0 205 2.93 5.250 17.98  0  0    3    4
#> Lincoln Continental 10.4   8 460.0 215 3.00 5.424 17.82  0  0    3    4
#> Chrysler Imperial   14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4
#> Fiat 128            32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1
#> Honda Civic         30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2
#> Toyota Corolla      33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1
#> Toyota Corona       21.5   4 120.1  97 3.70 2.465 20.01  1  0    3    1
#> Dodge Challenger    15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2
#> AMC Javelin         15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2
#> Camaro Z28          13.3   8 350.0 245 3.73 3.840 15.41  0  0    3    4
#> Pontiac Firebird    19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2
#> Fiat X1-9           27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1
#> Porsche 914-2       26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2
#> Lotus Europa        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2
#> Ford Pantera L      15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4
#> Ferrari Dino        19.7   6 145.0 175 3.62 2.770 15.50  0  1    5    6
#> Maserati Bora       15.0   8 301.0 335 3.54 3.570 14.60  0  1    5    8
#> Volvo 142E          21.4   4 121.0 109 4.11 2.780 18.60  1  1    4    2
```

To


```r
dframe(mtcars)
#> <scrubr dframe>
#> Size: 32 X 11
#> 
#> 
#>      mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb
#>    (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl) (dbl)
#> 1   21.0     6 160.0   110  3.90 2.620 16.46     0     1     4     4
#> 2   21.0     6 160.0   110  3.90 2.875 17.02     0     1     4     4
#> 3   22.8     4 108.0    93  3.85 2.320 18.61     1     1     4     1
#> 4   21.4     6 258.0   110  3.08 3.215 19.44     1     0     3     1
#> 5   18.7     8 360.0   175  3.15 3.440 17.02     0     0     3     2
#> 6   18.1     6 225.0   105  2.76 3.460 20.22     1     0     3     1
#> 7   14.3     8 360.0   245  3.21 3.570 15.84     0     0     3     4
#> 8   24.4     4 146.7    62  3.69 3.190 20.00     1     0     4     2
#> 9   22.8     4 140.8    95  3.92 3.150 22.90     1     0     4     2
#> 10  19.2     6 167.6   123  3.92 3.440 18.30     1     0     4     4
#> ..   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...
```

## Coordinate based cleaning

Load some sample data that comes with the package


```r
data("sampledata1")
```

Remove impossible coordinates (using sample data included in the pkg)


```r
dframe(sample_data_1) %>% coord_impossible()
#> <scrubr dframe>
#> Size: 1500 X 5
#> Lat/Lon vars: latitude/longitude
#> 
#>                name  longitude latitude                date        key
#>               (chr)      (dbl)    (dbl)              (time)      (int)
#> 1  Ursus americanus  -79.68283 38.36662 2015-01-14 16:36:45 1065590124
#> 2  Ursus americanus  -82.42028 35.73304 2015-01-13 00:25:39 1065588899
#> 3  Ursus americanus  -99.09625 23.66893 2015-02-20 23:00:00 1098894889
#> 4  Ursus americanus  -72.77432 43.94883 2015-02-13 16:16:41 1065611122
#> 5  Ursus americanus  -72.34617 43.86464 2015-03-01 20:20:45 1088908315
#> 6  Ursus americanus -108.53674 32.65219 2015-03-29 17:06:54 1088932238
#> 7  Ursus americanus -108.53691 32.65237 2015-03-29 17:12:50 1088932273
#> 8  Ursus americanus -123.82900 40.13240 2015-03-28 23:00:00 1132403409
#> 9  Ursus americanus  -78.25027 36.93018 2015-03-20 21:11:24 1088923534
#> 10 Ursus americanus  -76.78671 35.53079 2015-04-05 23:00:00 1088954559
#> ..              ...        ...      ...                 ...        ...
```

Remove incomplete coordinates


```r
dframe(sample_data_1) %>% coord_incomplete()
#> <scrubr dframe>
#> Size: 1306 X 5
#> Lat/Lon vars: latitude/longitude
#> 
#>                name  longitude latitude                date        key
#>               (chr)      (dbl)    (dbl)              (time)      (int)
#> 1  Ursus americanus  -79.68283 38.36662 2015-01-14 16:36:45 1065590124
#> 2  Ursus americanus  -82.42028 35.73304 2015-01-13 00:25:39 1065588899
#> 3  Ursus americanus  -99.09625 23.66893 2015-02-20 23:00:00 1098894889
#> 4  Ursus americanus  -72.77432 43.94883 2015-02-13 16:16:41 1065611122
#> 5  Ursus americanus  -72.34617 43.86464 2015-03-01 20:20:45 1088908315
#> 6  Ursus americanus -108.53674 32.65219 2015-03-29 17:06:54 1088932238
#> 7  Ursus americanus -108.53691 32.65237 2015-03-29 17:12:50 1088932273
#> 8  Ursus americanus -123.82900 40.13240 2015-03-28 23:00:00 1132403409
#> 9  Ursus americanus  -78.25027 36.93018 2015-03-20 21:11:24 1088923534
#> 10 Ursus americanus  -76.78671 35.53079 2015-04-05 23:00:00 1088954559
#> ..              ...        ...      ...                 ...        ...
```

Remove unlikely coordinates (e.g., those at 0,0)


```r
dframe(sample_data_1) %>% coord_unlikely()
#> <scrubr dframe>
#> Size: 1488 X 5
#> Lat/Lon vars: latitude/longitude
#> 
#>                name  longitude latitude                date        key
#>               (chr)      (dbl)    (dbl)              (time)      (int)
#> 1  Ursus americanus  -79.68283 38.36662 2015-01-14 16:36:45 1065590124
#> 2  Ursus americanus  -82.42028 35.73304 2015-01-13 00:25:39 1065588899
#> 3  Ursus americanus  -99.09625 23.66893 2015-02-20 23:00:00 1098894889
#> 4  Ursus americanus  -72.77432 43.94883 2015-02-13 16:16:41 1065611122
#> 5  Ursus americanus  -72.34617 43.86464 2015-03-01 20:20:45 1088908315
#> 6  Ursus americanus -108.53674 32.65219 2015-03-29 17:06:54 1088932238
#> 7  Ursus americanus -108.53691 32.65237 2015-03-29 17:12:50 1088932273
#> 8  Ursus americanus -123.82900 40.13240 2015-03-28 23:00:00 1132403409
#> 9  Ursus americanus  -78.25027 36.93018 2015-03-20 21:11:24 1088923534
#> 10 Ursus americanus  -76.78671 35.53079 2015-04-05 23:00:00 1088954559
#> ..              ...        ...      ...                 ...        ...
```

Do all three


```r
dframe(sample_data_1) %>%
  coord_impossible() %>%
  coord_incomplete() %>%
  coord_unlikely()
#> <scrubr dframe>
#> Size: 1294 X 5
#> Lat/Lon vars: latitude/longitude
#> 
#>                name  longitude latitude                date        key
#>               (chr)      (dbl)    (dbl)              (time)      (int)
#> 1  Ursus americanus  -79.68283 38.36662 2015-01-14 16:36:45 1065590124
#> 2  Ursus americanus  -82.42028 35.73304 2015-01-13 00:25:39 1065588899
#> 3  Ursus americanus  -99.09625 23.66893 2015-02-20 23:00:00 1098894889
#> 4  Ursus americanus  -72.77432 43.94883 2015-02-13 16:16:41 1065611122
#> 5  Ursus americanus  -72.34617 43.86464 2015-03-01 20:20:45 1088908315
#> 6  Ursus americanus -108.53674 32.65219 2015-03-29 17:06:54 1088932238
#> 7  Ursus americanus -108.53691 32.65237 2015-03-29 17:12:50 1088932273
#> 8  Ursus americanus -123.82900 40.13240 2015-03-28 23:00:00 1132403409
#> 9  Ursus americanus  -78.25027 36.93018 2015-03-20 21:11:24 1088923534
#> 10 Ursus americanus  -76.78671 35.53079 2015-04-05 23:00:00 1088954559
#> ..              ...        ...      ...                 ...        ...
```

Do vs. don't drop bad data


```r
# do
dframe(sample_data_1) %>% coord_incomplete(drop = TRUE) %>% NROW
#> [1] 1306
# don't
dframe(sample_data_1) %>% coord_incomplete(drop = FALSE) %>% NROW
#> [1] 1500
```


## Deduplicate

Get a smaller subset of a data.frame


```r
smalldf <- sample_data_1[1:20, ]
```

create a duplicate record


```r
smalldf <- rbind(smalldf, smalldf[10,])
row.names(smalldf) <- NULL
```

make it slightly different


```r
smalldf[21, "key"] <- 1088954555
NROW(smalldf)
#> [1] 21
```

It's 21 rows, including 1 duplicate. Do the deduplication


```r
(dp <- dframe(smalldf) %>% dedup())
#> <scrubr dframe>
#> Size: 20 X 5
#> 
#> 
#>                name  longitude latitude                date        key
#>               (chr)      (dbl)    (dbl)              (time)      (dbl)
#> 1  Ursus americanus  -79.68283 38.36662 2015-01-14 16:36:45 1065590124
#> 2  Ursus americanus  -82.42028 35.73304 2015-01-13 00:25:39 1065588899
#> 3  Ursus americanus  -99.09625 23.66893 2015-02-20 23:00:00 1098894889
#> 4  Ursus americanus  -72.77432 43.94883 2015-02-13 16:16:41 1065611122
#> 5  Ursus americanus  -72.34617 43.86464 2015-03-01 20:20:45 1088908315
#> 6  Ursus americanus -108.53674 32.65219 2015-03-29 17:06:54 1088932238
#> 7  Ursus americanus -108.53691 32.65237 2015-03-29 17:12:50 1088932273
#> 8  Ursus americanus -123.82900 40.13240 2015-03-28 23:00:00 1132403409
#> 9  Ursus americanus  -78.25027 36.93018 2015-03-20 21:11:24 1088923534
#> 10 Ursus americanus -103.30058 29.27042 2015-04-29 22:00:00 1088964797
#> ..              ...        ...      ...                 ...        ...
```

Now its 20 rows, duplicate removed

Here's the duplicates


```r
attr(dp, "dups")
#> <scrubr dframe>
#> Size: 1 X 5
#> 
#> 
#>               name longitude latitude                date        key
#>              (chr)     (dbl)    (dbl)              (time)      (dbl)
#> 1 Ursus americanus -76.78671 35.53079 2015-04-05 23:00:00 1088954555
```

## Dates

Standardize/convert dates


```r
df <- sample_data_1
dframe(df) %>% 
  date_standardize("%d%b%Y")
#> <scrubr dframe>
#> Size: 1500 X 5
#> 
#> 
#>                name  longitude latitude      date        key
#>               (chr)      (dbl)    (dbl)     (chr)      (int)
#> 1  Ursus americanus  -79.68283 38.36662 14Jan2015 1065590124
#> 2  Ursus americanus  -82.42028 35.73304 13Jan2015 1065588899
#> 3  Ursus americanus  -99.09625 23.66893 20Feb2015 1098894889
#> 4  Ursus americanus  -72.77432 43.94883 13Feb2015 1065611122
#> 5  Ursus americanus  -72.34617 43.86464 01Mar2015 1088908315
#> 6  Ursus americanus -108.53674 32.65219 29Mar2015 1088932238
#> 7  Ursus americanus -108.53691 32.65237 29Mar2015 1088932273
#> 8  Ursus americanus -123.82900 40.13240 28Mar2015 1132403409
#> 9  Ursus americanus  -78.25027 36.93018 20Mar2015 1088923534
#> 10 Ursus americanus  -76.78671 35.53079 05Apr2015 1088954559
#> ..              ...        ...      ...       ...        ...
```

Drop records without dates


```r
NROW(df)
#> [1] 1500
NROW(dframe(df) %>% date_missing())
#> [1] 1498
```

Create date field from other fields


```r
dframe(sample_data_2) %>% 
  date_create(year, month, day)
#> <scrubr dframe>
#> Size: 1500 X 8
#> 
#> 
#>                name  longitude latitude        key  year month   day
#>               (chr)      (dbl)    (dbl)      (int) (chr) (chr) (chr)
#> 1  Ursus americanus  -79.68283 38.36662 1065590124  2015    01    14
#> 2  Ursus americanus  -82.42028 35.73304 1065588899  2015    01    13
#> 3  Ursus americanus  -99.09625 23.66893 1098894889  2015    02    20
#> 4  Ursus americanus  -72.77432 43.94883 1065611122  2015    02    13
#> 5  Ursus americanus  -72.34617 43.86464 1088908315  2015    03    01
#> 6  Ursus americanus -108.53674 32.65219 1088932238  2015    03    29
#> 7  Ursus americanus -108.53691 32.65237 1088932273  2015    03    29
#> 8  Ursus americanus -123.82900 40.13240 1132403409  2015    03    28
#> 9  Ursus americanus  -78.25027 36.93018 1088923534  2015    03    20
#> 10 Ursus americanus  -76.78671 35.53079 1088954559  2015    04    05
#> ..              ...        ...      ...        ...   ...   ...   ...
#> Variables not shown: date (chr).
```

## bugs and such

Report them in the [scrubr issue tracker](https://github.com/ropenscilabs/scrubr/issues)

  </div>
  
</div>

<!-- Pagination links -->
<div class="pagination">
  
    <a href="/page3" class="older">Older</a>
  
  
    
      <a href="/" class="newer">Newer</a>
    
  
</div>

    </div>

    <!-- for bootstrap tooltips -->
    <script type="text/javascript">
      $("[data-toggle=\"tooltip\"]").tooltip();
    </script>

  </body>

  <footer>
  <!-- Disqus code -->
  <script type="text/javascript">
      /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
      var disqus_shortname = 'recology'; // required: replace example with your forum shortname

      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function () {
          var s = document.createElement('script'); s.async = true;
          s.type = 'text/javascript';
          s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
          (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
      }());
  </script>

  <!-- google analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-63197374-1', 'auto');
    ga('send', 'pageview');
  </script>
</footer>

</html>
