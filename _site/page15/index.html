<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

  <head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  <link href="http://gmpg.org/xfn/11" rel="profile">

  <title>
    
    Recology, R/etc.
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Open+Sans:300,400italic,400,600,700|Abril+Fatface">

  <link rel="stylesheet" href="/public/css/bootstrap/css/bootstrap.css">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/favicon.ico">
  <link rel="shortcut icon" href="/public/favicon.ico">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.css" rel="stylesheet">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body class="theme-base-0f layout-reverse">

    <header class="masthead">
      <div class="masthead-inner">
        <h1>Recology</h1>
        <!-- <h1> <a href="http://localhost:4000">Recology</a></h1> -->
        <p class="lead">R/etc.</p>

        <div class="colophon">
          <ul class="colophon-links">
            <li>
              <a href="/"><i class="fa fa-home fa-lg"></i></a>&nbsp;
              <a href="/about"><i class="fa fa-info-circle fa-lg"></i></a>&nbsp;
              <a href="/archives"><i class="fa fa-archive fa-lg"></i></a>&nbsp;
              <a href="/rresources"><i class="fa fa-book fa-lg"></i></a>&nbsp;
              <a href="http://rforcats.net/" rel><i class="fa fa-graduation-cap fa-lg"></i></a>&nbsp;
              <a href="/feed.xml"><i class="fa fa-rss fa-lg"></i></a>&nbsp;
              <a href="https://twitter.com/sckottie"><i class="fa fa-twitter fa-lg"></i></a>&nbsp;
              <a href="/fork"><i class="fa fa-spinner fa-lg"></i></a>
            </li>
          </ul>
          <!-- <small><a href="https://github.com/mdo/hyde">Hyde</a> from <a href="https://twitter.com/mdo" target="_blank">@mdo</a>.</small> -->
        </div>
      </div>
    </header>

    <div class="content container">
      <div class="posts">
  <a style="float:right;" href="/archives" data-toggle="tooltip" data-placement="bottom" title="Archives"><i class="fa fa-archive fa-lg"></i></a>
  <a style="float:right;" href="/tags"><i class="fa fa-tags fa-lg"></i></a>&nbsp;
  
  <div class="post">
    <h1>
      <a href="/2014/12/altmetrics-anywhere/">
        Altmetrics from anywhere
      </a>
    </h1>

    <span class="post-date">08 Dec 2014</span>

    The Lagotto application is a Rails app that collects and serves up via RESTful API article level metrics data for research objects. So far, this application has only been applied to scholarly articles, but will [see action on datasets soon](http://articlemetrics.github.io/MDC/). 

[Martin Fenner](http://blog.martinfenner.org/) has lead the development of Lagotto. He recently set up [a discussion site](http://discuss.lagotto.io/) if you want to chat about it.

The application has a [nice GUI interface](http://alm.plos.org/), and a quite nice [RESTful API](http://alm.plos.org/docs/api). 

Lagotto is open source! Because of this, and the quality of the software, other publishers have started using it to gather and deliver publicly article level metrics data, including:

* [eLife](http://lagotto.svr.elifesciences.org/)
* [Public Knowledge Project (PKP)](http://pkp-alm.lib.sfu.ca/)
* [Copernicus](http://metricus.copernicus.org/)
* [Crossref](http://det.labs.crossref.org/)
* [Pensoft](http://alm.pensoft.net:81/)

The PLOS instance at [http://alm.plos.org/](http://alm.plos.org/) is always the most up to date with the Lagotto software, but [Crossref](http://det.labs.crossref.org/) has the largest number of articles. 

I've been working on three clients for the Lagotto REST API, including for a while now on `R`, recently on `Python`, and just last week on `Ruby`. 

Please do try the clients, report bugs, request features - you know the open source drill...

I'd say the R client is the most mature, while Python is less so, end the Ruby gem the least mature. 

## Installation

R


```r
install.packages("devtools")
devtools::install_github("ropensci/alm")
```

Python


```r
git clone https://github.com/cameronneylon/pyalm.git
cd pyalm
git checkout scott
python setup.py install
```

Ruby


```r
gem install httparty json rake
git clone https://github.com/sckott/alm.git
cd alm
make # which runs build and install tasks
```

If you don't have `make`, then just run `gem build alm.gemspec` and 	`gem install alm-0.1.0.gem` seperately.

## Example

In this example, we'll get altmetrics data for two DOIs: [10.1371/journal.pone.0029797](http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0029797), and [10.1371/journal.pone.0029798](http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0029798) (click on links to go to paper).

### R


```r
library('alm')
ids <- c("10.1371/journal.pone.0029797","10.1371/journal.pone.0029798")
alm_ids(ids, info="summary")
#> $meta
#>   total total_pages page error
#> 1     2           1    1    NA
#> 
#> $data
#> $data$`10.1371/journal.pone.0029798`
#> $data$`10.1371/journal.pone.0029798`$info
#>                            doi
#> 1 10.1371/journal.pone.0029798
#>                                                                                     title
#> 1 Mitochondrial Electron Transport Is the Cellular Target of the Oncology Drug Elesclomol
#>                                                                canonical_url
#> 1 http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0029798
#>       pmid   pmcid                        mendeley_uuid
#> 1 22253786 3256171 b08cc99e-b526-3f0c-adaa-d5ee6d0d978a
#>            update_date     issued
#> 1 2014-12-09T02:52:47Z 2012-01-11
#> 
#> $data$`10.1371/journal.pone.0029798`$signposts
#>                            doi viewed saved discussed cited
#> 1 10.1371/journal.pone.0029798   4346    14         2    26
#> 
#> 
#> $data$`10.1371/journal.pone.0029797`
#> $data$`10.1371/journal.pone.0029797`$info
#>                            doi
#> 1 10.1371/journal.pone.0029797
#>                                                                             title
#> 1 Ecological Guild Evolution and the Discovery of the World's Smallest Vertebrate
#>                                                                canonical_url
#> 1 http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0029797
#>       pmid   pmcid                        mendeley_uuid
#> 1 22253785 3256195 897fbbd6-5a23-3552-8077-97251b82c1e1
#>            update_date     issued
#> 1 2014-12-09T02:52:46Z 2012-01-11
#> 
#> $data$`10.1371/journal.pone.0029797`$signposts
#>                            doi viewed saved discussed cited
#> 1 10.1371/journal.pone.0029797  34282    81       244     8
```

### Python


```r
import pyalm
ids = ["10.1371/journal.pone.0029797","10.1371/journal.pone.0029798"]
pyalm.get_alm(ids, info="summary")

#> {'articles': [<ArticleALM Mitochondrial Electron Transport Is the Cellular Target of the Oncology Drug Elesclomol,
#> DOI 10.1371/journal.pone.0029798>,
#>   <ArticleALM Ecological Guild Evolution and the Discovery of the World's Smallest Vertebrate,
#>         DOI 10.1371/journal.pone.0029797>],
#>  'meta': {u'error': None, u'page': 1, u'total': 2, u'total_pages': 1}}
```

### Ruby


```r
require 'alm'
Alm.alm(ids: ["10.1371/journal.pone.0029797","10.1371/journal.pone.0029798"], key: ENV['PLOS_API_KEY'])

#> => {"total"=>2,
#>  "total_pages"=>1,
#>  "page"=>1,
#>  "error"=>nil,
#>  "data"=>
#>   [{"doi"=>"10.1371/journal.pone.0029798",
#>     "title"=>"Mitochondrial Electron Transport Is the Cellular Target of the Oncology Drug Elesclomol",
#>     "issued"=>{"date-parts"=>[[2012, 1, 11]]},
#>     "canonical_url"=>"http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0029798",
#>     "pmid"=>"22253786",
#>     "pmcid"=>"3256171",
#>     "mendeley_uuid"=>"b08cc99e-b526-3f0c-adaa-d5ee6d0d978a",
#>     "viewed"=>4346,
#>     "saved"=>14,
#>     "discussed"=>2,
#>     "cited"=>26,
#>     "update_date"=>"2014-12-09T02:52:47Z"},
#>    {"doi"=>"10.1371/journal.pone.0029797",
#>     "title"=>"Ecological Guild Evolution and the Discovery of the World's Smallest Vertebrate",
#>     "issued"=>{"date-parts"=>[[2012, 1, 11]]},
#>     "canonical_url"=>"http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0029797",
#>     "pmid"=>"22253785",
#>     "pmcid"=>"3256195",
#>     "mendeley_uuid"=>"897fbbd6-5a23-3552-8077-97251b82c1e1",
#>     "viewed"=>34282,
#>     "saved"=>81,
#>     "discussed"=>244,
#>     "cited"=>8,
#>     "update_date"=>"2014-12-09T02:52:46Z"}]}
```

  </div>
  
  <div class="post">
    <h1>
      <a href="/2014/12/rplos-pubs-country/">
        Publications by author country
      </a>
    </h1>

    <span class="post-date">03 Dec 2014</span>

    I just missed another chat on the rOpenSci website:

> I want to know the number of publications by people from a certain country, but I dont know how to achieve this...

Fun! Let's do that. It's a bit complicated because there is no field like geography of the authors. But there are affiliation fields, from which we can collect data we need.

## Installation

You'll need the GitHub version for the coutry names data, or just use the CRAN version, and get country names elsewhere. 


```r
install.packages("devtools")
devtools::install_github("ropensci/rplos")
```


```r
library("rplos")
```

## Get the data


```r
articles <- searchplos(q='*:*', limit = 5,
    fl=c("id","author_affiliate"), 
    fq=list('article_type:"Research Article"', "doc_type:full"))
```

## Search for country names in affilitation field


```r
(countries <- lapply(articles$data$author_affiliate, function(x){
  out <- sapply(isocodes$name, function(z) grepl(z, x))
  isocodes$name[out]
}))
#> [[1]]
#> character(0)
#> 
#> [[2]]
#> [1] "Jersey"        "United States"
#> 
#> [[3]]
#> [1] "China"   "Germany"
#> 
#> [[4]]
#> character(0)
#> 
#> [[5]]
#> [1] "Argentina"      "United Kingdom"
```

You can combine this data with the previously collected data:


```r
# Helper function
splitem <- function(x){
  if(length(x) == 0) { NA } else {
    if(length(x) > 1) paste0(x, collapse = ", ") else x
  }
}

articles$data$countries <- sapply(countries, splitem)
head(articles$data)
#>                             id
#> 1 10.1371/journal.pone.0095870
#> 2 10.1371/journal.pone.0110535
#> 3 10.1371/journal.pone.0110991
#> 4 10.1371/journal.pone.0111234
#> 5 10.1371/journal.pone.0111388
#>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                author_affiliate
#> 1 Institute of Epidemiology and Preventive Medicine, College of Public Health, National Taiwan University, Taipei, Taiwan; Department of Clinical Laboratory Sciences and Medical Biotechnology, College of Medicine, National Taiwan University, Taipei, Taiwan; Department of Gastroenterology, Ren-Ai Branch, Taipei City Hospital, Taipei, Taiwan; Division of Gastroenterology, Department of Internal Medicine, National Taiwan University Hospital and National Taiwan University College of Medicine, Taipei, Taiwan; Liver Research Unit, Chang Gung Memorial Hospital, Chang Gung University College of Medicine, Taipei, Taiwan; Division of Gastroenterology, Department of Medicine, Taipei Veterans General Hospital, Taipei, Taiwan; Cheng Hsin General Hospital, Taipei, Taiwan
#> 2    Durham Nephrology Associates, Durham, North Carolina, United States of America; Scientific Activities Department, The National Kidney Foundation, Inc., New York, New York, United States of America; Covance Inc., Princeton, New Jersey, United States of America; Departments of Medicine and Population Health Sciences, University of Wisconsin School of Medicine and Public Health, Madison, Wisconsin, United States of America; Department of Family Medicine, University at Buffalo, Buffalo, New York, United States of America; Baylor Health Care System, Baylor Heart and Vascular Institute, Dallas, Texas, United States of America; Department of Medicine, Division of Nephrology, Icahn School of Medicine at Mount Sinai, New York, New York, United States of America
#> 3                                                                                                                                                                                                                                                                                                                                                                                                                                  State Key Laboratory of Electronic Thin Films and Integrated Devices, School of Microelectronics and Solid-State electronics, University of Electronic Science and Technology of China, Sichuan, China; Electrical and Computer Engineering, Kaiserslautern University of Technology, Kaiserslautern German Gottlieb-Daimler-Strabe, Kaiserslautern, Germany
#> 4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         SB RAS Institute of Chemical Biology and Fundamental Medicine, Novosibirsk, Russia; Pacific Institute of Bioorganic Chemistry, Far East Division, Russian Academy of Sciences, Vladivostok, Russia; Novosibirsk State University, Novosibirsk, Russia
#> 5                                                                                                                                                                                                                                                                                                                                                                                   CONICET, Consejo Nacional de Investigaciones Científicas y Técnicas, Ciudad Autónoma de Buenos Aires, Buenos Aires, Argentina; INGEO, Instituto de Geología, Facultad de Ciencias Exactas, Físicas y Naturales, Universidad Nacional de San Juan, San Juan, San Juan, Argentina; School of Geography, Earth and Environmental Sciences, University of Birmingham, Birmingham, West Midlands, United Kingdom
#>                   countries
#> 1                      <NA>
#> 2     Jersey, United States
#> 3            China, Germany
#> 4                      <NA>
#> 5 Argentina, United Kingdom
```

## Bigger data set

Okay, cool, lets do it on a bigger data set, and this time, we'll get another variable `counter_total_all`, which is the combination of page views/pdf downloads for each article. This will allow us to ask _Is number of countries included in the authors related to page views?_. I have no idea if this question makes sense, but nonetheless, it is a question :)


```r
articles <- searchplos(q='*:*', limit = 1000,
    fl=c("id","counter_total_all","author_affiliate"), 
    fq=list('article_type:"Research Article"', "doc_type:full"))
#> 1 
#> 2
```

Get countries


```r
countries <- lapply(articles$data$author_affiliate, function(x){
  out <- sapply(isocodes$name, function(z) grepl(z, x))
  isocodes$name[out]
})
df <- articles$data
df$countries <- sapply(countries, splitem)
```

Let's remove those rows with 0 countries, since the authors must be from somewhere, so the country name matching must have errored. 


```r
df$n_countries <- sapply(countries, length)
df <- df[ df$n_countries > 0, ]
```

Plot data


```r
library("ggplot2")
ggplot(df, aes(n_countries, as.numeric(counter_total_all))) +
  geom_point() +
  labs(y="total page views") + 
  theme_grey(base_size = 16)
```

![plot of chunk unnamed-chunk-10](figure/unnamed-chunk-10-1.png) 

Conclusion: meh, maybe, maybe not

## Into rplos

We'll probably add a function like this into `rplos`, as a convenient way to handle this use case.

  </div>
  
  <div class="post">
    <h1>
      <a href="/2014/12/http-codes/">
        http codes
      </a>
    </h1>

    <span class="post-date">02 Dec 2014</span>

    Recently noticed a little Python library called [httpcode](https://github.com/rspivak/httpcode) that does a simple thing: gives information on http codes in the CLI. I thought this could maybe potentially be useful for R. So I made an R version. 

## Installation


```r
devtools::install_github("sckott/httpcode")
```


```r
library("httpcode")
```

## Search by http code


```r
http_code(100)
#> <Status code: 100>
#>   Message: Continue
#>   Explanation: Request received, please continue
```


```r
http_code(400)
#> <Status code: 400>
#>   Message: Bad Request
#>   Explanation: Bad request syntax or unsupported method
```


```r
http_code(503)
#> <Status code: 503>
#>   Message: Service Unavailable
#>   Explanation: The server cannot process the request due to a high load
```


```r
http_code(999)
#> Error: No description found for code: 999
```

## Fuzzy code search


```r
http_code('1xx')
#> [[1]]
#> <Status code: 100>
#>   Message: Continue
#>   Explanation: Request received, please continue
#> 
#> [[2]]
#> <Status code: 101>
#>   Message: Switching Protocols
#>   Explanation: Switching to new protocol; obey Upgrade header
#> 
#> [[3]]
#> <Status code: 102>
#>   Message: Processing
#>   Explanation: WebDAV; RFC 2518
```


```r
http_code('3xx')
#> [[1]]
#> <Status code: 300>
#>   Message: Multiple Choices
#>   Explanation: Object has several resources -- see URI list
#> 
#> [[2]]
#> <Status code: 301>
#>   Message: Moved Permanently
#>   Explanation: Object moved permanently -- see URI list
#> 
#> [[3]]
#> <Status code: 302>
#>   Message: Found
#>   Explanation: Object moved temporarily -- see URI list
#> 
#> [[4]]
#> <Status code: 303>
#>   Message: See Other
#>   Explanation: Object moved -- see Method and URL list
#> 
#> [[5]]
#> <Status code: 304>
#>   Message: Not Modified
#>   Explanation: Document has not changed since given time
#> 
#> [[6]]
#> <Status code: 305>
#>   Message: Use Proxy
#>   Explanation: You must use proxy specified in Location to access this resource.
#> 
#> [[7]]
#> <Status code: 306>
#>   Message: Switch Proxy
#>   Explanation: Subsequent requests should use the specified proxy
#> 
#> [[8]]
#> <Status code: 307>
#>   Message: Temporary Redirect
#>   Explanation: Object moved temporarily -- see URI list
#> 
#> [[9]]
#> <Status code: 308>
#>   Message: Permanent Redirect
#>   Explanation: Object moved permanently
```


```r
http_code('30[12]')
#> [[1]]
#> <Status code: 301>
#>   Message: Moved Permanently
#>   Explanation: Object moved permanently -- see URI list
#> 
#> [[2]]
#> <Status code: 302>
#>   Message: Found
#>   Explanation: Object moved temporarily -- see URI list
```


```r
http_code('30[34]')
#> [[1]]
#> <Status code: 303>
#>   Message: See Other
#>   Explanation: Object moved -- see Method and URL list
#> 
#> [[2]]
#> <Status code: 304>
#>   Message: Not Modified
#>   Explanation: Document has not changed since given time
```

## Search by text message


```r
http_search("request")
#> [[1]]
#> <Status code: 100>
#>   Message: Continue
#>   Explanation: Request received, please continue
#> 
#> [[2]]
#> <Status code: 200>
#>   Message: OK
#>   Explanation: Request fulfilled, document follows
#> 
#> [[3]]
#> <Status code: 202>
#>   Message: Accepted
#>   Explanation: Request accepted, processing continues off-line
#> 
#> [[4]]
#> <Status code: 203>
#>   Message: Non-Authoritative Information
#>   Explanation: Request fulfilled from cache
#> 
#> [[5]]
#> <Status code: 204>
#>   Message: No Content
#>   Explanation: Request fulfilled, nothing follows
#> 
#> [[6]]
#> <Status code: 306>
#>   Message: Switch Proxy
#>   Explanation: Subsequent requests should use the specified proxy
#> 
#> [[7]]
#> <Status code: 400>
#>   Message: Bad Request
#>   Explanation: Bad request syntax or unsupported method
#> 
#> [[8]]
#> <Status code: 403>
#>   Message: Forbidden
#>   Explanation: Request forbidden -- authorization will not help
#> 
#> [[9]]
#> <Status code: 408>
#>   Message: Request Timeout
#>   Explanation: Request timed out; try again later.
#> 
#> [[10]]
#> <Status code: 409>
#>   Message: Conflict
#>   Explanation: Request conflict.
#> 
#> [[11]]
#> <Status code: 413>
#>   Message: Request Entity Too Large
#>   Explanation: Entity is too large.
#> 
#> [[12]]
#> <Status code: 414>
#>   Message: Request-URI Too Long
#>   Explanation: URI is too long.
#> 
#> [[13]]
#> <Status code: 416>
#>   Message: Requested Range Not Satisfiable
#>   Explanation: Cannot satisfy request range.
#> 
#> [[14]]
#> <Status code: 503>
#>   Message: Service Unavailable
#>   Explanation: The server cannot process the request due to a high load
#> 
#> [[15]]
#> <Status code: 505>
#>   Message: HTTP Version Not Supported
#>   Explanation: Cannot fulfill request.
```


```r
http_search("forbidden")
#> [[1]]
#> <Status code: 403>
#>   Message: Forbidden
#>   Explanation: Request forbidden -- authorization will not help
```


```r
http_search("too")
#> [[1]]
#> <Status code: 413>
#>   Message: Request Entity Too Large
#>   Explanation: Entity is too large.
#> 
#> [[2]]
#> <Status code: 414>
#>   Message: Request-URI Too Long
#>   Explanation: URI is too long.
```


```r
http_search("birds")
#> Error: No status code found for search: : birds
```

  </div>
  
</div>

<!-- Pagination links -->
<div class="pagination">
  
    <a href="/page16" class="older">Older</a>
  
  
    
      <a href="/page14" class="newer">Newer</a>
    
  
</div>

    </div>

    <!-- for bootstrap tooltips -->
    <script type="text/javascript">
      $("[data-toggle=\"tooltip\"]").tooltip();
    </script>

  </body>

  <footer>
  <!-- Disqus code -->
  <script type="text/javascript">
      /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
      var disqus_shortname = 'recology'; // required: replace example with your forum shortname

      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function () {
          var s = document.createElement('script'); s.async = true;
          s.type = 'text/javascript';
          s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
          (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
      }());
  </script>

  <!-- google analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-63197374-1', 'auto');
    ga('send', 'pageview');
  </script>
</footer>

</html>
