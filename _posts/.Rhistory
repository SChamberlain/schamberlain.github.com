md_listsets(provider = "arXiv") # arXiv
md_listsets(provider = c("datacite","pensoft","Aston University Research Archive"))
md_listsets(provider = "biology", fuzzy=TRUE)
#' List the OAI-PMH sets for each data provider.
#'
#' List sets for the data sources from the OAI-PMH list, and others not
#' 		on that list, including PMC, DataCite, Hindawi Journals, Dryad, and
#' 		Pensoft Journals.
#'
#' @import plyr httr XML
#' @param provider The metadata provider.
#' @param fuzzy Do fuzzy search or not (default FALSE). Fuzzy uses agrep.
#' @author Scott Chamberlain \email{myrmecocystus@@gmail.com}
#' @examples \dontrun{
#' md_listsets(provider = "datacite") # DataCite
#' md_listsets(provider = "arXiv") # arXiv
#'
#' # Many providers
#' md_listsets(provider = c("datacite","pensoft","Aston University Research Archive"))
#'
#' # Fuzzy search
#' md_listsets(provider = "biology", fuzzy=TRUE)
#' }
#' @export
md_listsets <- function(provider = NULL, fuzzy = FALSE)
{
if(exists(as.character(substitute(providers)))==TRUE){ NULL } else
{ data(providers); message("loaded providers") }
doit <- function(x, args) {
if(fuzzy){ get_ <- providers[ agrep(x, providers[,1]), ] } else
{ get_ <- providers[ grep(x, providers[,1]), ] }
if(nrow(get_) == 0){
data.frame(x="no match found")
} else
if(nrow(get_) > 1){
# user prompt
# sort alphabetically
get_df <- get_[order(get_$repo_name), ]
rownames(get_df) <- 1:nrow(get_df)
# prompt
cat("\n\n")
print(data.frame(get_df$repo_name))
cat("\nMore than one match found for provider '", provider, "'!\n
Enter row number of provider (other inputs will return 'NA'):\n") # prompt
take <- scan(n = 1, quiet = TRUE, what = 'raw')
# Get base url to use
if(length(take) == 0)
stop(paste("\nYou need to type in a number from 1 to ",nrow(get_df),'\n',sep=''))
if(take %in% seq_len(nrow(get_df))){
take <- as.numeric(take)
cat("Input accepted, took provider '", as.character(get_df$repo_name[take]), "'.\n")
url <-  get_df$base_url[take]
} else { stop("\nNo match found!\n") }
} else
{ url <- get_[,"base_url"] }
args <- list(verb = "ListSets")
iter <- 0
token <- "characters" # define a iterator, also used for gettingn the resumptionToken
nameslist <- list() # define empty list to put joural titles in to
while(is.character(token) == TRUE) # while token is class "character", keep going
{
iter <- iter + 1
args2 <- args
if(token == "characters"){NULL} else {args2$resumptionToken <- token}
crr <- xmlToList(xmlParse(content(GET(url, query=args2), as="text")))
out <- ldply(crr$ListSets, function(x) c(setName=x[["setName"]], setSpec=x[["setSpec"]]))[,-1]
nameslist[[iter]] <- out
if( class( try(crr$ListSets$resumptionToken$text) ) == "try-error") {
token <- 1
} else { token <- crr$ListIdentifiers$resumptionToken$text }
}
do.call(rbind, nameslist) # concatenate
}
llply(provider, function(x) doit(x, args) )
}
md_listsets(provider = "biology", fuzzy=TRUE)
md_listsets(provider = "biology", fuzzy=TRUE)
md_listsets(provider = "biology", fuzzy=TRUE)
count_identifiers("datacite")
ldply(c("datacite","Academic Commons","pensoft","arXiv"), count_identifiers)
url
args
ss <- tryCatch(http_status(GET(url, query=args, config=timeout(seconds))), error = function(e) e$message)
ss
seconds = 3
ss <- tryCatch(http_status(GET(url, query=args, config=timeout(seconds))), error = function(e) e$message)
ss
?tryCatch
ss <- tryCatch(content(GET(url, query=args, config=timeout(seconds)), as="text"), error = function(e) e$message)
ss
xmlToList(xmlParse(ss))
md_listmetadataformats(provider = "biology", fuzzy=TRUE)
provider = "AnimalPhysiology-LivestockSystems"
args <- compact(list(verb = 'ListMetadataFormats', identifier = identifier))
args
if(fuzzy){ get_ <- providers[ agrep(provider, providers[,1]), ] } else
{ get_ <- providers[ grep(provider, providers[,1]), ] }
get_
url <- get_[,"base_url"]
url
ss <- tryCatch(content(GET(url, query=args, config=timeout(seconds)), as="text"), error = function(e) e$message)
ss
class(ss)
ss
if(ss == "connect() timed out!"){ message("Connection timed out - try larger seconds arg, or url may be down") } else
{
crr <- xmlToList(xmlParse(ss))
if(!is.null(identifier)) {
id <- crr$request$.attrs[[2]]
df_ <- ldply(crr$ListMetadataFormats, function(x) data.frame(x))[,-1]
data.frame(identifier = rep(id, nrow(df_)), df_)
} else
{
ldply(crr$ListMetadataFormats, function(x) data.frame(x))[,-1]
}
}
#' List available metadata formats from various providers.
#'
#' List metadata formats for the data sources from the OAI-PMH list, and others not
#' 		on that list, including PMC, DataCite, Hindawi Journals, Dryad, and
#' 		Pensoft Journals.
#'
#' @import XML httr plyr
#' @param provider The metadata provider.
#' @param identifier The OAI-PMH identifier for the record. Optional.
#' @param fuzzy Do fuzzy search or not (default FALSE). Fuzzy uses agrep.
#' @author Scott Chamberlain \email{myrmecocystus@@gmail.com}
#' @examples \dontrun{
#' # List metadata formats for a provider
#' md_listmetadataformats(provider = "dryad")
#'
#' # List metadata formats for a specific identifier for a provider
#' md_listmetadataformats(provider = "pensoft", identifier = "10.3897/zookeys.1.10")
#'
#' # Fuzzy search
#' md_listmetadataformats(provider = "biology", fuzzy=TRUE)
#' md_listmetadataformats(provider = "AnimalPhysiology-LivestockSystems")
#' }
#' @export
md_listmetadataformats <- function(provider = NULL, identifier = NULL, fuzzy = FALSE
seconds = 3)
{
if(exists(as.character(substitute(providers)))==TRUE){ NULL } else
{ data(providers); message("loaded providers") }
doit <- function(provider, identifier=NULL) {
args <- compact(list(verb = 'ListMetadataFormats', identifier = identifier))
if(fuzzy){ get_ <- providers[ agrep(provider, providers[,1]), ] } else
{ get_ <- providers[ grep(provider, providers[,1]), ] }
if(nrow(get_) == 0){
stop("\nNo match found!\n")
} else
if(nrow(get_) > 1){
# user prompt
# sort alphabetically
get_df <- get_[order(get_$repo_name), ]
rownames(get_df) <- 1:nrow(get_df)
# prompt
cat("\n\n")
print(data.frame(get_df$repo_name))
cat("\nMore than one match found for provider '", provider, "'!\n
Enter row number of provider (other inputs will return 'NA'):\n") # prompt
take <- scan(n = 1, quiet = TRUE, what = 'raw')
# Get base url to use
if(length(take) == 0)
stop(paste("\nYou need to type in a number from 1 to ",nrow(get_df),'\n',sep=''))
if(take %in% seq_len(nrow(get_df))){
take <- as.numeric(take)
cat("Input accepted, took provider '", as.character(get_df$repo_name[take]), "'.\n")
url <-  get_df$base_url[take]
} else { stop("\nNo match found!\n") }
} else { url <- get_[,"base_url"] }
# 		crr <- xmlToList(xmlParse(content(GET(url, query=args), as="text")))
ss <- tryCatch(content(GET(url, query=args, config=timeout(seconds)), as="text"), error = function(e) e$message)
if(ss == "connect() timed out!"){ message("Connection timed out - try larger seconds arg, or url may be down") } else
{
crr <- xmlToList(xmlParse(ss))
if(!is.null(identifier)) {
id <- crr$request$.attrs[[2]]
df_ <- ldply(crr$ListMetadataFormats, function(x) data.frame(x))[,-1]
data.frame(identifier = rep(id, nrow(df_)), df_)
} else
{
ldply(crr$ListMetadataFormats, function(x) data.frame(x))[,-1]
}
}
}
if(!is.null(identifier)) {
ldply(identifier, function(x) doit(provider, x) )
} else
{
doit(provider=provider)
}
}
#' List available metadata formats from various providers.
#'
#' List metadata formats for the data sources from the OAI-PMH list, and others not
#' 		on that list, including PMC, DataCite, Hindawi Journals, Dryad, and
#' 		Pensoft Journals.
#'
#' @import XML httr plyr
#' @param provider The metadata provider.
#' @param identifier The OAI-PMH identifier for the record. Optional.
#' @param fuzzy Do fuzzy search or not (default FALSE). Fuzzy uses agrep.
#' @author Scott Chamberlain \email{myrmecocystus@@gmail.com}
#' @examples \dontrun{
#' # List metadata formats for a provider
#' md_listmetadataformats(provider = "dryad")
#'
#' # List metadata formats for a specific identifier for a provider
#' md_listmetadataformats(provider = "pensoft", identifier = "10.3897/zookeys.1.10")
#'
#' # Fuzzy search
#' md_listmetadataformats(provider = "biology", fuzzy=TRUE)
#' md_listmetadataformats(provider = "AnimalPhysiology-LivestockSystems")
#' }
#' @export
md_listmetadataformats <- function(provider = NULL, identifier = NULL,
fuzzy = FALSE, seconds = 3)
{
if(exists(as.character(substitute(providers)))==TRUE){ NULL } else
{ data(providers); message("loaded providers") }
doit <- function(provider, identifier=NULL) {
args <- compact(list(verb = 'ListMetadataFormats', identifier = identifier))
if(fuzzy){ get_ <- providers[ agrep(provider, providers[,1]), ] } else
{ get_ <- providers[ grep(provider, providers[,1]), ] }
if(nrow(get_) == 0){
stop("\nNo match found!\n")
} else
if(nrow(get_) > 1){
# user prompt
# sort alphabetically
get_df <- get_[order(get_$repo_name), ]
rownames(get_df) <- 1:nrow(get_df)
# prompt
cat("\n\n")
print(data.frame(get_df$repo_name))
cat("\nMore than one match found for provider '", provider, "'!\n
Enter row number of provider (other inputs will return 'NA'):\n") # prompt
take <- scan(n = 1, quiet = TRUE, what = 'raw')
# Get base url to use
if(length(take) == 0)
stop(paste("\nYou need to type in a number from 1 to ",nrow(get_df),'\n',sep=''))
if(take %in% seq_len(nrow(get_df))){
take <- as.numeric(take)
cat("Input accepted, took provider '", as.character(get_df$repo_name[take]), "'.\n")
url <-  get_df$base_url[take]
} else { stop("\nNo match found!\n") }
} else { url <- get_[,"base_url"] }
# 		crr <- xmlToList(xmlParse(content(GET(url, query=args), as="text")))
ss <- tryCatch(content(GET(url, query=args, config=timeout(seconds)), as="text"), error = function(e) e$message)
if(ss == "connect() timed out!"){ message("Connection timed out - try larger seconds arg, or url may be down") } else
{
crr <- xmlToList(xmlParse(ss))
if(!is.null(identifier)) {
id <- crr$request$.attrs[[2]]
df_ <- ldply(crr$ListMetadataFormats, function(x) data.frame(x))[,-1]
data.frame(identifier = rep(id, nrow(df_)), df_)
} else
{
ldply(crr$ListMetadataFormats, function(x) data.frame(x))[,-1]
}
}
}
if(!is.null(identifier)) {
ldply(identifier, function(x) doit(provider, x) )
} else
{
doit(provider=provider)
}
}
md_listmetadataformats(provider = "biology", fuzzy=TRUE)
md_listmetadataformats(provider = "biology", fuzzy=TRUE)
md_listmetadataformats(provider = "biology", fuzzy=TRUE)
md_listmetadataformats(provider = "biology", fuzzy=TRUE)
library(roxygen2)
rmd <- "/Users/scottmac2/github/ropensci/rmd"
roxygenize(rmd)
rmd <- "/Users/scottmac2/github/ropensci/rmd"
roxygenize(rmd)
install(rmd)
library(rmd)
help(package=rmd)
?save
Sys.Date()
date = Sys.Date()
path="."
paste(path, "/", date, "-providers", sep="")
paste(path, "/", date, "-providers.Rdata", sep="")
paste(path, "/", date, "-providers.rda", sep="")
path="."
update_providers <- function(path=".")
{
date <- Sys.Date()
temp <- content(GET("http://www.openarchives.org/Register/BrowseSites"))
providers <- readHTMLTable("http://www.openarchives.org/Register/BrowseSites")
providers <- providers[[2]] # get second table
providers <- providers[,-c(1,2)] # remove first two columns
names(providers) <- c("repo_name", "base_url", "oai_identifier")
save(providers, file=paste(path, "/", date, "-providers.rda", sep=""))
}
update_providers()
library(httr)
update_providers()
load_providers <- function(path=NULL){
if(is.null(path))
file <- system.file("data", "providers.rda", package="rmd")
else {
# load the most recent file from the cache
files <- list.files(path)
copies <- grep("providers.rda", files)
most_recent <- files[copies[length(copies)]]
file=paste(path, "/", most_recent, sep="")
}
load(file, envir = fishbaseCache)
fish.data <- get("fish.data", envir = fishbaseCache)
fish.data
}
load_providers(".")
rmdCache <- new.env(hash=TRUE)
load_providers <- function(path=NULL){
if(is.null(path))
file <- system.file("data", "providers.rda", package="rmd")
else {
# load the most recent file from the cache
files <- list.files(path)
copies <- grep("providers.rda", files)
most_recent <- files[copies[length(copies)]]
file=paste(path, "/", most_recent, sep="")
}
load(file, envir = rmdCache)
dat <- get("providers", envir = rmdCache)
dat
}
load_providers(".")
load_providers <- function(path=NULL){
if(is.null(path))
file <- system.file("data", "providers.rda", package="rmd")
else {
# load the most recent file from the cache
files <- list.files(path)
copies <- grep("providers.rda", files)
most_recent <- files[copies[length(copies)]]
file=paste(path, "/", most_recent, sep="")
}
load(file, envir = rmdCache)
invisible()
}
path="."
is.null(path)
files <- list.files(path)
files
copies <- grep("providers.rda", files)
copies
most_recent <- files[copies[length(copies)]]
most_recent
file=paste(path, "/", most_recent, sep="")
file
file
load(file, envir = rmdCache)
data(providers)
data(providers, envir=rmdCache)
rm(providers)
data(providers, envir=rmdCache)
data(providers, envir="rmdCache")
data(providers)
?invisible
load_providers <- function(path=NULL){
if(is.null(path))
file <- system.file("data", "providers.rda", package="rmd")
else {
# load the most recent file from the cache
files <- list.files(path)
copies <- grep("providers.rda", files)
most_recent <- files[copies[length(copies)]]
file=paste(path, "/", most_recent, sep="")
}
load(file, envir = rmdCache)
invisible(providers)
}
rm(providers)
load_providers(path=".")
load_providers <- function(path=NULL){
if(is.null(path))
file <- system.file("data", "providers.rda", package="rmd")
else {
# load the most recent file from the cache
files <- list.files(path)
copies <- grep("providers.rda", files)
most_recent <- files[copies[length(copies)]]
file=paste(path, "/", most_recent, sep="")
}
load(file, envir = rmdCache)
invisible(file)
}
load_providers(path=".")
library(rmd)
library(roxygen2)
rmd <- "/Users/scottmac2/github/ropensci/rmd"
roxygenize(rmd)
rmd <- "/Users/scottmac2/github/ropensci/rmd"
install(rmd)
library(rmd)
load_providers(path=".")
data(providers, envir='rmdCache')
data(providers, envir=rmdCache)
library(roxygen2)
rmd <- "/Users/scottmac2/github/ropensci/rmd"
roxygenize(rmd)
rmd <- "/Users/scottmac2/github/ropensci/rmd"
install(rmd)
library(rmd)
load_providers(path=".")
environment()
environment(rmdCache)
#' Update the locally stored OAI-PMH data providers table.
#'
#' Data comes from \url{http://www.openarchives.org/Register/BrowseSites}.
#' 		Data includes oai-identifier (if they have one) and baes URL. The website has
#' 		the name of the data provider too, but not provided in the data pulled
#' 		down here, but you can grab the name using example below.
#'
#' @import httr XML
#' @details This table is scraped from
#' 		\url{http://www.openarchives.org/Register/BrowseSites}.
#' 		I would get it from \url{http://www.openarchives.org/Register/ListFriends},
#' 		but it does not include repository names.
#'
#' 		This function updates the table for you. Does take a while though, so
#' 		go get a coffee.
#' @seealso \code{\link{load_providers}}
#' @author Scott Chamberlain \email{myrmecocystus@@gmail.com}
#' @examples \dontrun{
#' update_providers()
#' load_providers()
#' }
#' @export
update_providers <- function(path=".")
{
date <- Sys.Date()
temp <- content(GET("http://www.openarchives.org/Register/BrowseSites"))
providers <- readHTMLTable("http://www.openarchives.org/Register/BrowseSites")
providers <- providers[[2]] # get second table
providers <- providers[,-c(1,2)] # remove first two columns
names(providers) <- c("repo_name", "base_url", "oai_identifier")
save(providers, file=paste(path, "/", date, "-providers.rda", sep=""))
}
#' Load an updated cache
#'
#' @param path location where cache is located
#' @return loads the object providers into the working space.
#' @seealso \code{\link{update_providers}}
#' @author Scott Chamberlain \email{myrmecocystus@@gmail.com}
#' @examples \dontrun{
#' update_providers()
#' load_providers()
#'
#' load_providers(path=".")
#' }
#' @export
load_providers <- function(path=NULL){
if(is.null(path))
file <- system.file("data", "providers.rda", package="rmd")
else {
# load the most recent file from the cache
files <- list.files(path)
copies <- grep("providers.rda", files)
most_recent <- files[copies[length(copies)]]
file=paste(path, "/", most_recent, sep="")
}
#   load(file, envir = rmdCache)
load(file)
#   providers.data <- get("providers", envir = rmdCache)
#   providers.data
}
library(httr)
GET("http://ec2-54-245-199-174.us-west-2.compute.amazonaws.com/R/pub/stats/rnorm/json?n=15&mean=10")
POST("http://ec2-54-245-199-174.us-west-2.compute.amazonaws.com/R/pub/stats/rnorm/json?n=15&mean=10")
POST("http://ec2-54-245-199-174.us-west-2.compute.amazonaws.com/R/call/stats/rnorm/json?n=15&mean=10")
POST("http://ec2-54-245-199-174.us-west-2.compute.amazonaws.com/R/call/stats/rnorm/json?n=15&mean=10")
library(RCurl)
postForm("http://ec2-54-245-199-174.us-west-2.compute.amazonaws.com/R/call/stats/rnorm/json?n=15&mean=10")
postForm("https://public.opencpu.org/R/call/taxize/iucn_summary/json?sciname=%22Panthera%20uncia%22")
POST("https://public.opencpu.org/R/call/taxize/iucn_summary/json?sciname=%22Panthera%20uncia%22")
content(POST("https://public.opencpu.org/R/call/taxize/iucn_summary/json?sciname=%22Panthera%20uncia%22"))
content(POST("https://public.opencpu.org/R/call/taxize/iucn_summary/json?sciname=%22Panthera%20uncia%22"), as="text")
rmetadata <- "/Users/scottmac2/github/ropensci/rmetadata"
build_win(rmetadata)
library(roxygen2)
rmetadata <- "/Users/scottmac2/github/ropensci/rmetadata"
roxygenize(rmetadata)
check(rmetadata)
library(roxygen2)
rmetadata <- "/Users/scottmac2/github/ropensci/rmetadata"
roxygenize(rmetadata)
check(rmetadata)
install_github("rmetadata", "ropensci")
library(rmetadata)
help(package=rmetadata)
install_github("rpubmed", "ropensci")
library(rpubmed)
plasticity_ids <- entrez_search("pubmed", "phenotypic plasticity", retmax = 2600)$ids[1:100]
plasticity_ids
plasticity_records <- pubmed_fetch(plasticity_ids[1:2])
plasticity_records
plasticity_records[[1]]
install("~/github/ropensci/rmetadata/")
library(roxygen2)
rmetadata <- "/Users/scottmac2/github/ropensci/rmetadata"
roxygenize(rmetadata)
install(rmetadata)
setwd("~/github/sac/schamberlain.github.com/_posts/")
knitpost("/Users/scottmac2/github/sac/schamberlain.github.com/_drafts/2013-03-14-r-metadata.Rmd")
