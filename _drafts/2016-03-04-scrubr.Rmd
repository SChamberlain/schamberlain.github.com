---
name: scrubr
layout: post
title: scrubr - clean species occurrence records
date: 2016-03-04
author: Scott Chamberlain
sourceslug: _drafts/2016-03-04-scrubr.Rmd
tags:
- R
- occurrences
- occurrence records
- species
- ecology
---

```{r echo=FALSE}
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  collapse = TRUE,
  comment = "#>"
)
```

`scrubr` is an R library for cleaning species occurrence records. It's general purpose, and has the following approach:

* We think using a piping workflow (`%>%`) makes code easier to build up, and easier to understand. However, you don't have to use pipes in this package.
* All inputs and outputs are data.frame's - which makes the above point easier
* Records trimmed off due to various filters are retained as attributes, so can still be accessed for later inspection, but don't get in the way of the data.frame that gets modified for downstream use
* User interface vs. speed: This is the kind of package that surely can get faster. However, we're focusing on the UI first, then make speed improvements down the road. 
* Since occurrence record datasets should all have columns with lat/long information, we automatically look for those columns for you. If identified, we use them, but you can supply lat/long column names manually as well.

We have many packages that fetch species occurrence records from GBIF, iNaturalist, VertNet, iDigBio, Ecoengine, and more. `scrubr` fills a crucial missing niche as likely all uses of occurrence data requires cleaning of some kind. When using GBIF data via `rgbif`, that package has some utilities for cleaning data based on the issues returned with GBIF data - `scrubr` is a companion to do the rest of the cleaning.

## scrubr use cases

### Those covered

- Impossible lat/long values: e.g., latitude 75
- Incomplete cases: one or the other of lat/long missing
- Unlikely lat/long values: e.g., points at 0,0
- Deduplication: try to identify duplicates, esp. when pulling data from multiple sources, e.g., can try to use occurrence IDs, if provided
- Date based cleaning
- Outside political boundary: User input to check for points in the wrong country, or points outside of a known country
- Taxonomic name based cleaning: via `taxize` (one method so far)

### To be covered

* Political centroids: unlikely that occurrences fall exactly on these points, more likely a
default position (Draft function started, but not exported, and commented out)
* Herbaria/Museums: many specimens may have location of the collection they are housed in
* Habitat type filtering: e.g., fish should not be on land; marine fish should not be in fresh water
* Check for contextually wrong values: That is, if 99 out of 100 lat/long coordinates are within the continental US, but 1 is in China, then perhaps something is wrong with that one point
* and many more...

What else do you want included? [Open an issue in the repo](https://github.com/ropenscilabs/scrubr/issues) to chat about use cases.


## Install

From CRAN (binaries may not be up yet, but source is)

```{r eval=FALSE}
install.packages("scrubr")
```

Or from GitHub

```{r eval=FALSE}
devtools::install_github("ropenscilabs/scrubr")
```

```{r}
library("scrubr")
```

## dframe

`dframe()` is a tool to convert your data.frame to a compact `dplyr` like data.frame so that you can get a quick peek at your data each time you call a function - BUT, you don't have to use it.

Compare `mtcars`

```{r}
mtcars
```

To

```{r}
dframe(mtcars)
```

## Coordinate based cleaning

Load some sample data that comes with the package

```{r}
data("sampledata1")
```

Remove impossible coordinates (using sample data included in the pkg)

```{r}
dframe(sample_data_1) %>% coord_impossible()
```

Remove incomplete coordinates

```{r}
dframe(sample_data_1) %>% coord_incomplete()
```

Remove unlikely coordinates (e.g., those at 0,0)

```{r}
dframe(sample_data_1) %>% coord_unlikely()
```

Do all three

```{r}
dframe(sample_data_1) %>%
  coord_impossible() %>%
  coord_incomplete() %>%
  coord_unlikely()
```

Do vs. don't drop bad data

```{r}
# do
dframe(sample_data_1) %>% coord_incomplete(drop = TRUE) %>% NROW
# don't
dframe(sample_data_1) %>% coord_incomplete(drop = FALSE) %>% NROW
```


## Deduplicate

Get a smaller subset of a data.frame

```{r}
smalldf <- sample_data_1[1:20, ]
```

create a duplicate record

```{r}
smalldf <- rbind(smalldf, smalldf[10,])
row.names(smalldf) <- NULL
```

make it slightly different

```{r}
smalldf[21, "key"] <- 1088954555
NROW(smalldf)
```

It's `r NROW(smalldf)` rows, including 1 duplicate. Do the deduplication

```{r}
(dp <- dframe(smalldf) %>% dedup())
```

Now its `r NROW(dp)` rows, duplicate removed

Here's the duplicates

```{r}
attr(dp, "dups")
```

## Dates

Standardize/convert dates

```{r}
df <- sample_data_1
dframe(df) %>% 
  date_standardize("%d%b%Y")
```

Drop records without dates

```{r}
NROW(df)
NROW(dframe(df) %>% date_missing())
```

Create date field from other fields

```{r}
dframe(sample_data_2) %>% 
  date_create(year, month, day)
```

## bugs and such

Report them in the [scrubr issue tracker](https://github.com/ropenscilabs/scrubr/issues)
